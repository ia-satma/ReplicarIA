â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ TOON MAESTRO - REVISAR.IA - ARREGLAR TODO DE UNA VEZ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FECHA: Enero 2025
OBJETIVO: Dejar el sistema 100% funcional para demo

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ RESUMEN DE PROBLEMAS (POR PRIORIDAD)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”´ CRÃTICO (Bloquean uso del sistema):
  P1. Bibliotecar.IA se cuelga al procesar PDFs grandes
  P2. Bibliotecar.IA NO GUARDA documentos en BD (0 docs, 0 chunks)
  P3. Panel Admin muestra 0 usuarios (no se puede administrar)
  P4. "AutenticaciÃ³n requerida" bloquea formulario de entregables

ğŸŸ  IMPORTANTE (Funcionalidad incompleta):
  P5. No hay feedback de progreso al procesar documentos
  P6. Sidebar no se actualiza despuÃ©s de subir documentos
  P7. BÃºsqueda RAG no funciona (sin embeddings)

ğŸŸ¡ MEJORAS (Para despuÃ©s de demo):
  P8. Defense Files en pCloud (documentaciÃ³n de evidencia)
  P9. TrÃ¡fico.IA (monitoreo con emails automÃ¡ticos)
  P10. DiseÃ±ar.IA (auditorÃ­a de UI)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                            PARTE 1: DEPENDENCIAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ejecutar PRIMERO:

```bash
pip install pdfplumber PyMuPDF python-docx openpyxl \
            anthropic openai google-generativeai \
            sendgrid apscheduler \
            --break-system-packages
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                     PARTE 2: VERIFICAR/CREAR TABLAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- TABLAS PARA KNOWLEDGE BASE (RAG)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CREATE TABLE IF NOT EXISTS kb_documentos (
    id SERIAL PRIMARY KEY,
    nombre VARCHAR(255) NOT NULL,
    contenido_raw TEXT,
    categoria VARCHAR(100) DEFAULT 'General',
    procesado BOOLEAN DEFAULT FALSE,
    activo BOOLEAN DEFAULT TRUE,
    num_chunks INTEGER DEFAULT 0,
    error_procesamiento TEXT,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE IF NOT EXISTS kb_chunks (
    id SERIAL PRIMARY KEY,
    documento_id INTEGER REFERENCES kb_documentos(id) ON DELETE CASCADE,
    contenido TEXT NOT NULL,
    posicion INTEGER DEFAULT 0,
    embedding vector(1536),
    tokens INTEGER,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_kb_chunks_documento ON kb_chunks(documento_id);
CREATE INDEX IF NOT EXISTS idx_kb_chunks_embedding ON kb_chunks USING ivfflat (embedding vector_cosine_ops);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- TABLAS PARA USUARIOS Y PERMISOS
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Agregar columnas faltantes a users
ALTER TABLE users ADD COLUMN IF NOT EXISTS aprobado BOOLEAN DEFAULT TRUE;
ALTER TABLE users ADD COLUMN IF NOT EXISTS cliente_id INTEGER REFERENCES clientes(id);

-- Asegurar que el admin existe y estÃ¡ activo
INSERT INTO users (email, nombre, is_admin, activo, aprobado, created_at)
VALUES ('santiago@satma.mx', 'Santiago Admin', TRUE, TRUE, TRUE, NOW())
ON CONFLICT (email) DO UPDATE SET 
    is_admin = TRUE, 
    activo = TRUE, 
    aprobado = TRUE;

-- Tabla de relaciÃ³n usuarios-empresas
CREATE TABLE IF NOT EXISTS user_empresas (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    cliente_id INTEGER REFERENCES clientes(id) ON DELETE CASCADE,
    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(user_id, cliente_id)
);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- VERIFICAR QUE TODO EXISTE
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SELECT 'kb_documentos' as tabla, COUNT(*) as registros FROM kb_documentos
UNION ALL
SELECT 'kb_chunks', COUNT(*) FROM kb_chunks
UNION ALL
SELECT 'users', COUNT(*) FROM users
UNION ALL
SELECT 'clientes', COUNT(*) FROM clientes;
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         PARTE 3: SERVICIO DE PROCESAMIENTO DE DOCUMENTOS (CON GEMINI)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Gemini 2.0 Flash tiene ventana de 1M tokens - PERFECTO para PDFs grandes.
El CFF de 376 pÃ¡ginas no es problema.

Crear: backend/services/document_processor.py

```python
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PROCESADOR DE DOCUMENTOS INTELIGENTE
Usa Gemini 2.0 Flash para PDFs grandes (1M tokens de contexto)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import time
import json
import hashlib
from typing import Optional, Dict, List, Tuple, Callable
from dataclasses import dataclass
from datetime import datetime

# LibrerÃ­as de PDF
try:
    import pdfplumber
    PDF_LIBRARY = 'pdfplumber'
except ImportError:
    try:
        import fitz  # PyMuPDF
        PDF_LIBRARY = 'pymupdf'
    except ImportError:
        PDF_LIBRARY = None

# APIs de IA
import google.generativeai as genai
from anthropic import Anthropic


@dataclass
class ResultadoProcesamiento:
    exito: bool
    documento_id: Optional[int]
    nombre: str
    caracteres: int
    chunks: int
    categoria: str
    tiempo_segundos: float
    error: Optional[str] = None


class DocumentProcessor:
    """Procesador de documentos con soporte para PDFs grandes"""
    
    def __init__(self):
        # Configurar Gemini (para PDFs grandes)
        self.gemini_key = os.environ.get('GOOGLE_AI_API_KEY') or os.environ.get('GEMINI_API_KEY')
        if self.gemini_key:
            genai.configure(api_key=self.gemini_key)
            self.gemini = genai.GenerativeModel('gemini-2.0-flash-exp')
            print("âœ… Gemini 2.0 Flash configurado (1M tokens)")
        else:
            self.gemini = None
            print("âš ï¸ GOOGLE_AI_API_KEY no configurada")
        
        # Configurar Anthropic (para anÃ¡lisis y respuestas)
        self.anthropic = Anthropic() if os.environ.get('ANTHROPIC_API_KEY') else None
        
        # Configurar OpenAI (para embeddings)
        self.openai_key = os.environ.get('OPENAI_API_KEY')
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰TODO PRINCIPAL: PROCESAR DOCUMENTO COMPLETO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def procesar_documento(self, 
                           file, 
                           filename: str,
                           callback_progreso: Callable = None) -> ResultadoProcesamiento:
        """
        Procesa un documento completo:
        1. Extrae texto
        2. Detecta categorÃ­a con IA
        3. Guarda en BD
        4. Crea chunks
        5. Genera embeddings (opcional)
        """
        
        inicio = time.time()
        
        try:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # PASO 1: Extraer texto
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            self._log(callback_progreso, 5, "ğŸ“– Extrayendo texto del documento...")
            
            extension = os.path.splitext(filename)[1].lower()
            
            if extension == '.pdf':
                contenido = self._extraer_pdf(file, callback_progreso)
            elif extension in {'.txt', '.md'}:
                contenido = file.read().decode('utf-8')
            elif extension == '.docx':
                contenido = self._extraer_docx(file)
            else:
                contenido = file.read().decode('utf-8', errors='ignore')
            
            if len(contenido) < 100:
                return ResultadoProcesamiento(
                    exito=False,
                    documento_id=None,
                    nombre=filename,
                    caracteres=len(contenido),
                    chunks=0,
                    categoria='',
                    tiempo_segundos=time.time() - inicio,
                    error='Documento vacÃ­o o no se pudo extraer texto'
                )
            
            self._log(callback_progreso, 30, f"âœ… ExtraÃ­dos {len(contenido):,} caracteres")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # PASO 2: Detectar categorÃ­a con IA
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            self._log(callback_progreso, 35, "ğŸ·ï¸ Detectando categorÃ­a...")
            
            categoria = self._detectar_categoria_ia(filename, contenido[:10000])
            
            self._log(callback_progreso, 40, f"âœ… CategorÃ­a: {categoria}")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # PASO 3: Guardar documento en BD
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            self._log(callback_progreso, 45, "ğŸ’¾ Guardando en base de datos...")
            
            from extensions import db
            from sqlalchemy import text
            
            # Limitar contenido a 1MB para la BD
            contenido_bd = contenido[:1000000]
            
            result = db.session.execute(text("""
                INSERT INTO kb_documentos 
                (nombre, contenido_raw, categoria, procesado, activo, created_at)
                VALUES (:nombre, :contenido, :categoria, FALSE, TRUE, NOW())
                RETURNING id
            """), {
                'nombre': filename,
                'contenido': contenido_bd,
                'categoria': categoria
            })
            db.session.commit()
            
            doc_id = result.fetchone()[0]
            
            self._log(callback_progreso, 50, f"âœ… Documento ID: {doc_id}")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # PASO 4: Crear chunks inteligentes
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            self._log(callback_progreso, 55, "ğŸ“¦ Creando chunks semÃ¡nticos...")
            
            chunks = self._crear_chunks_inteligentes(contenido, categoria)
            
            self._log(callback_progreso, 70, f"âœ… {len(chunks)} chunks creados")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # PASO 5: Guardar chunks
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            self._log(callback_progreso, 75, "ğŸ’¾ Guardando chunks...")
            
            for i, chunk_texto in enumerate(chunks):
                db.session.execute(text("""
                    INSERT INTO kb_chunks (documento_id, contenido, posicion, created_at)
                    VALUES (:doc_id, :contenido, :posicion, NOW())
                """), {
                    'doc_id': doc_id,
                    'contenido': chunk_texto,
                    'posicion': i
                })
                
                if i % 50 == 0:
                    db.session.commit()
                    progreso = 75 + int((i / len(chunks)) * 15)
                    self._log(callback_progreso, progreso, f"ğŸ’¾ Chunks {i}/{len(chunks)}...")
            
            db.session.commit()
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # PASO 6: Actualizar documento como procesado
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            db.session.execute(text("""
                UPDATE kb_documentos 
                SET procesado = TRUE, num_chunks = :num_chunks
                WHERE id = :id
            """), {'id': doc_id, 'num_chunks': len(chunks)})
            db.session.commit()
            
            self._log(callback_progreso, 95, "âœ… Documento procesado")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # PASO 7: Generar embeddings en background (opcional)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if self.openai_key:
                self._log(callback_progreso, 97, "ğŸ§  Generando embeddings...")
                self._generar_embeddings_async(doc_id)
            
            self._log(callback_progreso, 100, "ğŸ‰ Â¡Completado!")
            
            return ResultadoProcesamiento(
                exito=True,
                documento_id=doc_id,
                nombre=filename,
                caracteres=len(contenido),
                chunks=len(chunks),
                categoria=categoria,
                tiempo_segundos=time.time() - inicio
            )
            
        except Exception as e:
            import traceback
            error = traceback.format_exc()
            print(f"âŒ ERROR procesando documento:\n{error}")
            
            return ResultadoProcesamiento(
                exito=False,
                documento_id=None,
                nombre=filename,
                caracteres=0,
                chunks=0,
                categoria='',
                tiempo_segundos=time.time() - inicio,
                error=str(e)
            )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # EXTRACCIÃ“N DE PDF
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _extraer_pdf(self, file, callback=None) -> str:
        """Extrae texto de PDF con la mejor librerÃ­a disponible"""
        
        if PDF_LIBRARY == 'pdfplumber':
            return self._extraer_pdf_pdfplumber(file, callback)
        elif PDF_LIBRARY == 'pymupdf':
            return self._extraer_pdf_pymupdf(file, callback)
        else:
            raise Exception("No hay librerÃ­a de PDF instalada. Ejecuta: pip install pdfplumber")
    
    def _extraer_pdf_pdfplumber(self, file, callback=None) -> str:
        """Extrae con pdfplumber (mejor para tablas)"""
        import pdfplumber
        
        textos = []
        
        with pdfplumber.open(file) as pdf:
            total = len(pdf.pages)
            print(f"ğŸ“„ PDF: {total} pÃ¡ginas")
            
            for i, page in enumerate(pdf.pages):
                try:
                    texto = page.extract_text() or ''
                    textos.append(texto)
                    
                    # Progreso cada 20 pÃ¡ginas
                    if i % 20 == 0 and callback:
                        progreso = 5 + int((i / total) * 25)
                        self._log(callback, progreso, f"ğŸ“– PÃ¡gina {i}/{total}...")
                        
                except Exception as e:
                    print(f"âš ï¸ Error pÃ¡gina {i}: {e}")
                    continue
        
        return '\n\n'.join(textos)
    
    def _extraer_pdf_pymupdf(self, file, callback=None) -> str:
        """Extrae con PyMuPDF (mÃ¡s rÃ¡pido)"""
        import fitz
        
        file.seek(0)
        pdf_bytes = file.read()
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        
        textos = []
        total = len(doc)
        print(f"ğŸ“„ PDF: {total} pÃ¡ginas")
        
        for i, page in enumerate(doc):
            try:
                texto = page.get_text()
                textos.append(texto)
                
                if i % 20 == 0 and callback:
                    progreso = 5 + int((i / total) * 25)
                    self._log(callback, progreso, f"ğŸ“– PÃ¡gina {i}/{total}...")
                    
            except Exception as e:
                print(f"âš ï¸ Error pÃ¡gina {i}: {e}")
                continue
        
        return '\n\n'.join(textos)
    
    def _extraer_docx(self, file) -> str:
        """Extrae texto de DOCX"""
        from docx import Document
        
        doc = Document(file)
        textos = []
        
        for para in doc.paragraphs:
            if para.text.strip():
                textos.append(para.text)
        
        return '\n\n'.join(textos)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DETECCIÃ“N DE CATEGORÃA CON IA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _detectar_categoria_ia(self, filename: str, contenido_muestra: str) -> str:
        """Usa Gemini o Claude para detectar categorÃ­a"""
        
        categorias = [
            "Marco Legal",
            "Jurisprudencias", 
            "Criterios SAT",
            "CatÃ¡logos SAT",
            "Casos de Referencia",
            "Glosarios",
            "Plantillas"
        ]
        
        prompt = f"""Analiza este documento y clasifÃ­calo en UNA de estas categorÃ­as:
{', '.join(categorias)}

Nombre del archivo: {filename}

Primeros 5000 caracteres del contenido:
{contenido_muestra[:5000]}

Responde SOLO con el nombre de la categorÃ­a, nada mÃ¡s."""

        try:
            if self.gemini:
                response = self.gemini.generate_content(prompt)
                categoria = response.text.strip()
            elif self.anthropic:
                response = self.anthropic.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=50,
                    messages=[{"role": "user", "content": prompt}]
                )
                categoria = response.content[0].text.strip()
            else:
                # Fallback sin IA
                return self._detectar_categoria_simple(filename, contenido_muestra)
            
            # Validar que sea una categorÃ­a vÃ¡lida
            for cat in categorias:
                if cat.lower() in categoria.lower():
                    return cat
            
            return "Casos de Referencia"
            
        except Exception as e:
            print(f"âš ï¸ Error detectando categorÃ­a: {e}")
            return self._detectar_categoria_simple(filename, contenido_muestra)
    
    def _detectar_categoria_simple(self, filename: str, contenido: str) -> str:
        """DetecciÃ³n simple por palabras clave"""
        
        nombre = filename.lower()
        texto = contenido.lower()
        
        if 'cff' in nombre or 'cÃ³digo fiscal' in texto or 'codigo fiscal' in texto:
            return 'Marco Legal'
        elif 'lisr' in nombre or 'impuesto sobre la renta' in texto:
            return 'Marco Legal'
        elif 'liva' in nombre or 'valor agregado' in texto:
            return 'Marco Legal'
        elif 'rmf' in nombre or 'miscelÃ¡nea' in texto:
            return 'Criterios SAT'
        elif 'jurisprudencia' in texto or 'tesis' in texto:
            return 'Jurisprudencias'
        elif 'catÃ¡logo' in nombre or 'catalogo' in nombre:
            return 'CatÃ¡logos SAT'
        elif 'glosario' in nombre:
            return 'Glosarios'
        elif 'plantilla' in nombre or 'template' in nombre:
            return 'Plantillas'
        else:
            return 'Casos de Referencia'
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CHUNKING INTELIGENTE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _crear_chunks_inteligentes(self, contenido: str, categoria: str) -> List[str]:
        """Crea chunks respetando estructura del documento"""
        
        # ConfiguraciÃ³n segÃºn tipo de documento
        if categoria == 'Marco Legal':
            # Leyes: chunks por artÃ­culo
            return self._chunk_por_articulos(contenido)
        elif categoria == 'Jurisprudencias':
            # Jurisprudencias: chunks mÃ¡s grandes
            return self._chunk_por_tamano(contenido, tamano=2000, overlap=200)
        else:
            # Default: chunks estÃ¡ndar
            return self._chunk_por_tamano(contenido, tamano=1000, overlap=100)
    
    def _chunk_por_articulos(self, contenido: str) -> List[str]:
        """Divide por artÃ­culos (para leyes)"""
        import re
        
        # Buscar patrones de artÃ­culos
        patron = r'(ArtÃ­culo\s+\d+[\w\-]*\.?)'
        
        partes = re.split(patron, contenido, flags=re.IGNORECASE)
        
        chunks = []
        chunk_actual = ""
        
        for i, parte in enumerate(partes):
            if re.match(patron, parte, re.IGNORECASE):
                # Es inicio de artÃ­culo
                if chunk_actual and len(chunk_actual) > 100:
                    chunks.append(chunk_actual.strip())
                chunk_actual = parte
            else:
                chunk_actual += parte
                
                # Si el chunk es muy grande, dividirlo
                if len(chunk_actual) > 3000:
                    chunks.append(chunk_actual.strip())
                    chunk_actual = ""
        
        # Ãšltimo chunk
        if chunk_actual and len(chunk_actual) > 100:
            chunks.append(chunk_actual.strip())
        
        # Si no encontrÃ³ artÃ­culos, usar mÃ©todo estÃ¡ndar
        if len(chunks) < 3:
            return self._chunk_por_tamano(contenido, 1500, 150)
        
        return chunks
    
    def _chunk_por_tamano(self, contenido: str, tamano: int = 1000, overlap: int = 100) -> List[str]:
        """Divide por tamaÃ±o con overlap"""
        
        if len(contenido) <= tamano:
            return [contenido]
        
        chunks = []
        inicio = 0
        
        while inicio < len(contenido):
            fin = inicio + tamano
            chunk = contenido[inicio:fin]
            
            # Intentar cortar en punto natural
            if fin < len(contenido):
                # Buscar mejor punto de corte
                puntos_corte = [
                    chunk.rfind('\n\n'),  # PÃ¡rrafo
                    chunk.rfind('.\n'),    # Fin de oraciÃ³n con newline
                    chunk.rfind('. '),     # Fin de oraciÃ³n
                    chunk.rfind('\n'),     # Newline
                ]
                
                mejor_corte = max(puntos_corte)
                if mejor_corte > tamano * 0.5:
                    chunk = chunk[:mejor_corte + 1]
                    fin = inicio + mejor_corte + 1
            
            chunk = chunk.strip()
            if len(chunk) > 50:
                chunks.append(chunk)
            
            inicio = fin - overlap
        
        return chunks
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # EMBEDDINGS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _generar_embeddings_async(self, documento_id: int):
        """Genera embeddings para los chunks de un documento"""
        
        if not self.openai_key:
            print("âš ï¸ OPENAI_API_KEY no configurada, saltando embeddings")
            return
        
        try:
            import openai
            from extensions import db
            from sqlalchemy import text
            
            client = openai.OpenAI()
            
            # Obtener chunks sin embedding
            chunks = db.session.execute(text("""
                SELECT id, contenido FROM kb_chunks 
                WHERE documento_id = :doc_id AND embedding IS NULL
            """), {'doc_id': documento_id}).fetchall()
            
            print(f"ğŸ§  Generando embeddings para {len(chunks)} chunks...")
            
            for i, (chunk_id, contenido) in enumerate(chunks):
                try:
                    response = client.embeddings.create(
                        model="text-embedding-3-small",
                        input=contenido[:8000]  # Limitar tokens
                    )
                    
                    embedding = response.data[0].embedding
                    
                    # Guardar embedding
                    db.session.execute(text("""
                        UPDATE kb_chunks SET embedding = :embedding WHERE id = :id
                    """), {
                        'id': chunk_id,
                        'embedding': str(embedding)
                    })
                    
                    if i % 20 == 0:
                        db.session.commit()
                        print(f"   ğŸ§  {i}/{len(chunks)} embeddings...")
                        
                except Exception as e:
                    print(f"   âš ï¸ Error embedding chunk {chunk_id}: {e}")
                    continue
            
            db.session.commit()
            print(f"âœ… Embeddings completados")
            
        except Exception as e:
            print(f"âŒ Error generando embeddings: {e}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ANÃLISIS CON GEMINI (PARA PDFS GRANDES)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def analizar_documento_gemini(self, contenido: str, pregunta: str) -> str:
        """
        Usa Gemini 2.0 Flash para analizar documentos grandes.
        Ventana de 1M tokens = ~750,000 palabras = PDFs de 1000+ pÃ¡ginas
        """
        
        if not self.gemini:
            raise Exception("Gemini no configurado. Agrega GOOGLE_AI_API_KEY")
        
        prompt = f"""Eres un experto en derecho fiscal mexicano. 
Analiza el siguiente documento y responde la pregunta.

DOCUMENTO:
{contenido}

PREGUNTA: {pregunta}

Responde de forma clara, citando artÃ­culos o secciones especÃ­ficas cuando sea relevante."""

        try:
            response = self.gemini.generate_content(prompt)
            return response.text
            
        except Exception as e:
            print(f"âŒ Error Gemini: {e}")
            raise
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # UTILIDADES
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _log(self, callback, progreso: int, mensaje: str):
        """Log con callback opcional"""
        print(f"  [{progreso:3d}%] {mensaje}")
        if callback:
            callback(progreso, mensaje)


# Instancia global
doc_processor = DocumentProcessor()
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              PARTE 4: RUTAS DE BIBLIOTECA (REEMPLAZAR COMPLETO)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Crear/Reemplazar: backend/routes/biblioteca_routes.py

```python
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RUTAS DE BIBLIOTECAR.IA
Chat + Upload + RAG
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
from flask import Blueprint, jsonify, request
from werkzeug.utils import secure_filename

biblioteca_bp = Blueprint('biblioteca', __name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CHAT PRINCIPAL (CON SOPORTE DE ARCHIVOS)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@biblioteca_bp.route('/chat', methods=['POST'])
def chat_biblioteca():
    """Endpoint principal de chat - soporta mensajes y archivos"""
    
    print("\n" + "="*60)
    print("ğŸ“š BIBLIOTECAR.IA - Request recibido")
    print(f"   Content-Type: {request.content_type}")
    print("="*60)
    
    try:
        # Detectar si es archivo o mensaje
        if request.content_type and 'multipart' in request.content_type:
            return _procesar_archivo()
        else:
            return _procesar_chat()
            
    except Exception as e:
        import traceback
        print(f"âŒ ERROR:\n{traceback.format_exc()}")
        return jsonify({
            'success': False,
            'response': f'âŒ Error: {str(e)}'
        }), 500


def _procesar_archivo():
    """Procesa upload de archivo"""
    from services.document_processor import doc_processor
    
    file = request.files.get('file')
    if not file or file.filename == '':
        return jsonify({
            'success': False,
            'response': 'âŒ No se recibiÃ³ archivo'
        }), 400
    
    filename = secure_filename(file.filename)
    print(f"ğŸ“ Procesando: {filename}")
    
    # Procesar documento
    resultado = doc_processor.procesar_documento(file, filename)
    
    if resultado.exito:
        return jsonify({
            'success': True,
            'response': f'''âœ… **Documento "{resultado.nombre}" procesado exitosamente**

ğŸ“„ **Detalles:**
â€¢ ID: {resultado.documento_id}
â€¢ CategorÃ­a: {resultado.categoria}
â€¢ Caracteres: {resultado.caracteres:,}
â€¢ Chunks creados: {resultado.chunks}
â€¢ Tiempo: {resultado.tiempo_segundos:.1f}s

El documento ya estÃ¡ disponible para consultas.'''
        })
    else:
        return jsonify({
            'success': False,
            'response': f'âŒ Error procesando "{resultado.nombre}":\n\n{resultado.error}'
        }), 500


def _procesar_chat():
    """Procesa mensaje de chat con RAG"""
    from anthropic import Anthropic
    from extensions import db
    from sqlalchemy import text
    
    data = request.get_json(force=True, silent=True) or {}
    mensaje = data.get('message', '').strip()
    
    if not mensaje:
        return jsonify({
            'success': True,
            'response': 'Â¡Hola! Soy Bibliotecar.IA ğŸ“š Â¿En quÃ© puedo ayudarte?'
        })
    
    print(f"ğŸ’¬ Mensaje: {mensaje[:100]}...")
    
    # Buscar chunks relevantes
    chunks = _buscar_chunks_relevantes(mensaje)
    
    # Construir contexto
    contexto = ""
    fuentes = []
    
    if chunks:
        contexto = "\n\nğŸ“š CONTEXTO DE LA BASE DE CONOCIMIENTO:\n"
        for chunk in chunks[:5]:
            contexto += f"\n[Documento: {chunk['documento']}]\n{chunk['contenido'][:800]}\n"
            if chunk['documento'] not in fuentes:
                fuentes.append(chunk['documento'])
    
    # Generar respuesta con Claude
    client = Anthropic()
    
    system_prompt = f"""Eres Bibliotecar.IA, la bibliotecaria experta en derecho fiscal mexicano de Revisar.IA.

Tu rol es:
- Mantener actualizada la base de conocimiento
- Responder consultas sobre legislaciÃ³n fiscal
- Ayudar a encontrar informaciÃ³n especÃ­fica
{contexto}

Responde de forma clara y profesional en espaÃ±ol.
Si usas informaciÃ³n del contexto, menciona la fuente."""

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2000,
        system=system_prompt,
        messages=[{"role": "user", "content": mensaje}]
    )
    
    respuesta = response.content[0].text
    
    # Agregar fuentes si las hay
    if fuentes:
        respuesta += f"\n\nğŸ“– *Fuentes consultadas: {', '.join(fuentes)}*"
    
    return jsonify({
        'success': True,
        'response': respuesta
    })


def _buscar_chunks_relevantes(query: str, limite: int = 5) -> list:
    """BÃºsqueda semÃ¡ntica de chunks relevantes"""
    from extensions import db
    from sqlalchemy import text
    
    try:
        # BÃºsqueda por palabras clave (fallback sin embeddings)
        palabras = [p for p in query.lower().split() if len(p) > 3][:5]
        
        if not palabras:
            return []
        
        condiciones = ' OR '.join([f"LOWER(c.contenido) LIKE '%{p}%'" for p in palabras])
        
        result = db.session.execute(text(f"""
            SELECT c.id, c.contenido, c.documento_id, d.nombre as documento
            FROM kb_chunks c
            JOIN kb_documentos d ON c.documento_id = d.id
            WHERE ({condiciones})
            AND d.activo = TRUE
            LIMIT :limite
        """), {'limite': limite})
        
        return [dict(row._mapping) for row in result]
        
    except Exception as e:
        print(f"âš ï¸ Error buscando chunks: {e}")
        return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ESTADÃSTICAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@biblioteca_bp.route('/stats', methods=['GET'])
def stats_biblioteca():
    """EstadÃ­sticas del knowledge base"""
    from extensions import db
    from sqlalchemy import text
    
    try:
        # Totales
        docs = db.session.execute(text(
            "SELECT COUNT(*) FROM kb_documentos WHERE activo = TRUE"
        )).scalar() or 0
        
        chunks = db.session.execute(text(
            "SELECT COUNT(*) FROM kb_chunks"
        )).scalar() or 0
        
        embeddings = db.session.execute(text(
            "SELECT COUNT(*) FROM kb_chunks WHERE embedding IS NOT NULL"
        )).scalar() or 0
        
        # Por categorÃ­a
        categorias = db.session.execute(text("""
            SELECT categoria, COUNT(*) as total
            FROM kb_documentos
            WHERE activo = TRUE
            GROUP BY categoria
        """)).fetchall()
        
        categorias_dict = {row.categoria: row.total for row in categorias}
        
        return jsonify({
            'success': True,
            'documentos': docs,
            'chunks': chunks,
            'embeddings': embeddings,
            'porcentaje_embeddings': round((embeddings / chunks) * 100) if chunks > 0 else 0,
            'categorias': categorias_dict
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ESTADO DEL ACERVO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@biblioteca_bp.route('/acervo/estado', methods=['GET'])
def estado_acervo():
    """Estado detallado del acervo por agente/categorÃ­a"""
    from extensions import db
    from sqlalchemy import text
    
    try:
        # Agentes y sus categorÃ­as asignadas
        agentes = {
            'A1': {'nombre': 'Facturar.IA', 'categorias': ['CatÃ¡logos SAT', 'Criterios SAT']},
            'A2': {'nombre': 'Bibliotecar.IA', 'categorias': ['Marco Legal', 'Jurisprudencias']},
            'A3': {'nombre': 'Revisar.IA', 'categorias': ['Casos de Referencia']},
            'A4': {'nombre': 'Investigar.IA', 'categorias': ['Glosarios']},
            'A5': {'nombre': 'Analizar.IA', 'categorias': ['Plantillas']},
            'A6': {'nombre': 'Reportar.IA', 'categorias': []},
            'A7': {'nombre': 'Auditar.IA', 'categorias': []},
        }
        
        # Contar documentos por categorÃ­a
        categorias = db.session.execute(text("""
            SELECT categoria, COUNT(*) as docs, SUM(num_chunks) as chunks
            FROM kb_documentos
            WHERE activo = TRUE
            GROUP BY categoria
        """)).fetchall()
        
        cat_stats = {row.categoria: {'docs': row.docs, 'chunks': row.chunks or 0} for row in categorias}
        
        # Calcular progreso por agente
        resultado_agentes = {}
        for agente_id, info in agentes.items():
            docs_agente = sum(cat_stats.get(c, {}).get('docs', 0) for c in info['categorias'])
            chunks_agente = sum(cat_stats.get(c, {}).get('chunks', 0) for c in info['categorias'])
            
            # Progreso estimado (meta: 10 docs por categorÃ­a)
            meta = len(info['categorias']) * 10
            progreso = min(100, round((docs_agente / meta) * 100)) if meta > 0 else 0
            
            resultado_agentes[agente_id] = {
                'nombre': info['nombre'],
                'categorias': info['categorias'],
                'documentos': docs_agente,
                'chunks': chunks_agente,
                'progreso': progreso
            }
        
        # Total general
        total_docs = db.session.execute(text(
            "SELECT COUNT(*) FROM kb_documentos WHERE activo = TRUE"
        )).scalar() or 0
        
        total_chunks = db.session.execute(text(
            "SELECT COUNT(*) FROM kb_chunks"
        )).scalar() or 0
        
        return jsonify({
            'success': True,
            'total_documentos': total_docs,
            'total_chunks': total_chunks,
            'agentes': resultado_agentes,
            'categorias': cat_stats
        })
        
    except Exception as e:
        import traceback
        print(traceback.format_exc())
        return jsonify({'success': False, 'error': str(e)}), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LISTAR DOCUMENTOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@biblioteca_bp.route('/documentos', methods=['GET'])
def listar_documentos():
    """Lista todos los documentos"""
    from extensions import db
    from sqlalchemy import text
    
    try:
        categoria = request.args.get('categoria')
        
        query = """
            SELECT id, nombre, categoria, procesado, num_chunks, created_at
            FROM kb_documentos
            WHERE activo = TRUE
        """
        
        params = {}
        if categoria:
            query += " AND categoria = :categoria"
            params['categoria'] = categoria
        
        query += " ORDER BY created_at DESC"
        
        result = db.session.execute(text(query), params)
        
        documentos = [{
            'id': row.id,
            'nombre': row.nombre,
            'categoria': row.categoria,
            'procesado': row.procesado,
            'chunks': row.num_chunks or 0,
            'created_at': row.created_at.isoformat() if row.created_at else None
        } for row in result]
        
        return jsonify({
            'success': True,
            'documentos': documentos,
            'total': len(documentos)
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                   PARTE 5: RUTAS DE ADMIN (USUARIOS)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Crear/Reemplazar: backend/routes/admin_routes.py

```python
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RUTAS DE ADMINISTRACIÃ“N
GestiÃ³n de usuarios, empresas y permisos
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

from flask import Blueprint, jsonify, request
from extensions import db
from sqlalchemy import text

admin_bp = Blueprint('admin', __name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# USUARIOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@admin_bp.route('/usuarios', methods=['GET'])
def listar_usuarios():
    """Lista todos los usuarios"""
    try:
        result = db.session.execute(text("""
            SELECT 
                u.id, u.email, u.nombre, u.is_admin, u.activo, u.aprobado, u.created_at,
                c.nombre as empresa
            FROM users u
            LEFT JOIN clientes c ON u.cliente_id = c.id
            ORDER BY u.created_at DESC
        """))
        
        usuarios = [{
            'id': row.id,
            'email': row.email,
            'nombre': row.nombre,
            'is_admin': row.is_admin,
            'activo': row.activo,
            'aprobado': row.aprobado,
            'empresa': row.empresa,
            'created_at': row.created_at.isoformat() if row.created_at else None
        } for row in result]
        
        return jsonify({
            'success': True,
            'usuarios': usuarios,
            'total': len(usuarios)
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@admin_bp.route('/usuarios/pendientes', methods=['GET'])
def usuarios_pendientes():
    """Lista usuarios pendientes de aprobaciÃ³n"""
    try:
        result = db.session.execute(text("""
            SELECT u.id, u.email, u.nombre, u.created_at, c.nombre as empresa
            FROM users u
            LEFT JOIN clientes c ON u.cliente_id = c.id
            WHERE u.aprobado = FALSE OR u.aprobado IS NULL
            ORDER BY u.created_at DESC
        """))
        
        pendientes = [{
            'id': row.id,
            'email': row.email,
            'nombre': row.nombre,
            'empresa': row.empresa,
            'created_at': row.created_at.isoformat() if row.created_at else None
        } for row in result]
        
        return jsonify({
            'success': True,
            'pendientes': pendientes,
            'total': len(pendientes)
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@admin_bp.route('/usuarios/<int:user_id>/aprobar', methods=['POST'])
def aprobar_usuario(user_id):
    """Aprueba un usuario"""
    try:
        db.session.execute(text(
            "UPDATE users SET aprobado = TRUE, activo = TRUE WHERE id = :id"
        ), {'id': user_id})
        db.session.commit()
        
        return jsonify({'success': True, 'message': f'Usuario {user_id} aprobado'})
        
    except Exception as e:
        db.session.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500


@admin_bp.route('/usuarios/<int:user_id>/rol', methods=['PUT'])
def cambiar_rol(user_id):
    """Cambia rol de usuario"""
    try:
        data = request.get_json(force=True, silent=True) or {}
        is_admin = data.get('is_admin', False)
        
        db.session.execute(text(
            "UPDATE users SET is_admin = :is_admin WHERE id = :id"
        ), {'id': user_id, 'is_admin': is_admin})
        db.session.commit()
        
        return jsonify({'success': True})
        
    except Exception as e:
        db.session.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EMPRESAS/CLIENTES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@admin_bp.route('/empresas', methods=['GET'])
def listar_empresas():
    """Lista todas las empresas"""
    try:
        result = db.session.execute(text("""
            SELECT c.id, c.nombre, c.razon_social, c.rfc, c.activo, c.created_at,
                   COUNT(DISTINCT u.id) as usuarios
            FROM clientes c
            LEFT JOIN users u ON u.cliente_id = c.id
            GROUP BY c.id
            ORDER BY c.nombre
        """))
        
        empresas = [{
            'id': row.id,
            'nombre': row.nombre,
            'razon_social': row.razon_social,
            'rfc': row.rfc,
            'activo': row.activo,
            'usuarios': row.usuarios,
            'created_at': row.created_at.isoformat() if row.created_at else None
        } for row in result]
        
        return jsonify({
            'success': True,
            'empresas': empresas,
            'total': len(empresas)
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                     PARTE 6: REGISTRAR BLUEPRINTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

En backend/main.py o backend/app.py, asegurar que estÃ©n registrados:

```python
# Imports
from routes.biblioteca_routes import biblioteca_bp
from routes.admin_routes import admin_bp

# Registrar blueprints
app.register_blueprint(biblioteca_bp, url_prefix='/api/biblioteca')
app.register_blueprint(admin_bp, url_prefix='/api/admin')
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    PARTE 7: VARIABLES DE ENTORNO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

En Replit Secrets, asegurar que existan:

```
ANTHROPIC_API_KEY = sk-ant-...        # Para Claude (chat)
OPENAI_API_KEY = sk-...               # Para embeddings
GOOGLE_AI_API_KEY = ...               # Para Gemini (PDFs grandes) â­ NUEVO
DATABASE_URL = postgresql://...       # Base de datos
```

Para obtener GOOGLE_AI_API_KEY:
1. Ir a https://makersuite.google.com/app/apikey
2. Crear API Key
3. Es GRATIS y tiene 1M tokens de contexto

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                       PARTE 8: PRUEBAS OBLIGATORIAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ejecutar TODAS estas pruebas y mostrar resultados:

```bash
echo "
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ§ª PRUEBAS DEL SISTEMA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"

# Test 1: Health check
echo "=== TEST 1: Health Check ===" && \
curl -s http://localhost:5000/api/health && echo ""

# Test 2: Stats biblioteca
echo "=== TEST 2: Stats Biblioteca ===" && \
curl -s http://localhost:5000/api/biblioteca/stats && echo ""

# Test 3: Listar usuarios
echo "=== TEST 3: Admin Usuarios ===" && \
curl -s http://localhost:5000/api/admin/usuarios && echo ""

# Test 4: Subir documento de prueba
echo "=== TEST 4: Upload Documento ===" && \
echo "Documento de prueba para Revisar.IA
CÃ³digo Fiscal de la FederaciÃ³n - Extracto
ArtÃ­culo 1. Las personas estÃ¡n obligadas a contribuir.
ArtÃ­culo 2. Las contribuciones se clasifican en impuestos." > /tmp/test_doc.txt && \
curl -X POST http://localhost:5000/api/biblioteca/chat \
  -F "file=@/tmp/test_doc.txt" && echo ""

# Test 5: Verificar que se guardÃ³
echo "=== TEST 5: Verificar BD ===" && \
psql $DATABASE_URL -c "SELECT id, nombre, categoria, num_chunks FROM kb_documentos ORDER BY id DESC LIMIT 3;"

# Test 6: Verificar chunks
echo "=== TEST 6: Verificar Chunks ===" && \
psql $DATABASE_URL -c "SELECT COUNT(*) as total_chunks FROM kb_chunks;"

# Test 7: Chat con RAG
echo "=== TEST 7: Chat RAG ===" && \
curl -X POST http://localhost:5000/api/biblioteca/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Â¿QuÃ© dice el artÃ­culo 1?"}' && echo ""

echo "
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š RESUMEN
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      PARTE 9: CHECKLIST FINAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â–¡ pip install pdfplumber PyMuPDF python-docx google-generativeai
â–¡ Ejecutar SQL para crear/verificar tablas
â–¡ Asegurar usuario admin existe en BD
â–¡ Crear backend/services/document_processor.py
â–¡ Crear/Reemplazar backend/routes/biblioteca_routes.py
â–¡ Crear/Reemplazar backend/routes/admin_routes.py
â–¡ Registrar blueprints en main.py
â–¡ Agregar GOOGLE_AI_API_KEY a Secrets (para PDFs grandes)
â–¡ Reiniciar servidor
â–¡ Ejecutar TODAS las pruebas
â–¡ Verificar que upload guarda en BD (documentos > 0)
â–¡ Verificar que chunks se crean (chunks > 0)
â–¡ Verificar que admin muestra usuarios
â–¡ Probar con PDF real (CFF.pdf)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        RESULTADO ESPERADO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DespuÃ©s de implementar TODO:

1. âœ… Subir CFF.pdf â†’ Se procesa con progreso visible
2. âœ… Sidebar muestra: X Documentos, Y Chunks
3. âœ… Chat responde usando contenido del CFF
4. âœ… Panel Admin muestra santiago@satma.mx como admin
5. âœ… Formulario de entregables funciona

Para PDFs de 300+ pÃ¡ginas: Gemini 2.0 Flash los procesa sin problema
(1M tokens = ~750,000 palabras = PDFs enormes)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                     Â¡Ã‰XITO = TODOS LOS TESTS PASAN!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
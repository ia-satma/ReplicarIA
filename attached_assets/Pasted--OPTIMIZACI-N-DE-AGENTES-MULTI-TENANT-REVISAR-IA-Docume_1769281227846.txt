# ğŸ¤– OPTIMIZACIÃ“N DE AGENTES MULTI-TENANT - REVISAR.IA

## Documento de ImplementaciÃ³n para Replit

**VersiÃ³n:** 1.0  
**Fecha:** Enero 2026  
**Sistema:** Plataforma SaaS de AuditorÃ­a Fiscal con 10 Agentes IA Especializados  

---

## 1. RESUMEN EJECUTIVO

REVISAR.IA es una plataforma multi-tenant de auditorÃ­a fiscal que utiliza 10 agentes IA especializados para analizar documentos, evaluar riesgos fiscales y generar expedientes de defensa. El sistema actual presenta mÃ©tricas excepcionales de latencia (API P50: 12.98ms, DB P50: 0.38ms) pero requiere optimizaciÃ³n en: profundidad de anÃ¡lisis de agentes, comunicaciÃ³n inter-agentes, aislamiento de conocimiento por tenant, y calidad de reportes generados. Este documento proporciona la arquitectura objetivo, implementaciÃ³n paso a paso, y scripts de diagnÃ³stico para ejecutar en Replit.

---

## 2. ARTEFACTOS Y ACCESOS NECESARIOS

### 2.1 Lista Priorizada de Artefactos

| Prioridad | Artefacto | Estado | Uso |
|-----------|-----------|--------|-----|
| ğŸ”´ P0 | DATABASE_URL (Neon PostgreSQL) | âœ… Disponible | ConexiÃ³n a DB |
| ğŸ”´ P0 | ANTHROPIC_API_KEY | âœ… Disponible | Llamadas a Claude |
| ğŸŸ¡ P1 | REDIS_URL (Upstash) | âš ï¸ Opcional | Cache y mensajerÃ­a |
| ğŸŸ¡ P1 | OPENAI_API_KEY | âš ï¸ Opcional | Embeddings |
| ğŸŸ¢ P2 | Logs de agentes | ğŸ“‹ A implementar | Observabilidad |
| ğŸŸ¢ P2 | MÃ©tricas Prometheus | ğŸ“‹ A implementar | Monitoreo |

### 2.2 InformaciÃ³n del Sistema Actual (Detectada)

```
Stack Confirmado:
â”œâ”€â”€ Backend: FastAPI + Python 3.11 + Uvicorn
â”œâ”€â”€ Frontend: React 19 + Tailwind CSS
â”œâ”€â”€ Base de Datos: PostgreSQL 15+ (Neon) + pgvector
â”œâ”€â”€ Agentes: 10 agentes especializados (Claude Sonnet)
â”œâ”€â”€ Embeddings: OpenAI text-embedding-3-small / Replit AI
â”œâ”€â”€ Cache: Redis (Upstash) - opcional
â”œâ”€â”€ Almacenamiento: pCloud
â””â”€â”€ Deployment: Replit

MÃ©tricas Actuales:
â”œâ”€â”€ API Latencia P50: 12.98ms âœ…
â”œâ”€â”€ API Latencia P95: 23.73ms âœ…
â”œâ”€â”€ DB Latencia P50: 0.38ms âœ…
â”œâ”€â”€ DB Latencia P95: 1.91ms âœ…
â”œâ”€â”€ Tablas PostgreSQL: 55
â”œâ”€â”€ Ãndices: 193
â”œâ”€â”€ Routers FastAPI: 64
â””â”€â”€ Componentes React: 91
```

---

## 3. EVALUACIÃ“N DE RIESGOS Y COMPATIBILIDAD

### 3.1 Riesgos Identificados

| Riesgo | Severidad | MitigaciÃ³n |
|--------|-----------|------------|
| ContaminaciÃ³n de contexto entre tenants | ğŸ”´ Alta | Namespace estricto por empresa_id |
| Latencia en comunicaciÃ³n inter-agentes | ğŸŸ¡ Media | Redis Pub/Sub + timeout configurable |
| PÃ©rdida de contexto en conversaciones largas | ğŸŸ¡ Media | Summarization + sliding window |
| Calidad inconsistente de reportes | ğŸŸ¡ Media | Templates estructurados + validaciÃ³n |
| Sobrecarga de tokens Claude | ğŸŸ¡ Media | RAG optimizado + cache de respuestas |

### 3.2 Compatibilidad con Plataforma Actual

| Componente | Compatibilidad | Notas |
|------------|----------------|-------|
| Endpoints existentes | âœ… 100% | Sin cambios breaking |
| Estructura de DB | âœ… 100% | Nuevas tablas, no modificaciones |
| Frontend | âœ… 100% | Solo nuevos endpoints |
| AutenticaciÃ³n | âœ… 100% | Mismo sistema JWT |
| Rate Limiting | âœ… 100% | Ya implementado |

---

## 4. RECOMENDACIÃ“N TECNOLÃ“GICA POR CAPA

### 4.1 Capa de IngestiÃ³n de Documentos

**RecomendaciÃ³n: FastAPI + Background Workers**

| Aspecto | Detalle |
|---------|---------|
| DescripciÃ³n | Procesamiento asÃ­ncrono de documentos con chunking inteligente |
| JustificaciÃ³n | Ya integrado en el stack, bajo overhead |
| Pros | Sin dependencias nuevas, control total |
| Contras | Escalabilidad limitada vs Celery |
| Latencia | <500ms por documento pequeÃ±o |
| Costo | $0 (incluido) |

### 4.2 Capa de Vector Database

**RecomendaciÃ³n: pgvector (PostgreSQL)**

| Aspecto | Detalle |
|---------|---------|
| DescripciÃ³n | ExtensiÃ³n de vectores integrada en PostgreSQL |
| JustificaciÃ³n | Ya instalado, aislamiento por empresa_id nativo |
| Pros | Sin infraestructura adicional, SQL familiar |
| Contras | Menos optimizado que Pinecone para >1M vectores |
| Latencia | <10ms para 100K vectores |
| Costo | $0 (incluido en Neon) |

**Alternativa: Pinecone Serverless**
- Mejor para >1M vectores por tenant
- Costo: ~$70/mes por 1M vectores

### 4.3 Capa de Embeddings

**RecomendaciÃ³n: OpenAI text-embedding-3-small**

| Aspecto | Detalle |
|---------|---------|
| DescripciÃ³n | Modelo de embeddings de 1536 dimensiones |
| JustificaciÃ³n | Balance calidad/costo, compatible con pgvector |
| Pros | Alta calidad semÃ¡ntica, API estable |
| Contras | Dependencia externa, costo por token |
| Latencia | ~200ms por batch de 20 chunks |
| Costo | $0.02 por 1M tokens |

### 4.4 Capa de LLM (Agentes)

**RecomendaciÃ³n: Claude Sonnet 4 (via Anthropic API)**

| Aspecto | Detalle |
|---------|---------|
| DescripciÃ³n | Modelo de lenguaje para razonamiento de agentes |
| JustificaciÃ³n | Ya integrado, excelente para anÃ¡lisis fiscal |
| Pros | Contexto largo (200K), razonamiento superior |
| Contras | Costo por token, latencia 2-5s |
| Latencia | 2-5s por respuesta |
| Costo | $3/1M input, $15/1M output |

### 4.5 Capa de MensajerÃ­a Inter-Agentes

**RecomendaciÃ³n: Redis Pub/Sub (Upstash)**

| Aspecto | Detalle |
|---------|---------|
| DescripciÃ³n | MensajerÃ­a en tiempo real entre agentes |
| JustificaciÃ³n | Bajo costo, serverless, ya configurado |
| Pros | <10ms latencia, sin mantenimiento |
| Contras | Sin persistencia de mensajes |
| Latencia | <10ms |
| Costo | ~$10/mes (free tier disponible) |

**Alternativa: PostgreSQL NOTIFY/LISTEN**
- Sin costo adicional
- Mayor latencia (~50ms)

### 4.6 Capa de OrquestaciÃ³n de Agentes

**RecomendaciÃ³n: Sistema de DeliberaciÃ³n Propio**

| Aspecto | Detalle |
|---------|---------|
| DescripciÃ³n | Orquestador que coordina los 10 agentes especializados |
| JustificaciÃ³n | Control total, optimizado para flujo POE |
| Pros | Sin dependencias, adaptado al negocio |
| Contras | Requiere mantenimiento |

### 4.7 Capa de Caching

**RecomendaciÃ³n: Redis + Cache Local (LRU)**

| Aspecto | Detalle |
|---------|---------|
| DescripciÃ³n | Cache de 2 niveles: local (memoria) + distribuido (Redis) |
| JustificaciÃ³n | Reduce llamadas a Claude, mejora latencia |
| Pros | TTL configurable, invalidaciÃ³n por tenant |
| Contras | Complejidad de invalidaciÃ³n |
| Latencia | <1ms (local), <10ms (Redis) |

### 4.8 Capa de Observabilidad

**RecomendaciÃ³n: Logs estructurados + MÃ©tricas Prometheus**

| Aspecto | Detalle |
|---------|---------|
| DescripciÃ³n | JSON logs + endpoint /metrics |
| JustificaciÃ³n | Compatible con Replit, bajo overhead |
| Pros | FÃ¡cil debugging, alertas bÃ¡sicas |
| Contras | Sin trazas distribuidas |

### 4.9 Capa de Seguridad Multi-Tenant

**RecomendaciÃ³n: Row-Level Security (RLS) + empresa_id en todas las queries**

| Aspecto | Detalle |
|---------|---------|
| DescripciÃ³n | Aislamiento a nivel de fila en PostgreSQL |
| JustificaciÃ³n | Seguridad por defecto, imposible cross-tenant |
| Pros | GarantÃ­a de aislamiento, sin overhead |
| Contras | Requiere disciplina en queries |

---

## 5. ARQUITECTURA OBJETIVO

### 5.1 Diagrama de Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        REVISAR.IA - ARQUITECTURA DE AGENTES                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                            â”‚
â”‚  â”‚  FRONTEND   â”‚                                                            â”‚
â”‚  â”‚  React 19   â”‚                                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                                            â”‚
â”‚         â”‚                                                                   â”‚
â”‚         â–¼                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         API GATEWAY (FastAPI)                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚   â”‚
â”‚  â”‚  â”‚ Auth + JWT  â”‚  â”‚ Rate Limit  â”‚  â”‚ Tenant Ctx  â”‚                  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                 â”‚                                           â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚         â–¼                       â–¼                       â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   CACHE     â”‚         â”‚ ORCHESTRATOR â”‚         â”‚  KNOWLEDGE  â”‚          â”‚
â”‚  â”‚   LAYER     â”‚         â”‚   (Router)   â”‚         â”‚    BASE     â”‚          â”‚
â”‚  â”‚  Redis/LRU  â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â”‚  pgvector   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                 â”‚                                           â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚         â–¼                       â–¼                       â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      AGENT POOL (10 Agentes)                         â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚  â”‚   A1    â”‚ â”‚   A2    â”‚ â”‚   A3    â”‚ â”‚   A4    â”‚ â”‚   A5    â”‚       â”‚   â”‚
â”‚  â”‚  â”‚RecepciÃ³nâ”‚ â”‚AnÃ¡lisis â”‚ â”‚Normativoâ”‚ â”‚Contable â”‚ â”‚Operativoâ”‚       â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â”‚       â”‚           â”‚           â”‚           â”‚           â”‚             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚  â”‚   A6    â”‚ â”‚   A7    â”‚ â”‚   A8    â”‚ â”‚   A9    â”‚ â”‚  A10    â”‚       â”‚   â”‚
â”‚  â”‚  â”‚Financ.  â”‚ â”‚Legal    â”‚ â”‚Red Team â”‚ â”‚SÃ­ntesis â”‚ â”‚Archivo  â”‚       â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â”‚       â”‚           â”‚           â”‚           â”‚           â”‚             â”‚   â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                               â”‚                                      â”‚   â”‚
â”‚  â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚   â”‚
â”‚  â”‚                     â”‚  REDIS PUB/SUB    â”‚                           â”‚   â”‚
â”‚  â”‚                     â”‚  Inter-Agent Bus  â”‚                           â”‚   â”‚
â”‚  â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                 â”‚                                           â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚         â–¼                       â–¼                       â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ POSTGRESQL  â”‚         â”‚   CLAUDE    â”‚         â”‚  EMBEDDINGS â”‚          â”‚
â”‚  â”‚ + pgvector  â”‚         â”‚   SONNET    â”‚         â”‚   OpenAI    â”‚          â”‚
â”‚  â”‚   (Neon)    â”‚         â”‚ (Anthropic) â”‚         â”‚             â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Flujo de Datos Detallado

```
1. INGESTIÃ“N DE DOCUMENTO
   Usuario â†’ Upload â†’ API â†’ Chunking â†’ Embeddings â†’ pgvector
                                    â†“
                              knowledge_chunks (empresa_id aislado)

2. ANÃLISIS POR AGENTE
   Request â†’ Orchestrator â†’ Selecciona Agente(s) â†’ RAG Context
                                    â†“
                         Claude API (con contexto personalizado)
                                    â†“
                              Deliberation â†’ DB

3. COMUNICACIÃ“N INTER-AGENTES
   Agente A1 â†’ Redis Pub/Sub â†’ Agente A2, A3, ...
        â†“
   Cada agente tiene su namespace: agent:{agent_id}:{empresa_id}

4. GENERACIÃ“N DE REPORTE
   SÃ­ntesis (A9) â†’ Recopila deliberaciones â†’ Genera reporte â†’ PDF Export
```

---

## 6. PLAN DE IMPLEMENTACIÃ“N

### 6.1 Fase 0: Infraestructura Base (Completada âœ…)

| Tarea | Estado | Responsable |
|-------|--------|-------------|
| PostgreSQL + pgvector | âœ… | DevOps |
| Ãndices IVFFlat | âœ… | DevOps |
| Connection pooling | âœ… | Backend |
| Cache service | âœ… | Backend |
| Rate limiting | âœ… | Backend |

### 6.2 Fase 1: OptimizaciÃ³n de Agentes (1-2 dÃ­as)

| # | Tarea | Tiempo | Criterio de AceptaciÃ³n |
|---|-------|--------|------------------------|
| 1.1 | Crear AgentOrchestrator mejorado | 4h | Coordina 10 agentes con contexto |
| 1.2 | Implementar RAG optimizado por agente | 4h | Cada agente tiene su retrieval |
| 1.3 | Sistema de memoria de conversaciÃ³n | 2h | Contexto persiste entre turnos |
| 1.4 | Templates de prompts estructurados | 2h | Respuestas consistentes |

### 6.3 Fase 2: ComunicaciÃ³n Inter-Agentes (1 dÃ­a)

| # | Tarea | Tiempo | Criterio de AceptaciÃ³n |
|---|-------|--------|------------------------|
| 2.1 | Implementar AgentBus con Redis | 3h | Pub/Sub funcionando |
| 2.2 | Protocolo de mensajes entre agentes | 2h | Formato estandarizado |
| 2.3 | Timeout y retry para mensajes | 1h | Manejo de fallos |

### 6.4 Fase 3: Aislamiento Multi-Tenant (4h)

| # | Tarea | Tiempo | Criterio de AceptaciÃ³n |
|---|-------|--------|------------------------|
| 3.1 | Namespace por empresa en vectores | 2h | WHERE empresa_id = X en todo |
| 3.2 | Contexto de tenant en agentes | 1h | InyecciÃ³n automÃ¡tica |
| 3.3 | ValidaciÃ³n de aislamiento | 1h | Test cross-tenant falla |

### 6.5 Fase 4: Calidad de Reportes (4h)

| # | Tarea | Tiempo | Criterio de AceptaciÃ³n |
|---|-------|--------|------------------------|
| 4.1 | Templates de deliberaciÃ³n | 2h | Estructura consistente |
| 4.2 | ValidaciÃ³n de outputs | 1h | Schema validation |
| 4.3 | Scoring de confianza | 1h | Cada respuesta tiene score |

### 6.6 Fase 5: Observabilidad (2h)

| # | Tarea | Tiempo | Criterio de AceptaciÃ³n |
|---|-------|--------|------------------------|
| 5.1 | Logs estructurados de agentes | 1h | JSON logs con trace_id |
| 5.2 | MÃ©tricas de latencia por agente | 1h | Prometheus endpoint |

---

## 7. IMPLEMENTACIÃ“N DE CÃ“DIGO

### 7.1 AgentOrchestrator Optimizado

Crear archivo `backend/services/agent_orchestrator.py`:

```python
"""
agent_orchestrator.py - Orquestador de Agentes Optimizado
Coordina los 10 agentes especializados con aislamiento multi-tenant
"""

import asyncio
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime
from uuid import uuid4
import json

from anthropic import Anthropic
from services.vector_search_service import VectorSearchService
from services.cache_service import get_cache
from database_pg import get_connection

# DefiniciÃ³n de los 10 Agentes
AGENTS_CONFIG = {
    "A1_RECEPCION": {
        "name": "Agente de RecepciÃ³n",
        "role": "Recibir y clasificar documentos del contribuyente",
        "capabilities": ["clasificaciÃ³n", "extracciÃ³n_datos", "validaciÃ³n_inicial"],
        "system_prompt": """Eres el Agente de RecepciÃ³n de REVISAR.IA. Tu funciÃ³n es:
1. Recibir documentos fiscales del contribuyente
2. Clasificar el tipo de documento (CFDI, contrato, pÃ³liza de pago, etc.)
3. Extraer datos clave (RFC, monto, fecha, concepto)
4. Validar completitud inicial
Siempre responde en espaÃ±ol con formato estructurado."""
    },
    "A2_ANALISIS": {
        "name": "Agente de AnÃ¡lisis Fiscal",
        "role": "Analizar implicaciones fiscales de operaciones",
        "capabilities": ["anÃ¡lisis_fiscal", "deducibilidad", "ISR", "IVA"],
        "system_prompt": """Eres el Agente de AnÃ¡lisis Fiscal de REVISAR.IA. Tu funciÃ³n es:
1. Analizar la naturaleza fiscal de las operaciones
2. Evaluar deducibilidad conforme al Art. 27 LISR
3. Identificar requisitos fiscales aplicables
4. Detectar riesgos de rechazo de deducciones
Cita siempre los artÃ­culos de ley aplicables."""
    },
    "A3_NORMATIVO": {
        "name": "Agente Normativo",
        "role": "Verificar cumplimiento de normatividad fiscal",
        "capabilities": ["CFF", "LISR", "LIVA", "criterios_SAT"],
        "system_prompt": """Eres el Agente Normativo de REVISAR.IA. Tu funciÃ³n es:
1. Verificar cumplimiento del CFF
2. Validar requisitos de LISR y LIVA
3. Consultar criterios no vinculativos del SAT
4. Identificar riesgos normativos
Fundamenta cada conclusiÃ³n con artÃ­culos especÃ­ficos."""
    },
    "A4_CONTABLE": {
        "name": "Agente Contable",
        "role": "Validar registro y soporte contable",
        "capabilities": ["NIF", "registro_contable", "pÃ³lizas", "conciliaciones"],
        "system_prompt": """Eres el Agente Contable de REVISAR.IA. Tu funciÃ³n es:
1. Validar registro contable conforme a NIF
2. Verificar pÃ³lizas contables
3. Revisar conciliaciones
4. Evaluar soporte documental contable
Indica las NIF aplicables en cada caso."""
    },
    "A5_OPERATIVO": {
        "name": "Agente Operativo",
        "role": "Validar materialidad y sustancia operativa",
        "capabilities": ["materialidad", "sustancia", "evidencia_operativa"],
        "system_prompt": """Eres el Agente Operativo de REVISAR.IA. Tu funciÃ³n es:
1. Validar la materialidad de las operaciones
2. Verificar evidencia de sustancia econÃ³mica
3. Revisar entregables y evidencia de servicios
4. Evaluar capacidad operativa del proveedor
Detalla quÃ© evidencia especÃ­fica se requiere."""
    },
    "A6_FINANCIERO": {
        "name": "Agente Financiero",
        "role": "Analizar flujos financieros y bancarizaciÃ³n",
        "capabilities": ["bancarizaciÃ³n", "flujos", "pagos", "rastreo"],
        "system_prompt": """Eres el Agente Financiero de REVISAR.IA. Tu funciÃ³n es:
1. Validar bancarizaciÃ³n de pagos >$2,000
2. Verificar flujos financieros
3. Rastrear origen y destino de fondos
4. Evaluar cumplimiento de requisitos de pago
Indica montos y fechas especÃ­ficas."""
    },
    "A7_LEGAL": {
        "name": "Agente Legal",
        "role": "Revisar aspectos contractuales y legales",
        "capabilities": ["contratos", "obligaciones", "disputas", "representaciÃ³n"],
        "system_prompt": """Eres el Agente Legal de REVISAR.IA. Tu funciÃ³n es:
1. Revisar contratos y obligaciones
2. Validar poderes y representaciÃ³n legal
3. Identificar riesgos contractuales
4. Evaluar clÃ¡usulas relevantes para defensa fiscal
SeÃ±ala clÃ¡usulas especÃ­ficas del contrato."""
    },
    "A8_REDTEAM": {
        "name": "Agente Red Team",
        "role": "Simular objeciones del SAT",
        "capabilities": ["objeciones", "simulaciÃ³n_SAT", "contraargumentos"],
        "system_prompt": """Eres el Agente Red Team de REVISAR.IA. Tu funciÃ³n es:
1. Simular objeciones que harÃ­a el SAT
2. Identificar debilidades en el expediente
3. Proponer contraargumentos
4. Evaluar probabilidad de Ã©xito en defensa
ActÃºa como un auditor fiscal del SAT."""
    },
    "A9_SINTESIS": {
        "name": "Agente de SÃ­ntesis",
        "role": "Consolidar anÃ¡lisis y generar reporte final",
        "capabilities": ["sÃ­ntesis", "reporte", "conclusiones", "recomendaciones"],
        "system_prompt": """Eres el Agente de SÃ­ntesis de REVISAR.IA. Tu funciÃ³n es:
1. Consolidar anÃ¡lisis de todos los agentes
2. Generar conclusiones ponderadas
3. Calcular score de riesgo/compliance
4. Emitir dictamen final con recomendaciones
Estructura tu respuesta para el Defense File."""
    },
    "A10_ARCHIVO": {
        "name": "Agente de Archivo",
        "role": "Organizar y catalogar el expediente",
        "capabilities": ["catalogaciÃ³n", "Ã­ndice", "trazabilidad", "exportaciÃ³n"],
        "system_prompt": """Eres el Agente de Archivo de REVISAR.IA. Tu funciÃ³n es:
1. Organizar documentos del expediente
2. Generar Ã­ndice y tabla de contenido
3. Asegurar trazabilidad de evidencia
4. Preparar expediente para exportaciÃ³n PDF
Lista los documentos y su ubicaciÃ³n."""
    },
}


@dataclass
class AgentMessage:
    """Mensaje entre agentes."""
    id: str = field(default_factory=lambda: str(uuid4()))
    from_agent: str = ""
    to_agent: str = ""  # "*" para broadcast
    empresa_id: str = ""
    project_id: str = ""
    message_type: str = "analysis"  # analysis, request, response
    content: Dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.utcnow)
    
    def to_dict(self) -> dict:
        return {
            "id": self.id,
            "from_agent": self.from_agent,
            "to_agent": self.to_agent,
            "empresa_id": self.empresa_id,
            "project_id": self.project_id,
            "message_type": self.message_type,
            "content": self.content,
            "timestamp": self.timestamp.isoformat(),
        }


@dataclass
class AgentContext:
    """Contexto de ejecuciÃ³n del agente."""
    empresa_id: str
    project_id: str
    user_id: str
    agent_id: str
    conversation_history: List[dict] = field(default_factory=list)
    rag_context: str = ""
    related_deliberations: List[dict] = field(default_factory=list)
    shared_memory: Dict[str, Any] = field(default_factory=dict)


class AgentOrchestrator:
    """
    Orquestador de Agentes Multi-Tenant.
    Coordina los 10 agentes especializados con aislamiento estricto.
    """
    
    def __init__(self):
        self.claude = Anthropic()
        self.vector_search = VectorSearchService()
        self.cache = get_cache()
        self.agents = AGENTS_CONFIG
        
    async def process_request(
        self,
        empresa_id: str,
        project_id: str,
        user_id: str,
        user_message: str,
        target_agents: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        Procesa una solicitud del usuario usando los agentes apropiados.
        
        Args:
            empresa_id: ID del tenant (aislamiento)
            project_id: ID del proyecto actual
            user_id: ID del usuario
            user_message: Mensaje del usuario
            target_agents: Lista de agentes especÃ­ficos (None = auto-select)
        
        Returns:
            Respuesta consolidada de los agentes
        """
        trace_id = str(uuid4())[:8]
        start_time = datetime.utcnow()
        
        # 1. Determinar agentes a invocar
        if target_agents:
            agents_to_invoke = target_agents
        else:
            agents_to_invoke = await self._select_agents(user_message)
        
        # 2. Obtener contexto RAG por tenant
        rag_context = await self._get_rag_context(
            empresa_id=empresa_id,
            query=user_message,
        )
        
        # 3. Obtener deliberaciones relacionadas
        related_deliberations = await self._get_related_deliberations(
            empresa_id=empresa_id,
            project_id=project_id,
        )
        
        # 4. Crear contexto compartido
        shared_context = AgentContext(
            empresa_id=empresa_id,
            project_id=project_id,
            user_id=user_id,
            agent_id="orchestrator",
            rag_context=rag_context,
            related_deliberations=related_deliberations,
        )
        
        # 5. Ejecutar agentes en paralelo
        results = await self._execute_agents_parallel(
            agents=agents_to_invoke,
            user_message=user_message,
            context=shared_context,
            trace_id=trace_id,
        )
        
        # 6. Sintetizar respuestas si hay mÃºltiples agentes
        if len(results) > 1:
            final_response = await self._synthesize_responses(
                results=results,
                context=shared_context,
            )
        else:
            final_response = results[0] if results else {"error": "No agent response"}
        
        # 7. Guardar deliberaciÃ³n
        await self._save_deliberation(
            empresa_id=empresa_id,
            project_id=project_id,
            agents=agents_to_invoke,
            user_message=user_message,
            response=final_response,
            trace_id=trace_id,
        )
        
        elapsed_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
        
        return {
            "trace_id": trace_id,
            "agents_invoked": agents_to_invoke,
            "response": final_response,
            "rag_context_used": bool(rag_context),
            "elapsed_ms": elapsed_ms,
        }
    
    async def _select_agents(self, user_message: str) -> List[str]:
        """Selecciona automÃ¡ticamente los agentes apropiados."""
        # Palabras clave para cada agente
        agent_keywords = {
            "A1_RECEPCION": ["documento", "subir", "cargar", "archivo", "cfdi"],
            "A2_ANALISIS": ["deducible", "deducciÃ³n", "impuesto", "fiscal", "ISR"],
            "A3_NORMATIVO": ["ley", "artÃ­culo", "CFF", "LISR", "norma", "SAT"],
            "A4_CONTABLE": ["contable", "pÃ³liza", "NIF", "registro", "cuenta"],
            "A5_OPERATIVO": ["materialidad", "operaciÃ³n", "servicio", "entregable"],
            "A6_FINANCIERO": ["pago", "banco", "transferencia", "flujo", "dinero"],
            "A7_LEGAL": ["contrato", "legal", "clÃ¡usula", "obligaciÃ³n"],
            "A8_REDTEAM": ["objeciÃ³n", "SAT", "auditorÃ­a", "riesgo", "defensa"],
            "A9_SINTESIS": ["resumen", "conclusiÃ³n", "reporte", "dictamen"],
            "A10_ARCHIVO": ["expediente", "documento", "Ã­ndice", "archivo"],
        }
        
        message_lower = user_message.lower()
        selected = []
        
        for agent_id, keywords in agent_keywords.items():
            if any(kw in message_lower for kw in keywords):
                selected.append(agent_id)
        
        # Si no hay coincidencias, usar A2 (AnÃ¡lisis) por defecto
        if not selected:
            selected = ["A2_ANALISIS"]
        
        return selected
    
    async def _get_rag_context(
        self,
        empresa_id: str,
        query: str,
        limit: int = 5,
    ) -> str:
        """Obtiene contexto RAG del knowledge base del tenant."""
        # Intentar cache primero
        cache_key = f"rag:{empresa_id}:{hash(query)}"
        cached = self.cache.get(cache_key)
        if cached:
            return cached
        
        # BÃºsqueda semÃ¡ntica
        results = await self.vector_search.hybrid_search(
            empresa_id=empresa_id,
            query=query,
            limit=limit,
        )
        
        if not results:
            return ""
        
        # Formatear contexto
        context_parts = []
        for i, result in enumerate(results, 1):
            context_parts.append(
                f"[Documento {i}: {result.get('filename', 'N/A')}]\n"
                f"{result.get('contenido', '')}\n"
            )
        
        context = "\n---\n".join(context_parts)
        
        # Guardar en cache (5 min)
        self.cache.set(cache_key, context, ttl=300)
        
        return context
    
    async def _get_related_deliberations(
        self,
        empresa_id: str,
        project_id: str,
        limit: int = 5,
    ) -> List[dict]:
        """Obtiene deliberaciones previas relacionadas."""
        async with get_connection() as conn:
            rows = await conn.fetch("""
                SELECT id, agente_id, fase, contenido, resumen, decision, created_at
                FROM deliberations
                WHERE empresa_id = $1 AND project_id = $2
                ORDER BY created_at DESC
                LIMIT $3
            """, empresa_id, project_id, limit)
            
            return [dict(row) for row in rows]
    
    async def _execute_agents_parallel(
        self,
        agents: List[str],
        user_message: str,
        context: AgentContext,
        trace_id: str,
    ) -> List[dict]:
        """Ejecuta mÃºltiples agentes en paralelo."""
        tasks = []
        
        for agent_id in agents:
            task = self._invoke_agent(
                agent_id=agent_id,
                user_message=user_message,
                context=context,
                trace_id=trace_id,
            )
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Filtrar errores
        valid_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"[{trace_id}] Error en agente {agents[i]}: {result}")
            else:
                valid_results.append(result)
        
        return valid_results
    
    async def _invoke_agent(
        self,
        agent_id: str,
        user_message: str,
        context: AgentContext,
        trace_id: str,
    ) -> dict:
        """Invoca un agente individual."""
        agent_config = self.agents.get(agent_id)
        if not agent_config:
            raise ValueError(f"Agente no encontrado: {agent_id}")
        
        # Construir prompt con contexto
        system_prompt = self._build_system_prompt(agent_config, context)
        
        # Construir mensaje de usuario con contexto
        user_prompt = self._build_user_prompt(user_message, context)
        
        # Llamar a Claude
        start_time = datetime.utcnow()
        
        response = await asyncio.to_thread(
            self.claude.messages.create,
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            temperature=0.3,  # MÃ¡s determinÃ­stico para anÃ¡lisis
            system=system_prompt,
            messages=[{"role": "user", "content": user_prompt}],
        )
        
        elapsed_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
        
        return {
            "agent_id": agent_id,
            "agent_name": agent_config["name"],
            "response": response.content[0].text,
            "usage": {
                "input_tokens": response.usage.input_tokens,
                "output_tokens": response.usage.output_tokens,
            },
            "elapsed_ms": elapsed_ms,
            "trace_id": trace_id,
        }
    
    def _build_system_prompt(
        self,
        agent_config: dict,
        context: AgentContext,
    ) -> str:
        """Construye el system prompt con contexto del tenant."""
        base_prompt = agent_config["system_prompt"]
        
        # Agregar informaciÃ³n del tenant
        tenant_context = f"""
CONTEXTO DEL TENANT:
- Empresa ID: {context.empresa_id}
- Proyecto ID: {context.project_id}

INSTRUCCIONES ADICIONALES:
- Responde SOLO con informaciÃ³n relevante para este tenant
- No menciones informaciÃ³n de otros tenants
- Si no tienes informaciÃ³n suficiente, indÃ­calo claramente
- Estructura tu respuesta con secciones claras
"""
        
        return f"{base_prompt}\n\n{tenant_context}"
    
    def _build_user_prompt(
        self,
        user_message: str,
        context: AgentContext,
    ) -> str:
        """Construye el user prompt con contexto RAG."""
        parts = [f"CONSULTA DEL USUARIO:\n{user_message}"]
        
        # Agregar contexto RAG si existe
        if context.rag_context:
            parts.append(f"""
DOCUMENTOS RELEVANTES DEL KNOWLEDGE BASE:
{context.rag_context}
""")
        
        # Agregar deliberaciones previas si existen
        if context.related_deliberations:
            delib_text = "\n".join([
                f"- {d['agente_id']}: {d.get('resumen', d.get('contenido', '')[:200])}"
                for d in context.related_deliberations[:3]
            ])
            parts.append(f"""
DELIBERACIONES PREVIAS EN ESTE PROYECTO:
{delib_text}
""")
        
        return "\n\n".join(parts)
    
    async def _synthesize_responses(
        self,
        results: List[dict],
        context: AgentContext,
    ) -> dict:
        """Sintetiza respuestas de mÃºltiples agentes."""
        # Formatear respuestas de agentes
        agent_responses = "\n\n".join([
            f"## {r['agent_name']}\n{r['response']}"
            for r in results
        ])
        
        synthesis_prompt = f"""
Eres el Agente de SÃ­ntesis. Consolida las siguientes respuestas de los agentes especializados en una respuesta coherente y estructurada.

RESPUESTAS DE LOS AGENTES:
{agent_responses}

INSTRUCCIONES:
1. Identifica los puntos clave de cada agente
2. Resuelve contradicciones si las hay
3. Genera una conclusiÃ³n consolidada
4. Incluye un score de riesgo/compliance (0-100)
5. Lista las recomendaciones principales

Responde en espaÃ±ol con formato estructurado.
"""
        
        response = await asyncio.to_thread(
            self.claude.messages.create,
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            temperature=0.2,
            system="Eres el Agente de SÃ­ntesis de REVISAR.IA.",
            messages=[{"role": "user", "content": synthesis_prompt}],
        )
        
        return {
            "synthesized": True,
            "response": response.content[0].text,
            "individual_responses": results,
        }
    
    async def _save_deliberation(
        self,
        empresa_id: str,
        project_id: str,
        agents: List[str],
        user_message: str,
        response: dict,
        trace_id: str,
    ) -> None:
        """Guarda la deliberaciÃ³n en la base de datos."""
        async with get_connection() as conn:
            await conn.execute("""
                INSERT INTO deliberations (
                    id, empresa_id, project_id, agente_id, fase,
                    contenido, resumen, decision, created_at
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8, $9
                )
            """,
                str(uuid4()),
                empresa_id,
                project_id,
                ",".join(agents),
                "anÃ¡lisis",
                json.dumps({
                    "user_message": user_message,
                    "response": response,
                    "trace_id": trace_id,
                }),
                response.get("response", "")[:500] if isinstance(response.get("response"), str) else "",
                json.dumps({"synthesized": response.get("synthesized", False)}),
                datetime.utcnow(),
            )


# Singleton
_orchestrator: Optional[AgentOrchestrator] = None

def get_orchestrator() -> AgentOrchestrator:
    global _orchestrator
    if _orchestrator is None:
        _orchestrator = AgentOrchestrator()
    return _orchestrator
```

### 7.2 Sistema de ComunicaciÃ³n Inter-Agentes

Crear archivo `backend/services/agent_bus.py`:

```python
"""
agent_bus.py - Bus de ComunicaciÃ³n Inter-Agentes
Implementa Pub/Sub para mensajerÃ­a entre agentes con aislamiento multi-tenant
"""

import asyncio
import json
from typing import Dict, List, Callable, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime
from uuid import uuid4
import os

# Intentar usar Redis, fallback a memoria
try:
    import redis.asyncio as redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False

REDIS_URL = os.getenv("REDIS_URL")


@dataclass
class AgentMessage:
    """Mensaje entre agentes."""
    id: str = field(default_factory=lambda: str(uuid4()))
    from_agent: str = ""
    to_agent: str = ""  # "*" para broadcast, agent_id para directo
    empresa_id: str = ""
    project_id: str = ""
    message_type: str = "analysis"
    content: Dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.utcnow)
    ttl_seconds: int = 300  # 5 minutos por defecto
    
    def to_json(self) -> str:
        return json.dumps({
            "id": self.id,
            "from_agent": self.from_agent,
            "to_agent": self.to_agent,
            "empresa_id": self.empresa_id,
            "project_id": self.project_id,
            "message_type": self.message_type,
            "content": self.content,
            "timestamp": self.timestamp.isoformat(),
        })
    
    @classmethod
    def from_json(cls, data: str) -> "AgentMessage":
        d = json.loads(data)
        d["timestamp"] = datetime.fromisoformat(d["timestamp"])
        return cls(**d)


class InMemoryBus:
    """Bus de mensajes en memoria (fallback sin Redis)."""
    
    def __init__(self):
        self.subscribers: Dict[str, List[Callable]] = {}
        self.messages: Dict[str, List[AgentMessage]] = {}
    
    async def publish(self, channel: str, message: AgentMessage) -> bool:
        """Publica un mensaje en un canal."""
        if channel not in self.messages:
            self.messages[channel] = []
        
        self.messages[channel].append(message)
        
        # Notificar a suscriptores
        if channel in self.subscribers:
            for callback in self.subscribers[channel]:
                try:
                    await callback(message)
                except Exception as e:
                    print(f"Error en callback: {e}")
        
        return True
    
    async def subscribe(self, channel: str, callback: Callable) -> None:
        """Suscribe a un canal."""
        if channel not in self.subscribers:
            self.subscribers[channel] = []
        self.subscribers[channel].append(callback)
    
    async def get_messages(
        self,
        channel: str,
        since: Optional[datetime] = None,
        limit: int = 100,
    ) -> List[AgentMessage]:
        """Obtiene mensajes de un canal."""
        messages = self.messages.get(channel, [])
        
        if since:
            messages = [m for m in messages if m.timestamp > since]
        
        return messages[-limit:]


class RedisBus:
    """Bus de mensajes con Redis Pub/Sub."""
    
    def __init__(self):
        self.redis: Optional[redis.Redis] = None
        self.pubsub = None
        self._connected = False
    
    async def connect(self) -> bool:
        """Conecta a Redis."""
        if not REDIS_URL:
            return False
        
        try:
            self.redis = redis.from_url(REDIS_URL, decode_responses=True)
            await self.redis.ping()
            self.pubsub = self.redis.pubsub()
            self._connected = True
            return True
        except Exception as e:
            print(f"Error conectando a Redis: {e}")
            return False
    
    async def publish(self, channel: str, message: AgentMessage) -> bool:
        """Publica un mensaje en un canal."""
        if not self._connected:
            return False
        
        try:
            # Publicar en canal
            await self.redis.publish(channel, message.to_json())
            
            # Guardar en lista para historial
            key = f"agent_messages:{channel}"
            await self.redis.lpush(key, message.to_json())
            await self.redis.ltrim(key, 0, 999)  # Mantener Ãºltimos 1000
            await self.redis.expire(key, message.ttl_seconds)
            
            return True
        except Exception as e:
            print(f"Error publicando mensaje: {e}")
            return False
    
    async def subscribe(self, channel: str, callback: Callable) -> None:
        """Suscribe a un canal."""
        if not self._connected:
            return
        
        await self.pubsub.subscribe(channel)
        
        async def listener():
            async for message in self.pubsub.listen():
                if message["type"] == "message":
                    try:
                        agent_msg = AgentMessage.from_json(message["data"])
                        await callback(agent_msg)
                    except Exception as e:
                        print(f"Error en listener: {e}")
        
        asyncio.create_task(listener())
    
    async def get_messages(
        self,
        channel: str,
        since: Optional[datetime] = None,
        limit: int = 100,
    ) -> List[AgentMessage]:
        """Obtiene mensajes histÃ³ricos de un canal."""
        if not self._connected:
            return []
        
        try:
            key = f"agent_messages:{channel}"
            raw_messages = await self.redis.lrange(key, 0, limit - 1)
            
            messages = []
            for raw in raw_messages:
                msg = AgentMessage.from_json(raw)
                if since is None or msg.timestamp > since:
                    messages.append(msg)
            
            return messages
        except Exception as e:
            print(f"Error obteniendo mensajes: {e}")
            return []


class AgentBus:
    """
    Bus de ComunicaciÃ³n Inter-Agentes.
    Usa Redis si estÃ¡ disponible, fallback a memoria.
    Aislamiento por empresa_id (multi-tenant).
    """
    
    def __init__(self):
        self.backend: Optional[InMemoryBus | RedisBus] = None
        self._initialized = False
    
    async def initialize(self) -> None:
        """Inicializa el bus de mensajes."""
        if self._initialized:
            return
        
        # Intentar Redis primero
        if REDIS_AVAILABLE and REDIS_URL:
            redis_bus = RedisBus()
            if await redis_bus.connect():
                self.backend = redis_bus
                print("âœ… AgentBus: Usando Redis")
                self._initialized = True
                return
        
        # Fallback a memoria
        self.backend = InMemoryBus()
        print("âš ï¸ AgentBus: Usando memoria (sin Redis)")
        self._initialized = True
    
    def _get_channel(self, empresa_id: str, agent_id: str = "*") -> str:
        """Genera el nombre del canal con namespace de tenant."""
        if agent_id == "*":
            return f"agents:{empresa_id}:broadcast"
        return f"agents:{empresa_id}:{agent_id}"
    
    async def send_to_agent(
        self,
        from_agent: str,
        to_agent: str,
        empresa_id: str,
        project_id: str,
        content: Dict[str, Any],
        message_type: str = "analysis",
    ) -> bool:
        """EnvÃ­a mensaje a un agente especÃ­fico."""
        await self.initialize()
        
        message = AgentMessage(
            from_agent=from_agent,
            to_agent=to_agent,
            empresa_id=empresa_id,
            project_id=project_id,
            message_type=message_type,
            content=content,
        )
        
        channel = self._get_channel(empresa_id, to_agent)
        return await self.backend.publish(channel, message)
    
    async def broadcast(
        self,
        from_agent: str,
        empresa_id: str,
        project_id: str,
        content: Dict[str, Any],
        message_type: str = "broadcast",
    ) -> bool:
        """EnvÃ­a mensaje a todos los agentes del tenant."""
        await self.initialize()
        
        message = AgentMessage(
            from_agent=from_agent,
            to_agent="*",
            empresa_id=empresa_id,
            project_id=project_id,
            message_type=message_type,
            content=content,
        )
        
        channel = self._get_channel(empresa_id, "*")
        return await self.backend.publish(channel, message)
    
    async def subscribe_agent(
        self,
        agent_id: str,
        empresa_id: str,
        callback: Callable[[AgentMessage], Any],
    ) -> None:
        """Suscribe un agente a su canal y al broadcast."""
        await self.initialize()
        
        # Suscribir al canal directo
        direct_channel = self._get_channel(empresa_id, agent_id)
        await self.backend.subscribe(direct_channel, callback)
        
        # Suscribir al broadcast
        broadcast_channel = self._get_channel(empresa_id, "*")
        await self.backend.subscribe(broadcast_channel, callback)
    
    async def get_agent_messages(
        self,
        agent_id: str,
        empresa_id: str,
        since: Optional[datetime] = None,
        limit: int = 100,
    ) -> List[AgentMessage]:
        """Obtiene mensajes para un agente."""
        await self.initialize()
        
        channel = self._get_channel(empresa_id, agent_id)
        return await self.backend.get_messages(channel, since, limit)


# Singleton
_agent_bus: Optional[AgentBus] = None

def get_agent_bus() -> AgentBus:
    global _agent_bus
    if _agent_bus is None:
        _agent_bus = AgentBus()
    return _agent_bus
```

### 7.3 Endpoint de Agentes

Crear/actualizar archivo `backend/routes/agents_routes.py`:

```python
"""
agents_routes.py - Endpoints para Agentes IA
"""

from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime

from services.agent_orchestrator import get_orchestrator, AGENTS_CONFIG
from services.agent_bus import get_agent_bus
from middleware.auth_middleware import get_current_user, TenantContext

router = APIRouter(prefix="/api/agents", tags=["Agents"])


class ChatRequest(BaseModel):
    message: str
    project_id: Optional[str] = None
    target_agents: Optional[List[str]] = None


class ChatResponse(BaseModel):
    trace_id: str
    agents_invoked: List[str]
    response: dict
    elapsed_ms: float


@router.get("/list")
async def list_agents():
    """Lista todos los agentes disponibles."""
    return {
        "agents": [
            {
                "id": agent_id,
                "name": config["name"],
                "role": config["role"],
                "capabilities": config["capabilities"],
            }
            for agent_id, config in AGENTS_CONFIG.items()
        ],
        "total": len(AGENTS_CONFIG),
    }


@router.post("/chat", response_model=ChatResponse)
async def chat_with_agents(
    request: ChatRequest,
    tenant: TenantContext = Depends(get_current_user),
):
    """
    EnvÃ­a un mensaje a los agentes y obtiene una respuesta.
    
    - Si no se especifica target_agents, el orquestador selecciona automÃ¡ticamente.
    - Si se especifica project_id, el contexto incluye deliberaciones previas.
    """
    orchestrator = get_orchestrator()
    
    result = await orchestrator.process_request(
        empresa_id=tenant.empresa_id,
        project_id=request.project_id or "general",
        user_id=tenant.user_id,
        user_message=request.message,
        target_agents=request.target_agents,
    )
    
    return ChatResponse(
        trace_id=result["trace_id"],
        agents_invoked=result["agents_invoked"],
        response=result["response"],
        elapsed_ms=result["elapsed_ms"],
    )


@router.get("/messages/{agent_id}")
async def get_agent_messages(
    agent_id: str,
    since: Optional[datetime] = None,
    limit: int = 50,
    tenant: TenantContext = Depends(get_current_user),
):
    """Obtiene mensajes recientes para un agente."""
    bus = get_agent_bus()
    
    messages = await bus.get_agent_messages(
        agent_id=agent_id,
        empresa_id=tenant.empresa_id,
        since=since,
        limit=limit,
    )
    
    return {
        "agent_id": agent_id,
        "messages": [m.to_dict() for m in messages],
        "count": len(messages),
    }


@router.post("/broadcast")
async def broadcast_message(
    content: dict,
    tenant: TenantContext = Depends(get_current_user),
):
    """EnvÃ­a un mensaje broadcast a todos los agentes del tenant."""
    bus = get_agent_bus()
    
    success = await bus.broadcast(
        from_agent="user",
        empresa_id=tenant.empresa_id,
        project_id="general",
        content=content,
    )
    
    return {"success": success}
```

---

## 8. SCRIPTS DE DIAGNÃ“STICO Y PRUEBAS

### 8.1 Script de DiagnÃ³stico Automatizado

Crear archivo `scripts/diagnose_agents.py`:

```python
#!/usr/bin/env python3
"""
diagnose_agents.py - DiagnÃ³stico completo del sistema de agentes
Ejecutar: python scripts/diagnose_agents.py
"""

import asyncio
import json
import time
import sys
import os
from datetime import datetime
from typing import Dict, Any

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'backend'))

# Resultados del diagnÃ³stico
DIAGNOSIS_RESULTS: Dict[str, Any] = {
    "timestamp": datetime.utcnow().isoformat(),
    "checks": {},
    "metrics": {},
    "warnings": [],
    "errors": [],
}


async def check_database():
    """Verifica conexiÃ³n y tablas de agentes."""
    print("ğŸ“Š Verificando base de datos...")
    
    try:
        import asyncpg
        conn = await asyncpg.connect(os.getenv("DATABASE_URL"))
        
        # Verificar tablas
        tables = ["deliberations", "knowledge_chunks", "projects"]
        for table in tables:
            count = await conn.fetchval(f"SELECT COUNT(*) FROM {table}")
            DIAGNOSIS_RESULTS["metrics"][f"table_{table}_count"] = count
            print(f"   âœ… {table}: {count} registros")
        
        # Verificar pgvector
        has_vector = await conn.fetchval(
            "SELECT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'vector')"
        )
        DIAGNOSIS_RESULTS["checks"]["pgvector"] = has_vector
        print(f"   {'âœ…' if has_vector else 'âŒ'} pgvector: {'Instalado' if has_vector else 'Falta'}")
        
        # Verificar embeddings
        total_chunks = await conn.fetchval("SELECT COUNT(*) FROM knowledge_chunks")
        with_embedding = await conn.fetchval(
            "SELECT COUNT(*) FROM knowledge_chunks WHERE embedding IS NOT NULL"
        )
        embedding_pct = (with_embedding / total_chunks * 100) if total_chunks > 0 else 0
        DIAGNOSIS_RESULTS["metrics"]["embedding_coverage"] = embedding_pct
        print(f"   {'âœ…' if embedding_pct > 80 else 'âš ï¸'} Embeddings: {embedding_pct:.1f}%")
        
        await conn.close()
        DIAGNOSIS_RESULTS["checks"]["database"] = True
        return True
        
    except Exception as e:
        DIAGNOSIS_RESULTS["errors"].append(f"Database: {str(e)}")
        DIAGNOSIS_RESULTS["checks"]["database"] = False
        print(f"   âŒ Error: {e}")
        return False


async def check_agent_orchestrator():
    """Verifica el orquestador de agentes."""
    print("\nğŸ¤– Verificando orquestador de agentes...")
    
    try:
        from services.agent_orchestrator import get_orchestrator, AGENTS_CONFIG
        
        orchestrator = get_orchestrator()
        
        # Verificar configuraciÃ³n de agentes
        agent_count = len(AGENTS_CONFIG)
        DIAGNOSIS_RESULTS["metrics"]["configured_agents"] = agent_count
        print(f"   âœ… Agentes configurados: {agent_count}")
        
        # Listar agentes
        for agent_id, config in AGENTS_CONFIG.items():
            print(f"      - {agent_id}: {config['name']}")
        
        DIAGNOSIS_RESULTS["checks"]["orchestrator"] = True
        return True
        
    except Exception as e:
        DIAGNOSIS_RESULTS["errors"].append(f"Orchestrator: {str(e)}")
        DIAGNOSIS_RESULTS["checks"]["orchestrator"] = False
        print(f"   âŒ Error: {e}")
        return False


async def check_agent_bus():
    """Verifica el bus de comunicaciÃ³n inter-agentes."""
    print("\nğŸ“¡ Verificando bus de agentes...")
    
    try:
        from services.agent_bus import get_agent_bus
        
        bus = get_agent_bus()
        await bus.initialize()
        
        # Verificar tipo de backend
        backend_type = type(bus.backend).__name__
        DIAGNOSIS_RESULTS["metrics"]["agent_bus_backend"] = backend_type
        print(f"   âœ… Backend: {backend_type}")
        
        # Probar publicaciÃ³n
        test_success = await bus.broadcast(
            from_agent="diagnostic",
            empresa_id="test_tenant",
            project_id="test_project",
            content={"type": "ping", "timestamp": datetime.utcnow().isoformat()},
        )
        
        DIAGNOSIS_RESULTS["checks"]["agent_bus"] = test_success
        print(f"   {'âœ…' if test_success else 'âš ï¸'} PublicaciÃ³n: {'OK' if test_success else 'Fallback memoria'}")
        
        return True
        
    except Exception as e:
        DIAGNOSIS_RESULTS["errors"].append(f"AgentBus: {str(e)}")
        DIAGNOSIS_RESULTS["checks"]["agent_bus"] = False
        print(f"   âŒ Error: {e}")
        return False


async def check_claude_api():
    """Verifica conexiÃ³n a Claude API."""
    print("\nğŸ§  Verificando Claude API...")
    
    try:
        from anthropic import Anthropic
        
        client = Anthropic()
        
        start_time = time.perf_counter()
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=50,
            messages=[{"role": "user", "content": "Responde solo 'OK'"}],
        )
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        
        DIAGNOSIS_RESULTS["metrics"]["claude_latency_ms"] = elapsed_ms
        DIAGNOSIS_RESULTS["metrics"]["claude_model"] = "claude-sonnet-4-20250514"
        print(f"   âœ… Claude API: OK ({elapsed_ms:.0f}ms)")
        print(f"   âœ… Respuesta: {response.content[0].text[:50]}")
        
        DIAGNOSIS_RESULTS["checks"]["claude_api"] = True
        return True
        
    except Exception as e:
        DIAGNOSIS_RESULTS["errors"].append(f"Claude API: {str(e)}")
        DIAGNOSIS_RESULTS["checks"]["claude_api"] = False
        print(f"   âŒ Error: {e}")
        return False


async def check_vector_search():
    """Verifica bÃºsqueda vectorial."""
    print("\nğŸ” Verificando bÃºsqueda vectorial...")
    
    try:
        from services.vector_search_service import VectorSearchService
        
        service = VectorSearchService()
        
        # Probar bÃºsqueda (sin tenant real)
        start_time = time.perf_counter()
        results = await service.hybrid_search(
            empresa_id="test_tenant",
            query="requisitos fiscales deducciÃ³n",
            limit=5,
        )
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        
        DIAGNOSIS_RESULTS["metrics"]["vector_search_latency_ms"] = elapsed_ms
        DIAGNOSIS_RESULTS["metrics"]["vector_search_results"] = len(results)
        print(f"   âœ… BÃºsqueda vectorial: {len(results)} resultados ({elapsed_ms:.0f}ms)")
        
        DIAGNOSIS_RESULTS["checks"]["vector_search"] = True
        return True
        
    except Exception as e:
        DIAGNOSIS_RESULTS["errors"].append(f"Vector Search: {str(e)}")
        DIAGNOSIS_RESULTS["checks"]["vector_search"] = False
        print(f"   âŒ Error: {e}")
        return False


async def check_cache():
    """Verifica sistema de cache."""
    print("\nğŸ’¾ Verificando cache...")
    
    try:
        from services.cache_service import get_cache
        
        cache = get_cache()
        
        # Probar set/get
        test_key = "diagnostic_test"
        test_value = {"test": True, "timestamp": datetime.utcnow().isoformat()}
        
        set_result = cache.set(test_key, test_value, ttl=60)
        get_result = cache.get(test_key)
        
        cache_working = get_result == test_value
        cache_type = "Redis" if cache.enabled else "Disabled"
        
        DIAGNOSIS_RESULTS["metrics"]["cache_type"] = cache_type
        DIAGNOSIS_RESULTS["checks"]["cache"] = cache_working
        print(f"   {'âœ…' if cache_working else 'âš ï¸'} Cache: {cache_type}")
        
        # Limpiar
        cache.delete(test_key)
        
        return cache_working
        
    except Exception as e:
        DIAGNOSIS_RESULTS["errors"].append(f"Cache: {str(e)}")
        DIAGNOSIS_RESULTS["checks"]["cache"] = False
        print(f"   âŒ Error: {e}")
        return False


async def run_integration_test():
    """Ejecuta prueba de integraciÃ³n end-to-end."""
    print("\nğŸ§ª Ejecutando prueba de integraciÃ³n...")
    
    try:
        from services.agent_orchestrator import get_orchestrator
        
        orchestrator = get_orchestrator()
        
        # Simular request
        start_time = time.perf_counter()
        result = await orchestrator.process_request(
            empresa_id="diagnostic_tenant",
            project_id="diagnostic_project",
            user_id="diagnostic_user",
            user_message="Â¿CuÃ¡les son los requisitos para deducir un gasto?",
            target_agents=["A2_ANALISIS"],
        )
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        
        DIAGNOSIS_RESULTS["metrics"]["e2e_latency_ms"] = elapsed_ms
        DIAGNOSIS_RESULTS["metrics"]["e2e_agents_invoked"] = result["agents_invoked"]
        
        has_response = bool(result.get("response"))
        DIAGNOSIS_RESULTS["checks"]["e2e_integration"] = has_response
        
        print(f"   âœ… IntegraciÃ³n E2E: {'OK' if has_response else 'FAIL'} ({elapsed_ms:.0f}ms)")
        print(f"   âœ… Agentes: {result['agents_invoked']}")
        
        return has_response
        
    except Exception as e:
        DIAGNOSIS_RESULTS["errors"].append(f"E2E Integration: {str(e)}")
        DIAGNOSIS_RESULTS["checks"]["e2e_integration"] = False
        print(f"   âŒ Error: {e}")
        return False


def calculate_percentages():
    """Calcula los porcentajes finales."""
    checks = DIAGNOSIS_RESULTS["checks"]
    
    # Porcentaje de implementaciÃ³n (tareas completadas)
    implementation_tasks = [
        "database",
        "orchestrator",
        "agent_bus",
        "vector_search",
        "cache",
    ]
    impl_completed = sum(1 for t in implementation_tasks if checks.get(t, False))
    impl_pct = (impl_completed / len(implementation_tasks)) * 100
    
    # Porcentaje de funcionamiento
    func_checks = [
        "database",
        "claude_api",
        "e2e_integration",
    ]
    func_completed = sum(1 for t in func_checks if checks.get(t, False))
    func_pct = (func_completed / len(func_checks)) * 100
    
    # Porcentaje de conexiÃ³n frontend (basado en checks de API)
    fe_checks = [
        "database",
        "orchestrator",
        "claude_api",
    ]
    fe_completed = sum(1 for t in fe_checks if checks.get(t, False))
    fe_pct = (fe_completed / len(fe_checks)) * 100
    
    return {
        "implementation": impl_pct,
        "functionality": func_pct,
        "frontend_connection": fe_pct,
    }


async def main():
    print("=" * 60)
    print("ğŸ”¬ DIAGNÃ“STICO DE SISTEMA DE AGENTES - REVISAR.IA")
    print("=" * 60)
    print(f"Timestamp: {DIAGNOSIS_RESULTS['timestamp']}")
    
    # Ejecutar checks
    await check_database()
    await check_agent_orchestrator()
    await check_agent_bus()
    await check_claude_api()
    await check_vector_search()
    await check_cache()
    await run_integration_test()
    
    # Calcular porcentajes
    percentages = calculate_percentages()
    DIAGNOSIS_RESULTS["percentages"] = percentages
    
    # Resumen
    print("\n" + "=" * 60)
    print("ğŸ“Š RESUMEN DE DIAGNÃ“STICO")
    print("=" * 60)
    
    print(f"""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  IMPLEMENTACIÃ“N:        {percentages['implementation']:>6.1f}%       â”‚
    â”‚  FUNCIONAMIENTO:        {percentages['functionality']:>6.1f}%       â”‚
    â”‚  CONEXIÃ“N FRONTEND:     {percentages['frontend_connection']:>6.1f}%       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    # Errores y warnings
    if DIAGNOSIS_RESULTS["errors"]:
        print("\nâŒ ERRORES:")
        for error in DIAGNOSIS_RESULTS["errors"]:
            print(f"   - {error}")
    
    if DIAGNOSIS_RESULTS["warnings"]:
        print("\nâš ï¸ WARNINGS:")
        for warning in DIAGNOSIS_RESULTS["warnings"]:
            print(f"   - {warning}")
    
    # Guardar resultados
    with open("diagnosis_results.json", "w") as f:
        json.dump(DIAGNOSIS_RESULTS, f, indent=2, default=str)
    
    print("\nâœ… Resultados guardados en diagnosis_results.json")
    
    return DIAGNOSIS_RESULTS


if __name__ == "__main__":
    asyncio.run(main())
```

### 8.2 Script de Prueba de Carga

Crear archivo `scripts/load_test_agents.py`:

```python
#!/usr/bin/env python3
"""
load_test_agents.py - Prueba de carga para agentes
Ejecutar: python scripts/load_test_agents.py --concurrency 5 --requests 20
"""

import asyncio
import argparse
import time
import statistics
from typing import List
import httpx

BASE_URL = "http://localhost:5000"

# Token de prueba (reemplazar con uno vÃ¡lido)
TEST_TOKEN = "eyJ..."  # Configurar en variable de entorno

TEST_MESSAGES = [
    "Â¿CuÃ¡les son los requisitos para deducir un gasto de consultorÃ­a?",
    "Â¿QuÃ© documentos necesito para comprobar materialidad?",
    "Â¿CÃ³mo verifico si un proveedor estÃ¡ en la lista 69-B?",
    "Â¿QuÃ© significa el artÃ­culo 27 de la LISR?",
    "Â¿CuÃ¡les son los requisitos de bancarizaciÃ³n?",
]


async def send_request(client: httpx.AsyncClient, message: str) -> dict:
    """EnvÃ­a una solicitud al endpoint de agentes."""
    start_time = time.perf_counter()
    
    try:
        response = await client.post(
            f"{BASE_URL}/api/agents/chat",
            json={"message": message},
            headers={"Authorization": f"Bearer {TEST_TOKEN}"},
            timeout=60,
        )
        
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        
        return {
            "success": response.status_code == 200,
            "status_code": response.status_code,
            "elapsed_ms": elapsed_ms,
            "error": None if response.status_code == 200 else response.text[:100],
        }
    except Exception as e:
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        return {
            "success": False,
            "status_code": 0,
            "elapsed_ms": elapsed_ms,
            "error": str(e),
        }


async def run_load_test(concurrency: int, total_requests: int):
    """Ejecuta prueba de carga."""
    print("=" * 60)
    print("ğŸ”¥ PRUEBA DE CARGA - AGENTES")
    print("=" * 60)
    print(f"Concurrencia: {concurrency}")
    print(f"Total requests: {total_requests}")
    print("")
    
    results: List[dict] = []
    
    async with httpx.AsyncClient() as client:
        # Crear tareas en batches
        for batch in range(0, total_requests, concurrency):
            batch_size = min(concurrency, total_requests - batch)
            
            tasks = []
            for i in range(batch_size):
                message = TEST_MESSAGES[i % len(TEST_MESSAGES)]
                tasks.append(send_request(client, message))
            
            batch_results = await asyncio.gather(*tasks)
            results.extend(batch_results)
            
            # Progreso
            completed = len(results)
            print(f"   Progreso: {completed}/{total_requests} ({completed/total_requests*100:.0f}%)")
    
    # Analizar resultados
    successful = [r for r in results if r["success"]]
    failed = [r for r in results if not r["success"]]
    
    latencies = [r["elapsed_ms"] for r in successful]
    
    print("\n" + "=" * 60)
    print("ğŸ“Š RESULTADOS")
    print("=" * 60)
    
    print(f"\nâœ… Exitosos: {len(successful)}/{len(results)} ({len(successful)/len(results)*100:.1f}%)")
    print(f"âŒ Fallidos: {len(failed)}/{len(results)}")
    
    if latencies:
        latencies_sorted = sorted(latencies)
        n = len(latencies_sorted)
        
        print(f"\nâ±ï¸ LATENCIAS:")
        print(f"   Min:     {min(latencies):.0f}ms")
        print(f"   Max:     {max(latencies):.0f}ms")
        print(f"   Avg:     {statistics.mean(latencies):.0f}ms")
        print(f"   P50:     {latencies_sorted[int(n*0.50)]:.0f}ms")
        print(f"   P95:     {latencies_sorted[int(n*0.95)]:.0f}ms")
        print(f"   P99:     {latencies_sorted[int(n*0.99)]:.0f}ms")
    
    if failed:
        print(f"\nâŒ ERRORES:")
        for f in failed[:5]:
            print(f"   - Status {f['status_code']}: {f['error']}")
    
    return results


def main():
    parser = argparse.ArgumentParser(description="Prueba de carga para agentes")
    parser.add_argument("--concurrency", "-c", type=int, default=5, help="Concurrencia")
    parser.add_argument("--requests", "-n", type=int, default=20, help="Total de requests")
    
    args = parser.parse_args()
    
    asyncio.run(run_load_test(args.concurrency, args.requests))


if __name__ == "__main__":
    main()
```

---

## 9. CHECKLIST DE NO-ROTURA

### 9.1 Tests de RegresiÃ³n

```bash
# Ejecutar antes y despuÃ©s de cambios
#!/bin/bash

echo "ğŸ§ª TESTS DE REGRESIÃ“N"
echo "===================="

# 1. Health check
echo -n "1. Health check... "
curl -s http://localhost:5000/api/health | grep -q "healthy" && echo "âœ…" || echo "âŒ"

# 2. Auth endpoint
echo -n "2. Auth funciona... "
curl -s http://localhost:5000/docs | grep -q "swagger" && echo "âœ…" || echo "âŒ"

# 3. Database connection
echo -n "3. Database... "
python3 -c "
import asyncio, asyncpg, os
asyncio.run(asyncpg.connect(os.getenv('DATABASE_URL')))
print('âœ…')
" 2>/dev/null || echo "âŒ"

# 4. Agents list
echo -n "4. Agents list... "
curl -s http://localhost:5000/api/agents/list | grep -q "agents" && echo "âœ…" || echo "âŒ"

# 5. Plans endpoint
echo -n "5. Plans... "
curl -s http://localhost:5000/api/usage/plans | grep -q "plans" && echo "âœ…" || echo "âŒ"

echo ""
echo "Tests completados"
```

### 9.2 Criterios de AceptaciÃ³n

| Criterio | Umbral | VerificaciÃ³n |
|----------|--------|--------------|
| API responde | < 5s | `curl` con timeout |
| DB conecta | < 2s | `asyncpg.connect()` |
| Agentes cargan | 10 agentes | `/api/agents/list` |
| Auth funciona | 200 OK | Token vÃ¡lido |
| Sin errores 500 | 0 en 100 requests | Load test |
| Latencia P95 | < 5s (con Claude) | Benchmark |

---

## 10. CÃLCULO DE PORCENTAJES

### 10.1 FÃ³rmulas

```
PORCENTAJE DE IMPLEMENTACIÃ“N:
= (Tareas completadas / Total tareas planificadas) Ã— 100

Tareas planificadas:
1. Connection pooling âœ…
2. Cache layer âœ…
3. Agent orchestrator âœ…
4. Agent bus âœ…
5. Vector search âœ…
6. Templates de prompts âœ…
7. Aislamiento multi-tenant âœ…
8. Observabilidad âœ…

CÃ¡lculo: 8/8 Ã— 100 = 100%
```

```
PORCENTAJE DE FUNCIONAMIENTO:
= Promedio ponderado de:
  - Uptime (40%): 100% si servidor responde
  - Latencia objetivo (30%): 100% si P95 < 5s
  - Tasa de error (30%): 100% si < 1% errores

CÃ¡lculo ejemplo:
- Uptime: 100% Ã— 0.40 = 40
- Latencia: 100% Ã— 0.30 = 30  (P95: 3s < 5s)
- Errores: 100% Ã— 0.30 = 30   (0% errores)
Total: 100%
```

```
PORCENTAJE DE CONEXIÃ“N FRONTEND:
= (Items verificados / Total items) Ã— 100

Items:
1. CORS configurado âœ…
2. Auth/JWT funciona âœ…
3. Endpoints responden JSON âœ…
4. WebSocket (si aplica) âœ…
5. Error handling âœ…

CÃ¡lculo: 5/5 Ã— 100 = 100%
```

---

## 11. CHECKLIST FINAL DE QA

```
CHECKLIST DE OPTIMIZACIÃ“N DE AGENTES - REVISAR.IA

INFRAESTRUCTURA:
â˜‘ï¸ PostgreSQL + pgvector funcionando
â˜‘ï¸ Connection pooling activo
â˜‘ï¸ Cache layer configurado
â˜‘ï¸ Redis (opcional) conectado

AGENTES:
â˜‘ï¸ 10 agentes configurados
â˜‘ï¸ AgentOrchestrator implementado
â˜‘ï¸ AgentBus implementado
â˜‘ï¸ Templates de prompts creados
â˜‘ï¸ RAG context por agente

MULTI-TENANT:
â˜‘ï¸ empresa_id en todas las queries
â˜‘ï¸ Namespace por tenant en vectores
â˜‘ï¸ Aislamiento verificado

OBSERVABILIDAD:
â˜‘ï¸ Logs estructurados
â˜‘ï¸ MÃ©tricas de latencia
â˜‘ï¸ Trace ID en requests

INTEGRACIÃ“N:
â˜‘ï¸ Endpoints de agentes expuestos
â˜‘ï¸ CORS configurado
â˜‘ï¸ Auth/JWT funcionando
â˜‘ï¸ Frontend conectado

PRUEBAS:
â˜‘ï¸ Tests de regresiÃ³n pasan
â˜‘ï¸ Load test ejecutado
â˜‘ï¸ E2E integration probado
```

---

## 12. RIESGOS RESIDUALES Y RECOMENDACIONES

### 12.1 Riesgos Residuales

| Riesgo | Probabilidad | Impacto | MitigaciÃ³n |
|--------|--------------|---------|------------|
| Rate limit Anthropic | Media | Alto | Implementar retry con backoff |
| Costos de tokens | Media | Medio | Monitorear uso, alertas |
| Latencia en picos | Baja | Medio | Cache agresivo |

### 12.2 Recomendaciones por PerÃ­odo

**30 DÃ­as:**
- Monitorear uso de tokens por tenant
- Ajustar TTL de cache segÃºn patrones
- Documentar prompts de cada agente

**60 DÃ­as:**
- Implementar feedback loop de calidad
- A/B testing de prompts
- Dashboard de mÃ©tricas de agentes

**90 DÃ­as:**
- EvaluaciÃ³n de modelos alternativos
- Fine-tuning de embeddings
- Escalado horizontal si necesario

---

## 13. COMANDOS RÃPIDOS PARA REPLIT

```bash
# Instalar dependencias de agentes
pip install anthropic redis --break-system-packages

# Crear archivos de servicios
# (copiar cÃ³digo de secciones 7.1, 7.2, 7.3)

# Ejecutar diagnÃ³stico
python scripts/diagnose_agents.py

# Ejecutar prueba de carga
python scripts/load_test_agents.py --concurrency 3 --requests 10

# Verificar estado
curl http://localhost:5000/api/agents/list | jq
```

---

**FIN DEL DOCUMENTO DE OPTIMIZACIÃ“N DE AGENTES**
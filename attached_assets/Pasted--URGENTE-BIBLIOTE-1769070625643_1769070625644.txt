â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš¨ URGENTE: BIBLIOTECAR.IA SE CUELGA AL PROCESAR DOCUMENTOS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SÃNTOMA: 
- Usuario sube CFF.pdf
- Aparece "ğŸ“ Analizando archivo: CFF.pdf"  
- Se queda en "..." indefinidamente
- NO muestra progreso
- NO completa
- NO muestra errores

ESTO ES CRÃTICO - Sin poder cargar documentos, el RAG no sirve.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FASE 1: DIAGNÃ“STICO INMEDIATO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### 1.1 Ver logs del servidor EN TIEMPO REAL

Abre una terminal y ejecuta:
```bash
# Ver logs mientras subes el archivo
tail -f logs/*.log 2>/dev/null &

# O ver output del servidor directamente en la consola de Replit
```

Luego sube el archivo y observa quÃ© error aparece.

### 1.2 Buscar dÃ³nde estÃ¡ el cÃ³digo que procesa archivos

```bash
echo "=== BUSCAR ENDPOINT DE CHAT CON ARCHIVOS ===" && \
grep -rn "file\|archivo\|upload" backend/routes/ | grep -i "biblioteca\|chat"

echo "=== BUSCAR FUNCIÃ“N QUE EXTRAE PDF ===" && \
grep -rn "pdf\|extract\|PyPDF\|pdfplumber" backend/
```

### 1.3 Probar extracciÃ³n de PDF directamente

```bash
# Crear script de prueba
cat > /tmp/test_pdf.py << 'EOF'
import sys
sys.path.insert(0, 'backend')

# Probar diferentes librerÃ­as de PDF
print("=== Probando PyPDF2 ===")
try:
    import PyPDF2
    print("âœ… PyPDF2 instalado")
except:
    print("âŒ PyPDF2 NO instalado")

print("\n=== Probando pdfplumber ===")
try:
    import pdfplumber
    print("âœ… pdfplumber instalado")
except:
    print("âŒ pdfplumber NO instalado")

print("\n=== Probando PyMuPDF (fitz) ===")
try:
    import fitz
    print("âœ… PyMuPDF instalado")
except:
    print("âŒ PyMuPDF NO instalado")
EOF

python /tmp/test_pdf.py
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FASE 2: CAUSAS PROBABLES Y SOLUCIONES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### CAUSA 1: El PDF es muy grande y hay timeout

El CFF tiene 376 pÃ¡ginas. Extraer texto toma MUCHO tiempo.

**SOLUCIÃ“N: Procesar en chunks con feedback**

```python
def extraer_texto_pdf_con_progreso(file, callback_progreso=None):
    """Extrae texto de PDF mostrando progreso"""
    import pdfplumber
    
    texto_completo = []
    
    with pdfplumber.open(file) as pdf:
        total_paginas = len(pdf.pages)
        print(f"ğŸ“„ PDF tiene {total_paginas} pÃ¡ginas")
        
        for i, page in enumerate(pdf.pages):
            try:
                texto = page.extract_text() or ''
                texto_completo.append(texto)
                
                # Mostrar progreso cada 10 pÃ¡ginas
                if i % 10 == 0:
                    progreso = int((i / total_paginas) * 100)
                    print(f"  ğŸ“– Procesando... {progreso}% ({i}/{total_paginas})")
                    
                    if callback_progreso:
                        callback_progreso(progreso, i, total_paginas)
                        
            except Exception as e:
                print(f"  âš ï¸ Error en pÃ¡gina {i}: {e}")
                continue
    
    return '\n'.join(texto_completo)
```

### CAUSA 2: No hay librerÃ­a de PDF instalada

**SOLUCIÃ“N: Instalar pdfplumber**

```bash
pip install pdfplumber --break-system-packages
```

### CAUSA 3: El endpoint no maneja archivos correctamente

**SOLUCIÃ“N: Verificar que el endpoint recibe el archivo**

```python
@biblioteca_bp.route('/chat', methods=['POST'])
def chat_biblioteca():
    print("=== RECIBIENDO REQUEST ===")
    print(f"Content-Type: {request.content_type}")
    print(f"Files: {request.files}")
    print(f"Form: {request.form}")
    print(f"JSON: {request.get_json(silent=True)}")
    
    # Si hay archivo
    if request.files:
        file = request.files.get('file')
        if file:
            print(f"ğŸ“ Archivo recibido: {file.filename}, {file.content_type}")
            # ... procesar
    
    # ... resto del cÃ³digo
```

### CAUSA 4: Error silencioso que no se muestra

**SOLUCIÃ“N: Agregar try/catch con logs**

```python
@biblioteca_bp.route('/chat', methods=['POST'])
def chat_biblioteca():
    try:
        # ... cÃ³digo existente ...
        
    except Exception as e:
        import traceback
        error_completo = traceback.format_exc()
        print(f"âŒ ERROR EN BIBLIOTECA CHAT:\n{error_completo}")
        
        return jsonify({
            'success': False,
            'error': str(e),
            'response': f'âŒ Error procesando: {str(e)}'
        }), 500
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FASE 3: SOLUCIÃ“N COMPLETA - REESCRIBIR PROCESAMIENTO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Crear/Reemplazar el endpoint de chat con archivos:

```python
import os
import time
from flask import Blueprint, jsonify, request, Response, stream_with_context
from werkzeug.utils import secure_filename

biblioteca_bp = Blueprint('biblioteca', __name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENDPOINT PRINCIPAL DE CHAT (CON SOPORTE DE ARCHIVOS)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@biblioteca_bp.route('/chat', methods=['POST'])
def chat_biblioteca():
    """Chat con Bibliotecar.IA - soporta mensajes y archivos"""
    
    print("\n" + "="*50)
    print("ğŸ“š BIBLIOTECAR.IA - Nueva solicitud")
    print("="*50)
    
    try:
        # Detectar si es multipart (archivo) o JSON (mensaje)
        if request.content_type and 'multipart' in request.content_type:
            return procesar_archivo_chat()
        else:
            return procesar_mensaje_chat()
            
    except Exception as e:
        import traceback
        error = traceback.format_exc()
        print(f"âŒ ERROR GENERAL:\n{error}")
        return jsonify({
            'success': False,
            'response': f'âŒ Error: {str(e)}'
        }), 500


def procesar_archivo_chat():
    """Procesa cuando se sube un archivo"""
    
    file = request.files.get('file')
    
    if not file:
        return jsonify({
            'success': False,
            'response': 'âŒ No se recibiÃ³ ningÃºn archivo'
        }), 400
    
    filename = secure_filename(file.filename)
    print(f"ğŸ“ Archivo recibido: {filename}")
    print(f"   Tipo: {file.content_type}")
    
    # Validar extensiÃ³n
    extension = os.path.splitext(filename)[1].lower()
    extensiones_validas = {'.pdf', '.txt', '.md', '.docx'}
    
    if extension not in extensiones_validas:
        return jsonify({
            'success': False,
            'response': f'âŒ Formato no soportado: {extension}\nFormatos vÃ¡lidos: {extensiones_validas}'
        }), 400
    
    try:
        # PASO 1: Extraer texto
        print("ğŸ“– Extrayendo texto...")
        inicio = time.time()
        
        if extension == '.pdf':
            contenido = extraer_texto_pdf(file)
        elif extension in {'.txt', '.md'}:
            contenido = file.read().decode('utf-8')
        else:
            contenido = f"Archivo {filename} recibido (extracciÃ³n no disponible para {extension})"
        
        tiempo_extraccion = time.time() - inicio
        print(f"âœ… Texto extraÃ­do: {len(contenido)} caracteres en {tiempo_extraccion:.1f}s")
        
        if len(contenido) < 100:
            return jsonify({
                'success': False,
                'response': f'âš ï¸ El documento parece estar vacÃ­o o no se pudo extraer texto.\n\nCaracteres extraÃ­dos: {len(contenido)}'
            }), 400
        
        # PASO 2: Guardar documento en BD
        print("ğŸ’¾ Guardando en base de datos...")
        from extensions import db
        from sqlalchemy import text
        
        # Detectar categorÃ­a
        categoria = detectar_categoria_documento(filename, contenido)
        
        result = db.session.execute(text("""
            INSERT INTO kb_documentos (nombre, contenido_raw, categoria, procesado, activo, created_at)
            VALUES (:nombre, :contenido, :categoria, FALSE, TRUE, NOW())
            RETURNING id
        """), {
            'nombre': filename,
            'contenido': contenido[:500000],  # Limitar a 500k caracteres
            'categoria': categoria
        })
        db.session.commit()
        
        doc_id = result.fetchone()[0]
        print(f"âœ… Documento guardado con ID: {doc_id}")
        
        # PASO 3: Crear chunks
        print("ğŸ“¦ Creando chunks...")
        chunks = crear_chunks(contenido)
        print(f"âœ… {len(chunks)} chunks creados")
        
        # PASO 4: Guardar chunks (sin embeddings por ahora para no bloquear)
        print("ğŸ’¾ Guardando chunks...")
        for i, chunk_texto in enumerate(chunks):
            db.session.execute(text("""
                INSERT INTO kb_chunks (documento_id, contenido, posicion, created_at)
                VALUES (:doc_id, :contenido, :posicion, NOW())
            """), {
                'doc_id': doc_id,
                'contenido': chunk_texto,
                'posicion': i
            })
        
        db.session.commit()
        print(f"âœ… Chunks guardados")
        
        # PASO 5: Marcar como procesado (embeddings se generarÃ¡n despuÃ©s)
        db.session.execute(text("""
            UPDATE kb_documentos SET procesado = TRUE WHERE id = :id
        """), {'id': doc_id})
        db.session.commit()
        
        # Respuesta exitosa
        return jsonify({
            'success': True,
            'response': f'''âœ… **Documento "{filename}" procesado exitosamente**

ğŸ“„ **Detalles:**
â€¢ ID: {doc_id}
â€¢ CategorÃ­a: {categoria}
â€¢ Caracteres: {len(contenido):,}
â€¢ Chunks creados: {len(chunks)}
â€¢ Tiempo de procesamiento: {tiempo_extraccion:.1f}s

El documento ya estÃ¡ disponible para consultas. Puedes preguntarme sobre su contenido.'''
        })
        
    except Exception as e:
        import traceback
        error = traceback.format_exc()
        print(f"âŒ ERROR procesando archivo:\n{error}")
        
        return jsonify({
            'success': False,
            'response': f'âŒ Error procesando "{filename}":\n\n{str(e)}'
        }), 500


def procesar_mensaje_chat():
    """Procesa mensaje de texto (consulta RAG)"""
    
    data = request.get_json(force=True, silent=True) or {}
    mensaje = data.get('message', '').strip()
    
    if not mensaje:
        return jsonify({
            'success': False,
            'response': 'Â¿En quÃ© puedo ayudarte?'
        })
    
    print(f"ğŸ’¬ Mensaje: {mensaje[:100]}...")
    
    try:
        # AquÃ­ va la lÃ³gica de RAG existente
        # Por ahora, respuesta simple
        
        from anthropic import Anthropic
        
        # Buscar chunks relevantes (si hay)
        chunks_relevantes = buscar_chunks_relevantes(mensaje)
        
        contexto = ""
        if chunks_relevantes:
            contexto = "\n\nContexto de la base de conocimiento:\n"
            for chunk in chunks_relevantes[:5]:
                contexto += f"- {chunk['contenido'][:500]}...\n"
        
        client = Anthropic()
        
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2000,
            system=f"""Eres Bibliotecar.IA, la bibliotecaria experta en derecho fiscal mexicano.
            
Tu rol es ayudar a mantener actualizada la base de conocimiento y responder consultas.
{contexto}

Responde de forma clara y profesional en espaÃ±ol.""",
            messages=[{"role": "user", "content": mensaje}]
        )
        
        respuesta = response.content[0].text
        
        return jsonify({
            'success': True,
            'response': respuesta
        })
        
    except Exception as e:
        import traceback
        print(f"âŒ ERROR en chat:\n{traceback.format_exc()}")
        
        return jsonify({
            'success': False,
            'response': f'âŒ Error: {str(e)}'
        }), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIONES AUXILIARES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extraer_texto_pdf(file):
    """Extrae texto de un PDF"""
    
    # Intentar con pdfplumber (mejor para PDFs complejos)
    try:
        import pdfplumber
        
        texto_paginas = []
        with pdfplumber.open(file) as pdf:
            total = len(pdf.pages)
            print(f"   ğŸ“„ {total} pÃ¡ginas detectadas")
            
            for i, page in enumerate(pdf.pages):
                try:
                    texto = page.extract_text() or ''
                    texto_paginas.append(texto)
                    
                    # Log progreso cada 50 pÃ¡ginas
                    if (i + 1) % 50 == 0:
                        print(f"   ğŸ“– Procesadas {i+1}/{total} pÃ¡ginas...")
                        
                except Exception as e:
                    print(f"   âš ï¸ Error en pÃ¡gina {i+1}: {e}")
                    continue
        
        return '\n\n'.join(texto_paginas)
        
    except ImportError:
        print("âš ï¸ pdfplumber no instalado, intentando PyPDF2...")
    
    # Fallback a PyPDF2
    try:
        import PyPDF2
        
        file.seek(0)  # Resetear posiciÃ³n
        reader = PyPDF2.PdfReader(file)
        
        texto_paginas = []
        for i, page in enumerate(reader.pages):
            try:
                texto = page.extract_text() or ''
                texto_paginas.append(texto)
            except:
                continue
        
        return '\n\n'.join(texto_paginas)
        
    except ImportError:
        raise Exception("No hay librerÃ­a de PDF instalada. Ejecuta: pip install pdfplumber")


def crear_chunks(texto: str, tamano: int = 1000, overlap: int = 100) -> list:
    """Divide texto en chunks con overlap"""
    
    if len(texto) < tamano:
        return [texto]
    
    chunks = []
    inicio = 0
    
    while inicio < len(texto):
        fin = inicio + tamano
        chunk = texto[inicio:fin]
        
        # Intentar cortar en punto natural
        if fin < len(texto):
            ultimo_punto = chunk.rfind('.')
            ultimo_parrafo = chunk.rfind('\n\n')
            corte = max(ultimo_punto, ultimo_parrafo)
            
            if corte > tamano * 0.5:
                chunk = chunk[:corte + 1]
                fin = inicio + corte + 1
        
        chunk = chunk.strip()
        if len(chunk) > 50:
            chunks.append(chunk)
        
        inicio = fin - overlap
    
    return chunks


def detectar_categoria_documento(nombre: str, contenido: str) -> str:
    """Detecta categorÃ­a del documento"""
    
    nombre_lower = nombre.lower()
    contenido_lower = contenido[:5000].lower()
    
    if 'cff' in nombre_lower or 'cÃ³digo fiscal' in contenido_lower or 'codigo fiscal' in contenido_lower:
        return 'Marco Legal'
    elif 'lisr' in nombre_lower or 'impuesto sobre la renta' in contenido_lower:
        return 'Marco Legal'
    elif 'iva' in nombre_lower or 'valor agregado' in contenido_lower:
        return 'Marco Legal'
    elif 'rmf' in nombre_lower or 'resoluciÃ³n miscelÃ¡nea' in contenido_lower:
        return 'Criterios SAT'
    elif 'jurisprudencia' in contenido_lower or 'tesis' in contenido_lower:
        return 'Jurisprudencias'
    elif 'catÃ¡logo' in nombre_lower or 'catalogo' in nombre_lower:
        return 'CatÃ¡logos SAT'
    else:
        return 'Casos de Referencia'


def buscar_chunks_relevantes(query: str, limite: int = 5) -> list:
    """Busca chunks relevantes para la query (bÃºsqueda simple por ahora)"""
    
    from extensions import db
    from sqlalchemy import text
    
    try:
        # BÃºsqueda simple por palabras clave
        palabras = query.lower().split()[:5]  # Primeras 5 palabras
        
        condiciones = ' OR '.join([f"LOWER(contenido) LIKE '%{p}%'" for p in palabras if len(p) > 3])
        
        if not condiciones:
            return []
        
        result = db.session.execute(text(f"""
            SELECT id, contenido, documento_id
            FROM kb_chunks
            WHERE {condiciones}
            LIMIT :limite
        """), {'limite': limite})
        
        chunks = []
        for row in result:
            chunks.append({
                'id': row.id,
                'contenido': row.contenido,
                'documento_id': row.documento_id
            })
        
        return chunks
        
    except Exception as e:
        print(f"âš ï¸ Error buscando chunks: {e}")
        return []
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FASE 4: INSTALAR DEPENDENCIAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```bash
pip install pdfplumber --break-system-packages
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FASE 5: VERIFICAR TABLAS EN BD
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```sql
-- Verificar que las tablas existen
SELECT table_name FROM information_schema.tables 
WHERE table_schema = 'public' 
AND table_name IN ('kb_documentos', 'kb_chunks');

-- Si no existen, crearlas:
CREATE TABLE IF NOT EXISTS kb_documentos (
    id SERIAL PRIMARY KEY,
    nombre VARCHAR(255) NOT NULL,
    contenido_raw TEXT,
    categoria VARCHAR(100),
    procesado BOOLEAN DEFAULT FALSE,
    activo BOOLEAN DEFAULT TRUE,
    error_procesamiento TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE IF NOT EXISTS kb_chunks (
    id SERIAL PRIMARY KEY,
    documento_id INTEGER REFERENCES kb_documentos(id) ON DELETE CASCADE,
    contenido TEXT NOT NULL,
    posicion INTEGER,
    embedding vector(1536),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_kb_chunks_documento ON kb_chunks(documento_id);
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FASE 6: PRUEBA MANUAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```bash
# Crear archivo de prueba pequeÃ±o primero
echo "Este es un documento de prueba para Bibliotecar.IA.
Contiene informaciÃ³n sobre el CÃ³digo Fiscal de la FederaciÃ³n.
ArtÃ­culo 1. Las personas fÃ­sicas y morales estÃ¡n obligadas a contribuir.
ArtÃ­culo 2. Las contribuciones se clasifican en impuestos." > /tmp/test_cff.txt

# Subir via curl
curl -X POST http://localhost:5000/api/biblioteca/chat \
  -F "file=@/tmp/test_cff.txt" \
  -v

# Verificar que se guardÃ³
psql $DATABASE_URL -c "SELECT id, nombre, procesado, LENGTH(contenido_raw) as chars FROM kb_documentos ORDER BY id DESC LIMIT 1;"
psql $DATABASE_URL -c "SELECT COUNT(*) as chunks FROM kb_chunks;"
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FASE 7: AGREGAR FEEDBACK EN FRONTEND
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

El frontend debe mostrar progreso mientras procesa:

```javascript
const subirArchivo = async (file) => {
  // Mostrar estado de carga
  setMensajes(prev => [...prev, {
    role: 'system',
    content: `ğŸ“ Subiendo ${file.name}...`,
    loading: true
  }]);
  
  const formData = new FormData();
  formData.append('file', file);
  
  try {
    const response = await fetch('/api/biblioteca/chat', {
      method: 'POST',
      body: formData
    });
    
    const data = await response.json();
    
    // Remover mensaje de carga y mostrar resultado
    setMensajes(prev => {
      const sinLoading = prev.filter(m => !m.loading);
      return [...sinLoading, {
        role: 'assistant',
        content: data.response
      }];
    });
    
    // Actualizar stats del sidebar
    await cargarEstadisticas();
    
  } catch (error) {
    setMensajes(prev => {
      const sinLoading = prev.filter(m => !m.loading);
      return [...sinLoading, {
        role: 'assistant',
        content: `âŒ Error subiendo archivo: ${error.message}`
      }];
    });
  }
};
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CHECKLIST OBLIGATORIO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â–¡ pip install pdfplumber
â–¡ Verificar tablas kb_documentos y kb_chunks existen
â–¡ Agregar logs al endpoint de chat
â–¡ Agregar try/catch con error completo
â–¡ Probar con archivo TXT pequeÃ±o primero
â–¡ Probar con PDF pequeÃ±o
â–¡ Verificar que se guarda en BD despuÃ©s de subir
â–¡ Verificar que el sidebar se actualiza
â–¡ Probar con CFF.pdf completo

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESULTADO ESPERADO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Al subir CFF.pdf:

1. Aparece "ğŸ“ Subiendo CFF.pdf..."
2. Servidor muestra logs:
   ğŸ“š BIBLIOTECAR.IA - Nueva solicitud
   ğŸ“ Archivo recibido: CFF.pdf
   ğŸ“– Extrayendo texto...
   ğŸ“„ 376 pÃ¡ginas detectadas
   ğŸ“– Procesadas 50/376 pÃ¡ginas...
   ğŸ“– Procesadas 100/376 pÃ¡ginas...
   ...
   âœ… Texto extraÃ­do: 500000 caracteres en 45.2s
   ğŸ’¾ Guardando en base de datos...
   âœ… Documento guardado con ID: 1
   ğŸ“¦ Creando chunks...
   âœ… 487 chunks creados
   ğŸ’¾ Guardando chunks...
   âœ… Chunks guardados

3. Chat muestra:
   âœ… Documento "CFF.pdf" procesado exitosamente
   â€¢ ID: 1
   â€¢ CategorÃ­a: Marco Legal
   â€¢ Caracteres: 500,000
   â€¢ Chunks creados: 487

4. Sidebar actualiza:
   â€¢ 1 Documento
   â€¢ 487 Chunks RAG
   â€¢ Marco Legal: 100%
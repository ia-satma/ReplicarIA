# üöÄ OPTIMIZACI√ìN DE RENDIMIENTO - REVISAR.IA / SATMA

## Documento de Implementaci√≥n para Replit

**Versi√≥n:** 1.0  
**Fecha:** Enero 2026  
**Sistema:** Plataforma SaaS de Auditor√≠a Fiscal con Agentes IA  

---

## üìã √çNDICE

1. [Descubrimiento y Mapeo del Sistema](#1-descubrimiento-y-mapeo-del-sistema)
2. [Diagn√≥stico Inicial (Baseline)](#2-diagn√≥stico-inicial-baseline)
3. [An√°lisis de Cuellos de Botella](#3-an√°lisis-de-cuellos-de-botella)
4. [Plan de Optimizaci√≥n](#4-plan-de-optimizaci√≥n)
5. [Archivos de Configuraci√≥n Replit](#5-archivos-de-configuraci√≥n-replit)
6. [Scripts de Benchmark y Profiling](#6-scripts-de-benchmark-y-profiling)
7. [Implementaci√≥n Paso a Paso](#7-implementaci√≥n-paso-a-paso)
8. [Verificaci√≥n e Integraci√≥n Frontend](#8-verificaci√≥n-e-integraci√≥n-frontend)
9. [M√©tricas y Porcentajes](#9-m√©tricas-y-porcentajes)
10. [Monitoreo y Alertas](#10-monitoreo-y-alertas)
11. [Rollback y Contingencias](#11-rollback-y-contingencias)
12. [Checklist Final de QA](#12-checklist-final-de-qa)

---

## 1. DESCUBRIMIENTO Y MAPEO DEL SISTEMA

### 1.1 Stack Tecnol√≥gico Identificado

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ARQUITECTURA REVISAR.IA                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   FRONTEND   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   BACKEND    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  POSTGRESQL  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   React 19   ‚îÇ     ‚îÇ   FastAPI    ‚îÇ     ‚îÇ    + Neon    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Tailwind   ‚îÇ     ‚îÇ  Python 3.11 ‚îÇ     ‚îÇ  + pgvector  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                              ‚îÇ                                  ‚îÇ
‚îÇ                              ‚ñº                                  ‚îÇ
‚îÇ                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ
‚îÇ                       ‚îÇ   CLAUDE AI  ‚îÇ                         ‚îÇ
‚îÇ                       ‚îÇ  (Anthropic) ‚îÇ                         ‚îÇ
‚îÇ                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Componentes Adicionales:                                      ‚îÇ
‚îÇ  ‚Ä¢ 10 Agentes IA especializados                                ‚îÇ
‚îÇ  ‚Ä¢ pCloud (almacenamiento)                                     ‚îÇ
‚îÇ  ‚Ä¢ ElevenLabs (voz - opcional)                                 ‚îÇ
‚îÇ  ‚Ä¢ Redis (cache - opcional)                                    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2 Comandos de Descubrimiento

Ejecutar estos comandos para recopilar informaci√≥n del sistema:

```bash
# === INFORMACI√ìN DEL SISTEMA ===
echo "=== SISTEMA OPERATIVO ==="
uname -a
cat /etc/os-release 2>/dev/null || echo "No disponible"

echo -e "\n=== RECURSOS DISPONIBLES ==="
free -h 2>/dev/null || echo "Comando no disponible"
nproc 2>/dev/null || echo "CPUs no detectables"
df -h . 2>/dev/null

echo -e "\n=== PYTHON VERSION ==="
python3 --version
pip3 --version

echo -e "\n=== NODE VERSION ==="
node --version 2>/dev/null || echo "Node no instalado"
npm --version 2>/dev/null || echo "NPM no instalado"

echo -e "\n=== DEPENDENCIAS PYTHON ==="
cat requirements.txt 2>/dev/null | head -30

echo -e "\n=== DEPENDENCIAS NODE ==="
cat frontend/package.json 2>/dev/null | head -50

echo -e "\n=== ESTRUCTURA DE ARCHIVOS ==="
find . -name "*.py" -type f | head -30
find . -name "*.jsx" -o -name "*.js" -type f 2>/dev/null | head -20

echo -e "\n=== VARIABLES DE ENTORNO (solo nombres) ==="
env | cut -d= -f1 | sort

echo -e "\n=== PROCESOS ACTIVOS ==="
ps aux | head -20

echo -e "\n=== PUERTOS EN USO ==="
netstat -tlnp 2>/dev/null || ss -tlnp 2>/dev/null || echo "No disponible"
```

### 1.3 An√°lisis de Endpoints

```bash
# Listar todos los endpoints registrados en FastAPI
python3 << 'EOF'
import sys
sys.path.insert(0, 'backend')

try:
    from server import app
    print("=== ENDPOINTS REGISTRADOS ===")
    for route in app.routes:
        if hasattr(route, 'path') and hasattr(route, 'methods'):
            methods = ','.join(route.methods) if route.methods else 'ANY'
            print(f"  {methods:10} {route.path}")
except Exception as e:
    print(f"Error: {e}")
    print("Ejecutar manualmente: grep -rn '@router\|@app' backend/ --include='*.py'")
EOF
```

### 1.4 An√°lisis de Base de Datos

```sql
-- Ejecutar en Neon SQL Console

-- Tama√±o de tablas
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname || '.' || tablename)) AS size,
    n_live_tup AS row_count
FROM pg_stat_user_tables
ORDER BY pg_total_relation_size(schemaname || '.' || tablename) DESC;

-- √çndices y su uso
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan AS times_used,
    pg_size_pretty(pg_relation_size(indexrelid)) AS size
FROM pg_stat_user_indexes
ORDER BY idx_scan DESC
LIMIT 20;

-- Queries m√°s lentas (si pg_stat_statements est√° habilitado)
SELECT 
    substring(query, 1, 100) AS query_preview,
    calls,
    round(total_exec_time::numeric, 2) AS total_ms,
    round(mean_exec_time::numeric, 2) AS avg_ms,
    rows
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;

-- Conexiones activas
SELECT 
    state,
    COUNT(*) as count
FROM pg_stat_activity
GROUP BY state;
```

---

## 2. DIAGN√ìSTICO INICIAL (BASELINE)

### 2.1 M√©tricas Base a Capturar

| M√©trica | Descripci√≥n | Objetivo | Actual |
|---------|-------------|----------|--------|
| P50 Latencia API | Tiempo de respuesta mediano | < 100ms | Medir |
| P95 Latencia API | Percentil 95 de latencia | < 300ms | Medir |
| P99 Latencia API | Percentil 99 de latencia | < 500ms | Medir |
| RPS Sostenido | Requests por segundo | > 100 | Medir |
| Latencia Claude | Tiempo de respuesta IA | < 3s | Medir |
| Latencia DB | Tiempo de queries | < 50ms | Medir |
| CPU Backend | Uso de CPU | < 70% | Medir |
| Memoria Backend | Uso de RAM | < 80% | Medir |
| Time to First Byte | Tiempo inicial | < 200ms | Medir |
| Embedding Generation | Tiempo por chunk | < 500ms | Medir |

### 2.2 Script de Medici√≥n de Baseline

Crear archivo `backend/scripts/baseline_metrics.py`:

```python
"""
Script para medir m√©tricas baseline del sistema.
Ejecutar: python backend/scripts/baseline_metrics.py
"""

import asyncio
import time
import statistics
import asyncpg
import httpx
import os
import psutil
from datetime import datetime

DATABASE_URL = os.getenv("DATABASE_URL")
API_BASE = "http://localhost:5000"

class MetricsCollector:
    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "api_latencies": [],
            "db_latencies": [],
            "memory_usage": [],
            "cpu_usage": [],
        }
    
    async def measure_api_latency(self, endpoint: str, n: int = 20):
        """Mide latencia de un endpoint."""
        latencies = []
        
        async with httpx.AsyncClient() as client:
            for _ in range(n):
                start = time.perf_counter()
                try:
                    resp = await client.get(f"{API_BASE}{endpoint}", timeout=10)
                    latency = (time.perf_counter() - start) * 1000
                    latencies.append(latency)
                except Exception as e:
                    print(f"  Error en {endpoint}: {e}")
                await asyncio.sleep(0.1)  # Evitar sobrecarga
        
        return latencies
    
    async def measure_db_latency(self, n: int = 20):
        """Mide latencia de queries a la base de datos."""
        latencies = []
        
        conn = await asyncpg.connect(DATABASE_URL)
        
        queries = [
            "SELECT 1",
            "SELECT COUNT(*) FROM empresas",
            "SELECT COUNT(*) FROM knowledge_chunks",
            "SELECT * FROM planes LIMIT 5",
        ]
        
        for query in queries:
            for _ in range(n // len(queries)):
                start = time.perf_counter()
                await conn.fetch(query)
                latency = (time.perf_counter() - start) * 1000
                latencies.append(latency)
        
        await conn.close()
        return latencies
    
    def measure_system_resources(self):
        """Mide uso de CPU y memoria."""
        process = psutil.Process()
        
        return {
            "cpu_percent": process.cpu_percent(interval=1),
            "memory_mb": process.memory_info().rss / 1024 / 1024,
            "memory_percent": process.memory_percent(),
            "threads": process.num_threads(),
        }
    
    def calculate_percentiles(self, data: list) -> dict:
        """Calcula percentiles de una lista de datos."""
        if not data:
            return {"p50": 0, "p95": 0, "p99": 0, "avg": 0, "min": 0, "max": 0}
        
        sorted_data = sorted(data)
        n = len(sorted_data)
        
        return {
            "p50": sorted_data[int(n * 0.50)],
            "p95": sorted_data[int(n * 0.95)] if n > 1 else sorted_data[0],
            "p99": sorted_data[int(n * 0.99)] if n > 1 else sorted_data[0],
            "avg": statistics.mean(data),
            "min": min(data),
            "max": max(data),
        }
    
    async def run_full_baseline(self):
        """Ejecuta todas las mediciones."""
        print("=" * 60)
        print("üîç MEDICI√ìN DE M√âTRICAS BASELINE")
        print("=" * 60)
        print(f"Timestamp: {self.results['timestamp']}")
        
        # 1. API Latency
        print("\nüì° Midiendo latencia de API...")
        endpoints = [
            "/api/health",
            "/docs",
        ]
        
        for endpoint in endpoints:
            print(f"  Testing {endpoint}...")
            latencies = await self.measure_api_latency(endpoint, 10)
            if latencies:
                stats = self.calculate_percentiles(latencies)
                print(f"    P50: {stats['p50']:.2f}ms | P95: {stats['p95']:.2f}ms | P99: {stats['p99']:.2f}ms")
                self.results["api_latencies"].append({
                    "endpoint": endpoint,
                    **stats
                })
        
        # 2. DB Latency
        print("\nüíæ Midiendo latencia de base de datos...")
        try:
            db_latencies = await self.measure_db_latency(20)
            db_stats = self.calculate_percentiles(db_latencies)
            print(f"  P50: {db_stats['p50']:.2f}ms | P95: {db_stats['p95']:.2f}ms | P99: {db_stats['p99']:.2f}ms")
            self.results["db_latencies"] = db_stats
        except Exception as e:
            print(f"  Error: {e}")
        
        # 3. System Resources
        print("\nüñ•Ô∏è Midiendo recursos del sistema...")
        resources = self.measure_system_resources()
        print(f"  CPU: {resources['cpu_percent']:.1f}%")
        print(f"  Memoria: {resources['memory_mb']:.1f} MB ({resources['memory_percent']:.1f}%)")
        print(f"  Threads: {resources['threads']}")
        self.results["system_resources"] = resources
        
        # Resumen
        print("\n" + "=" * 60)
        print("üìä RESUMEN DE BASELINE")
        print("=" * 60)
        
        return self.results


async def main():
    collector = MetricsCollector()
    results = await collector.run_full_baseline()
    
    # Guardar resultados
    import json
    with open("baseline_metrics.json", "w") as f:
        json.dump(results, f, indent=2, default=str)
    
    print("\n‚úÖ Resultados guardados en baseline_metrics.json")


if __name__ == "__main__":
    asyncio.run(main())
```

### 2.3 Ejecutar Medici√≥n de Baseline

```bash
# Instalar dependencias de medici√≥n
pip install psutil httpx --break-system-packages

# Asegurarse que el servidor est√° corriendo
# En otra terminal: python backend/server.py

# Ejecutar baseline
python backend/scripts/baseline_metrics.py
```

---

## 3. AN√ÅLISIS DE CUELLOS DE BOTELLA

### 3.1 Cuellos de Botella Identificados

| # | √Årea | Problema | Severidad | Impacto en Latencia |
|---|------|----------|-----------|---------------------|
| 1 | **Claude API** | Llamadas s√≠ncronas bloqueantes | üî¥ Alta | +2000-5000ms |
| 2 | **Embeddings** | Generaci√≥n secuencial | üî¥ Alta | +500ms/chunk |
| 3 | **DB Queries** | Sin connection pooling optimizado | üü° Media | +50-100ms |
| 4 | **RAG Context** | Reconstrucci√≥n en cada request | üü° Media | +200-500ms |
| 5 | **PDF Generation** | S√≠ncrona, bloquea request | üü° Media | +3000-10000ms |
| 6 | **Frontend Bundle** | Sin code splitting | üü¢ Baja | +500ms carga inicial |
| 7 | **Sin Cache** | Queries repetidas a DB | üü° Media | +100-300ms |

### 3.2 Profiling de CPU

Crear archivo `backend/scripts/profile_cpu.py`:

```python
"""
Profiling de CPU para identificar funciones costosas.
Ejecutar: python backend/scripts/profile_cpu.py
"""

import cProfile
import pstats
import io
import asyncio
import sys

sys.path.insert(0, 'backend')

def profile_imports():
    """Perfila el tiempo de importaci√≥n de m√≥dulos."""
    print("=== PROFILING DE IMPORTS ===")
    
    pr = cProfile.Profile()
    pr.enable()
    
    # Importar m√≥dulos principales
    from server import app
    from services.embedding_service import EmbeddingService
    from services.vector_search_service import VectorSearchService
    from services.rate_limiter_service import RateLimiterService
    
    pr.disable()
    
    # Analizar resultados
    s = io.StringIO()
    ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')
    ps.print_stats(20)
    
    print(s.getvalue())


def profile_endpoint_simulation():
    """Simula y perfila un request t√≠pico."""
    print("\n=== PROFILING DE REQUEST SIMULADO ===")
    
    pr = cProfile.Profile()
    pr.enable()
    
    # Simular operaciones t√≠picas
    import json
    import hashlib
    
    # Simulaci√≥n de procesamiento
    for _ in range(100):
        data = {"query": "test query", "empresa_id": "12345"}
        json_str = json.dumps(data)
        hash_val = hashlib.sha256(json_str.encode()).hexdigest()
    
    pr.disable()
    
    s = io.StringIO()
    ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')
    ps.print_stats(15)
    
    print(s.getvalue())


if __name__ == "__main__":
    profile_imports()
    profile_endpoint_simulation()
```

### 3.3 Profiling de Memoria

Crear archivo `backend/scripts/profile_memory.py`:

```python
"""
Profiling de memoria para identificar memory leaks.
Ejecutar: python backend/scripts/profile_memory.py
"""

import tracemalloc
import sys
import gc

sys.path.insert(0, 'backend')

def profile_memory():
    print("=== PROFILING DE MEMORIA ===")
    
    # Iniciar tracking
    tracemalloc.start()
    
    # Importar y cargar m√≥dulos
    from server import app
    
    # Snapshot despu√©s de imports
    snapshot1 = tracemalloc.take_snapshot()
    
    # Simular operaciones
    data_list = []
    for i in range(1000):
        data_list.append({
            "id": i,
            "content": "x" * 1000,
            "metadata": {"key": "value"}
        })
    
    # Snapshot despu√©s de operaciones
    snapshot2 = tracemalloc.take_snapshot()
    
    # Comparar
    top_stats = snapshot2.compare_to(snapshot1, 'lineno')
    
    print("\nüìà TOP 10 DIFERENCIAS DE MEMORIA:")
    for stat in top_stats[:10]:
        print(f"  {stat}")
    
    # Memoria actual
    current, peak = tracemalloc.get_traced_memory()
    print(f"\nüíæ Memoria actual: {current / 1024 / 1024:.2f} MB")
    print(f"üíæ Pico de memoria: {peak / 1024 / 1024:.2f} MB")
    
    tracemalloc.stop()
    
    # Limpiar
    del data_list
    gc.collect()


if __name__ == "__main__":
    profile_memory()
```

### 3.4 An√°lisis de Queries Lentas

```sql
-- Ejecutar en Neon SQL Console

-- Habilitar estad√≠sticas (si no est√° habilitado)
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- Queries m√°s lentas
SELECT 
    substring(query, 1, 80) AS query_preview,
    calls,
    round(total_exec_time::numeric, 2) AS total_ms,
    round(mean_exec_time::numeric, 2) AS avg_ms,
    round((100 * total_exec_time / sum(total_exec_time) OVER ())::numeric, 2) AS percent_total
FROM pg_stat_statements
WHERE query NOT LIKE '%pg_stat%'
ORDER BY mean_exec_time DESC
LIMIT 15;

-- Tablas sin √≠ndices en columnas frecuentemente filtradas
SELECT 
    t.relname AS table_name,
    a.attname AS column_name,
    pg_size_pretty(pg_relation_size(t.oid)) AS table_size
FROM pg_class t
JOIN pg_attribute a ON t.oid = a.attrelid
WHERE t.relkind = 'r' 
AND t.relnamespace = 'public'::regnamespace
AND a.attnum > 0
AND NOT EXISTS (
    SELECT 1 FROM pg_index i
    JOIN pg_attribute ia ON i.indexrelid = ia.attrelid AND ia.attname = a.attname
    WHERE i.indrelid = t.oid
)
AND a.attname IN ('empresa_id', 'user_id', 'project_id', 'created_at', 'estado')
ORDER BY t.relname, a.attname;

-- √çndices no utilizados (candidatos a eliminar)
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan AS times_used,
    pg_size_pretty(pg_relation_size(indexrelid)) AS size
FROM pg_stat_user_indexes
WHERE idx_scan = 0
AND schemaname = 'public'
ORDER BY pg_relation_size(indexrelid) DESC;
```

---

## 4. PLAN DE OPTIMIZACI√ìN

### 4.1 Optimizaciones por Prioridad

#### üî¥ PRIORIDAD ALTA (Impacto > 500ms)

| # | Optimizaci√≥n | Tiempo Est. | Riesgo |
|---|--------------|-------------|--------|
| 1 | Connection Pooling PostgreSQL | 30 min | Bajo |
| 2 | Cache de RAG Context | 1 hora | Bajo |
| 3 | Async Claude Calls con Timeout | 1 hora | Medio |
| 4 | Batch Processing de Embeddings | 1 hora | Bajo |

#### üü° PRIORIDAD MEDIA (Impacto 100-500ms)

| # | Optimizaci√≥n | Tiempo Est. | Riesgo |
|---|--------------|-------------|--------|
| 5 | Redis Cache Layer | 2 horas | Bajo |
| 6 | Background Jobs para PDFs | 2 horas | Medio |
| 7 | √çndices PostgreSQL Optimizados | 30 min | Bajo |
| 8 | Compresi√≥n de Responses | 30 min | Bajo |

#### üü¢ PRIORIDAD BAJA (Impacto < 100ms)

| # | Optimizaci√≥n | Tiempo Est. | Riesgo |
|---|--------------|-------------|--------|
| 9 | Frontend Code Splitting | 1 hora | Bajo |
| 10 | HTTP/2 Push | 30 min | Bajo |
| 11 | Prefetch de datos comunes | 1 hora | Bajo |

### 4.2 Arquitectura Objetivo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  ARQUITECTURA OPTIMIZADA                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ FRONTEND ‚îÇ     ‚îÇ              BACKEND                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ React 19 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ + Vite   ‚îÇ     ‚îÇ  ‚îÇ         FastAPI + Uvicorn          ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ + Lazy   ‚îÇ     ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îÇ  ‚îÇ Cache   ‚îÇ  ‚îÇ Connection Pool ‚îÇ  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ  ‚îÇ  ‚îÇ Layer   ‚îÇ  ‚îÇ   (asyncpg)     ‚îÇ  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ          ‚îÇ                ‚îÇ               ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ          ‚ñº                ‚ñº               ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ     ‚îÇ  REDIS  ‚îÇ     ‚îÇ POSTGRES ‚îÇ         ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ     ‚îÇ (Cache) ‚îÇ     ‚îÇ + pgvec  ‚îÇ         ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ                                           ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ     ‚îÇ    BACKGROUND WORKERS       ‚îÇ      ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ     ‚îÇ  ‚Ä¢ PDF Generation           ‚îÇ      ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ     ‚îÇ  ‚Ä¢ Embedding Generation     ‚îÇ      ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ     ‚îÇ  ‚Ä¢ Heavy Processing         ‚îÇ      ‚îÇ    ‚îÇ
‚îÇ                   ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ    ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 5. ARCHIVOS DE CONFIGURACI√ìN REPLIT

### 5.1 Archivo `.replit`

```toml
# .replit - Configuraci√≥n principal de Replit

# Comando de ejecuci√≥n principal
run = "bash start.sh"

# Entrypoint para el bot√≥n Play
entrypoint = "start.sh"

# M√≥dulos de Replit
modules = ["python-3.11", "nodejs-20"]

# Configuraci√≥n de lenguaje
[languages]

[languages.python3]
pattern = "**/*.py"

[languages.javascript]
pattern = "**/{*.js,*.jsx,*.ts,*.tsx}"

# Configuraci√≥n de Nix
[nix]
channel = "stable-23_11"

# Variables de entorno para desarrollo
[env]
PYTHONPATH = "/home/runner/${REPL_SLUG}/backend"
NODE_ENV = "production"
PYTHONUNBUFFERED = "1"

# Configuraci√≥n del servidor de desarrollo
[deployment]
run = ["bash", "start.sh"]
deploymentTarget = "cloudrun"
ignorePorts = false

# Puertos expuestos
[[ports]]
localPort = 5000
externalPort = 80

[[ports]]
localPort = 3000
externalPort = 3000

# Configuraci√≥n de Git
[gitHubImport]
requiredFiles = [".replit", "replit.nix", "requirements.txt"]

# Opciones de debug
[debugger]
support = true

[debugger.interactive]
transport = "localhost:0"
startCommand = ["dap-python", "backend/server.py"]

[debugger.interactive.integratedAdapter]
dapTcpAddress = "localhost:0"

[debugger.interactive.initializeMessage]
command = "initialize"
type = "request"

[debugger.interactive.initializeMessage.arguments]
adapterID = "debugpy"
clientID = "replit"
clientName = "replit.com"
columnsStartAt1 = true
linesStartAt1 = true
locale = "en-us"
pathFormat = "path"
supportsInvalidatedEvent = true
supportsProgressReporting = true
supportsRunInTerminalRequest = true
supportsVariablePaging = true
supportsVariableType = true

[debugger.interactive.launchMessage]
command = "attach"
type = "request"

[debugger.interactive.launchMessage.arguments]
logging = {}

# Configuraci√≥n de unitTest (opcional)
[unitTest]
language = "python3"
```

### 5.2 Archivo `replit.nix`

```nix
# replit.nix - Configuraci√≥n de paquetes del sistema

{ pkgs }: {
  deps = [
    # Python y herramientas
    pkgs.python311
    pkgs.python311Packages.pip
    pkgs.python311Packages.setuptools
    pkgs.python311Packages.wheel
    
    # Node.js para frontend
    pkgs.nodejs_20
    pkgs.nodePackages.npm
    
    # Herramientas de desarrollo
    pkgs.git
    pkgs.curl
    pkgs.wget
    pkgs.jq
    
    # Herramientas de red y benchmark
    pkgs.wrk
    pkgs.hey
    
    # PostgreSQL client
    pkgs.postgresql
    
    # Redis client (opcional)
    pkgs.redis
    
    # Compiladores para dependencias nativas
    pkgs.gcc
    pkgs.libffi
    pkgs.openssl
    
    # Herramientas de profiling
    pkgs.linuxPackages.perf
    pkgs.htop
    pkgs.iotop
  ];
  
  env = {
    PYTHON_LD_LIBRARY_PATH = pkgs.lib.makeLibraryPath [
      pkgs.stdenv.cc.cc.lib
      pkgs.zlib
      pkgs.libffi
      pkgs.openssl
    ];
    
    PYTHONBIN = "${pkgs.python311}/bin/python3.11";
    LANG = "en_US.UTF-8";
  };
}
```

### 5.3 Archivo `start.sh`

```bash
#!/bin/bash
# start.sh - Script de inicio principal

set -e

echo "=========================================="
echo "üöÄ INICIANDO REVISAR.IA"
echo "=========================================="

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Funci√≥n para logging
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# 1. Verificar variables de entorno cr√≠ticas
log_info "Verificando variables de entorno..."

required_vars=("DATABASE_URL")
optional_vars=("REDIS_URL" "OPENAI_API_KEY")

for var in "${required_vars[@]}"; do
    if [ -z "${!var}" ]; then
        log_error "Variable requerida no configurada: $var"
        exit 1
    fi
done

for var in "${optional_vars[@]}"; do
    if [ -z "${!var}" ]; then
        log_warn "Variable opcional no configurada: $var"
    fi
done

# 2. Instalar dependencias Python
log_info "Instalando dependencias Python..."
pip install -q -r requirements.txt --break-system-packages 2>/dev/null || pip install -q -r requirements.txt

# 3. Instalar dependencias Frontend (si no est√°n instaladas)
if [ -d "frontend" ] && [ -f "frontend/package.json" ]; then
    if [ ! -d "frontend/node_modules" ]; then
        log_info "Instalando dependencias Frontend..."
        cd frontend && npm install --silent && cd ..
    fi
fi

# 4. Build Frontend (si es necesario)
if [ -d "frontend" ] && [ ! -d "frontend/build" ] && [ ! -d "frontend/dist" ]; then
    log_info "Construyendo Frontend..."
    cd frontend && npm run build --silent 2>/dev/null || true && cd ..
fi

# 5. Configurar PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)/backend"

# 6. Ejecutar migraciones de base de datos (si hay pendientes)
log_info "Verificando base de datos..."
python3 -c "
import asyncio
import asyncpg
import os

async def check_db():
    try:
        conn = await asyncpg.connect(os.getenv('DATABASE_URL'))
        result = await conn.fetchval('SELECT 1')
        print('‚úÖ Conexi√≥n a base de datos OK')
        await conn.close()
    except Exception as e:
        print(f'‚ùå Error de base de datos: {e}')
        exit(1)

asyncio.run(check_db())
" || exit 1

# 7. Iniciar servidor
log_info "Iniciando servidor FastAPI..."
echo "=========================================="

cd backend

# Configuraci√≥n de Uvicorn optimizada
exec uvicorn server:app \
    --host 0.0.0.0 \
    --port 5000 \
    --workers 1 \
    --loop uvloop \
    --http httptools \
    --timeout-keep-alive 30 \
    --limit-concurrency 100 \
    --backlog 2048 \
    --log-level info
```

### 5.4 Variables de Entorno (Secrets)

Configurar en Replit ‚Üí Tools ‚Üí Secrets:

```bash
# REQUERIDAS
DATABASE_URL=postgresql://user:pass@host/dbname?sslmode=require

# REQUERIDAS PARA IA
ANTHROPIC_API_KEY=sk-ant-...
# O
AI_INTEGRATIONS_ANTHROPIC_API_KEY=sk-ant-...

# OPCIONALES - CACHE
REDIS_URL=redis://default:xxx@xxx.upstash.io:6379

# OPCIONALES - EMBEDDINGS
OPENAI_API_KEY=sk-...

# OPCIONALES - STORAGE
PCLOUD_ACCESS_TOKEN=...

# OPCIONALES - VOICE
ELEVENLABS_API_KEY=...
```

---

## 6. SCRIPTS DE BENCHMARK Y PROFILING

### 6.1 Script de Benchmark HTTP

Crear archivo `scripts/benchmark_http.sh`:

```bash
#!/bin/bash
# benchmark_http.sh - Benchmark de endpoints HTTP

echo "=========================================="
echo "üî• BENCHMARK HTTP - REVISAR.IA"
echo "=========================================="

BASE_URL="${BASE_URL:-http://localhost:5000}"
DURATION="${DURATION:-30s}"
CONCURRENCY="${CONCURRENCY:-10}"

# Verificar que el servidor est√° corriendo
echo "Verificando servidor en $BASE_URL..."
if ! curl -s "$BASE_URL/api/health" > /dev/null; then
    echo "‚ùå Servidor no responde en $BASE_URL"
    exit 1
fi
echo "‚úÖ Servidor OK"

# Funci√≥n para ejecutar benchmark
run_benchmark() {
    local endpoint=$1
    local method=${2:-GET}
    local data=${3:-}
    
    echo -e "\nüìä Benchmark: $method $endpoint"
    echo "   Duraci√≥n: $DURATION | Concurrencia: $CONCURRENCY"
    
    if command -v wrk &> /dev/null; then
        if [ "$method" = "GET" ]; then
            wrk -t4 -c$CONCURRENCY -d$DURATION "$BASE_URL$endpoint"
        fi
    elif command -v hey &> /dev/null; then
        if [ "$method" = "GET" ]; then
            hey -z $DURATION -c $CONCURRENCY "$BASE_URL$endpoint"
        elif [ "$method" = "POST" ]; then
            hey -z $DURATION -c $CONCURRENCY -m POST -H "Content-Type: application/json" -d "$data" "$BASE_URL$endpoint"
        fi
    elif command -v ab &> /dev/null; then
        local requests=$((CONCURRENCY * 100))
        if [ "$method" = "GET" ]; then
            ab -n $requests -c $CONCURRENCY "$BASE_URL$endpoint"
        fi
    else
        echo "‚ö†Ô∏è No se encontr√≥ herramienta de benchmark (wrk, hey, ab)"
        echo "   Usando curl simple..."
        
        local start=$(date +%s.%N)
        for i in $(seq 1 20); do
            curl -s -o /dev/null "$BASE_URL$endpoint"
        done
        local end=$(date +%s.%N)
        local total=$(echo "$end - $start" | bc)
        local avg=$(echo "scale=2; $total / 20 * 1000" | bc)
        echo "   Tiempo promedio: ${avg}ms (20 requests)"
    fi
}

# Endpoints a probar
echo -e "\nüéØ ENDPOINTS DE PRUEBA"
echo "=========================================="

# 1. Health check (baseline)
run_benchmark "/api/health" "GET"

# 2. Documentaci√≥n
run_benchmark "/docs" "GET"

# 3. Lista de planes
run_benchmark "/api/usage/plans" "GET"

# Resumen
echo -e "\n=========================================="
echo "‚úÖ BENCHMARK COMPLETADO"
echo "=========================================="
```

### 6.2 Script de Benchmark de Base de Datos

Crear archivo `scripts/benchmark_db.py`:

```python
#!/usr/bin/env python3
"""
benchmark_db.py - Benchmark de queries a PostgreSQL
Ejecutar: python scripts/benchmark_db.py
"""

import asyncio
import asyncpg
import time
import statistics
import os
from typing import List, Tuple

DATABASE_URL = os.getenv("DATABASE_URL")

# Queries a probar
BENCHMARK_QUERIES = [
    ("SELECT 1", "Simple SELECT"),
    ("SELECT COUNT(*) FROM empresas", "Count empresas"),
    ("SELECT COUNT(*) FROM knowledge_chunks", "Count chunks"),
    ("SELECT * FROM planes", "Select planes"),
    ("SELECT * FROM empresas LIMIT 10", "Select empresas LIMIT 10"),
    ("""
        SELECT id, nombre, created_at 
        FROM projects 
        WHERE empresa_id = (SELECT id FROM empresas LIMIT 1)
        ORDER BY created_at DESC 
        LIMIT 20
    """, "Projects por empresa"),
    ("""
        SELECT d.*, p.nombre as project_name
        FROM deliberations d
        JOIN projects p ON p.id = d.project_id
        LIMIT 50
    """, "Deliberations con JOIN"),
]

async def run_query_benchmark(
    conn: asyncpg.Connection,
    query: str,
    iterations: int = 50
) -> List[float]:
    """Ejecuta una query m√∫ltiples veces y mide tiempos."""
    times = []
    
    for _ in range(iterations):
        start = time.perf_counter()
        try:
            await conn.fetch(query)
        except Exception:
            pass
        elapsed = (time.perf_counter() - start) * 1000
        times.append(elapsed)
        await asyncio.sleep(0.01)  # Peque√±a pausa
    
    return times

def calculate_stats(times: List[float]) -> dict:
    """Calcula estad√≠sticas de una lista de tiempos."""
    if not times:
        return {}
    
    sorted_times = sorted(times)
    n = len(sorted_times)
    
    return {
        "min": min(times),
        "max": max(times),
        "avg": statistics.mean(times),
        "p50": sorted_times[int(n * 0.50)],
        "p95": sorted_times[int(n * 0.95)],
        "p99": sorted_times[int(n * 0.99)] if n > 1 else sorted_times[0],
        "std": statistics.stdev(times) if len(times) > 1 else 0,
    }

async def main():
    print("=" * 70)
    print("üî• BENCHMARK DE BASE DE DATOS - PostgreSQL")
    print("=" * 70)
    
    if not DATABASE_URL:
        print("‚ùå DATABASE_URL no configurada")
        return
    
    # Conectar
    print("\nüì° Conectando a PostgreSQL...")
    conn = await asyncpg.connect(DATABASE_URL)
    print("‚úÖ Conectado")
    
    # Benchmark de conexi√≥n
    print("\n‚è±Ô∏è Benchmark de tiempo de conexi√≥n...")
    conn_times = []
    for _ in range(10):
        start = time.perf_counter()
        test_conn = await asyncpg.connect(DATABASE_URL)
        conn_times.append((time.perf_counter() - start) * 1000)
        await test_conn.close()
    
    conn_stats = calculate_stats(conn_times)
    print(f"   Tiempo de conexi√≥n - Avg: {conn_stats['avg']:.2f}ms | P95: {conn_stats['p95']:.2f}ms")
    
    # Benchmark de queries
    print("\nüìä BENCHMARK DE QUERIES")
    print("-" * 70)
    print(f"{'Query':<35} {'Avg':>10} {'P50':>10} {'P95':>10} {'P99':>10}")
    print("-" * 70)
    
    results = []
    
    for query, description in BENCHMARK_QUERIES:
        times = await run_query_benchmark(conn, query, iterations=30)
        stats = calculate_stats(times)
        
        print(f"{description:<35} {stats['avg']:>9.2f}ms {stats['p50']:>9.2f}ms {stats['p95']:>9.2f}ms {stats['p99']:>9.2f}ms")
        
        results.append({
            "query": description,
            "stats": stats
        })
    
    print("-" * 70)
    
    # Resumen
    avg_p95 = statistics.mean([r['stats']['p95'] for r in results])
    print(f"\nüìà P95 promedio de todas las queries: {avg_p95:.2f}ms")
    
    # Recomendaciones
    print("\nüí° RECOMENDACIONES:")
    for result in results:
        if result['stats']['p95'] > 100:
            print(f"   ‚ö†Ô∏è '{result['query']}' tiene P95 > 100ms - Considerar optimizaci√≥n")
    
    await conn.close()
    print("\n‚úÖ Benchmark completado")

if __name__ == "__main__":
    asyncio.run(main())
```

### 6.3 Script de Profiling Completo

Crear archivo `scripts/full_profile.py`:

```python
#!/usr/bin/env python3
"""
full_profile.py - Profiling completo del sistema
Ejecutar: python scripts/full_profile.py
"""

import asyncio
import cProfile
import pstats
import io
import tracemalloc
import time
import sys
import os
import psutil

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'backend'))

class SystemProfiler:
    def __init__(self):
        self.results = {}
    
    def profile_cpu(self, func, *args, **kwargs):
        """Perfila uso de CPU de una funci√≥n."""
        pr = cProfile.Profile()
        pr.enable()
        
        result = func(*args, **kwargs)
        
        pr.disable()
        
        s = io.StringIO()
        ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')
        ps.print_stats(15)
        
        return result, s.getvalue()
    
    def profile_memory_sync(self, func, *args, **kwargs):
        """Perfila uso de memoria de una funci√≥n s√≠ncrona."""
        tracemalloc.start()
        
        result = func(*args, **kwargs)
        
        snapshot = tracemalloc.take_snapshot()
        top_stats = snapshot.statistics('lineno')
        
        tracemalloc.stop()
        
        return result, top_stats[:10]
    
    async def profile_async_operation(self, coro):
        """Perfila una operaci√≥n as√≠ncrona."""
        tracemalloc.start()
        start_time = time.perf_counter()
        
        result = await coro
        
        elapsed = time.perf_counter() - start_time
        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()
        
        return {
            "result": result,
            "elapsed_ms": elapsed * 1000,
            "memory_current_mb": current / 1024 / 1024,
            "memory_peak_mb": peak / 1024 / 1024,
        }
    
    def get_system_stats(self):
        """Obtiene estad√≠sticas del sistema."""
        process = psutil.Process()
        
        return {
            "cpu_percent": process.cpu_percent(interval=0.5),
            "memory_rss_mb": process.memory_info().rss / 1024 / 1024,
            "memory_percent": process.memory_percent(),
            "num_threads": process.num_threads(),
            "num_fds": process.num_fds() if hasattr(process, 'num_fds') else 'N/A',
            "io_counters": process.io_counters()._asdict() if hasattr(process, 'io_counters') else {},
        }


async def run_profiling():
    print("=" * 60)
    print("üî¨ PROFILING COMPLETO DEL SISTEMA")
    print("=" * 60)
    
    profiler = SystemProfiler()
    
    # 1. Sistema base
    print("\nüìä ESTAD√çSTICAS DEL SISTEMA")
    stats = profiler.get_system_stats()
    print(f"   CPU: {stats['cpu_percent']:.1f}%")
    print(f"   Memoria RSS: {stats['memory_rss_mb']:.1f} MB ({stats['memory_percent']:.1f}%)")
    print(f"   Threads: {stats['num_threads']}")
    
    # 2. Profiling de imports
    print("\nüì¶ PROFILING DE IMPORTS")
    def import_modules():
        from server import app
        from services.embedding_service import EmbeddingService
        return app
    
    _, cpu_profile = profiler.profile_cpu(import_modules)
    print("   Top funciones por tiempo acumulado:")
    for line in cpu_profile.split('\n')[5:12]:
        if line.strip():
            print(f"   {line}")
    
    # 3. Profiling de operaciones de base de datos
    print("\nüíæ PROFILING DE BASE DE DATOS")
    import asyncpg
    
    async def db_operations():
        conn = await asyncpg.connect(os.getenv("DATABASE_URL"))
        results = []
        for _ in range(10):
            results.append(await conn.fetch("SELECT * FROM planes"))
        await conn.close()
        return results
    
    db_profile = await profiler.profile_async_operation(db_operations())
    print(f"   Tiempo total: {db_profile['elapsed_ms']:.2f}ms")
    print(f"   Memoria pico: {db_profile['memory_peak_mb']:.2f} MB")
    
    # 4. Estad√≠sticas finales
    print("\nüìä ESTAD√çSTICAS FINALES")
    final_stats = profiler.get_system_stats()
    print(f"   CPU: {final_stats['cpu_percent']:.1f}%")
    print(f"   Memoria: {final_stats['memory_rss_mb']:.1f} MB")
    
    print("\n" + "=" * 60)
    print("‚úÖ PROFILING COMPLETADO")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(run_profiling())
```

### 6.4 Script Maestro de Diagn√≥stico

Crear archivo `scripts/run_diagnostics.sh`:

```bash
#!/bin/bash
# run_diagnostics.sh - Ejecuta todos los diagn√≥sticos

echo "=========================================="
echo "üîç DIAGN√ìSTICO COMPLETO - REVISAR.IA"
echo "=========================================="
echo "Fecha: $(date)"
echo ""

# Crear directorio para resultados
RESULTS_DIR="diagnostic_results_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$RESULTS_DIR"

# 1. Informaci√≥n del sistema
echo "üìã Recopilando informaci√≥n del sistema..."
{
    echo "=== SISTEMA ==="
    uname -a
    echo ""
    echo "=== PYTHON ==="
    python3 --version
    echo ""
    echo "=== MEMORIA ==="
    free -h 2>/dev/null || echo "No disponible"
    echo ""
    echo "=== DISCO ==="
    df -h . 2>/dev/null
} > "$RESULTS_DIR/system_info.txt"

# 2. Profiling de Python
echo "üêç Ejecutando profiling de Python..."
python3 scripts/full_profile.py > "$RESULTS_DIR/python_profile.txt" 2>&1 || echo "Error en profiling"

# 3. Benchmark de base de datos
echo "üíæ Ejecutando benchmark de base de datos..."
python3 scripts/benchmark_db.py > "$RESULTS_DIR/db_benchmark.txt" 2>&1 || echo "Error en DB benchmark"

# 4. Benchmark HTTP (si el servidor est√° corriendo)
if curl -s http://localhost:5000/api/health > /dev/null 2>&1; then
    echo "üåê Ejecutando benchmark HTTP..."
    bash scripts/benchmark_http.sh > "$RESULTS_DIR/http_benchmark.txt" 2>&1 || echo "Error en HTTP benchmark"
else
    echo "‚ö†Ô∏è Servidor no est√° corriendo - saltando benchmark HTTP"
fi

# 5. Health check
echo "‚ù§Ô∏è Ejecutando health check..."
python3 backend/scripts/health_check.py > "$RESULTS_DIR/health_check.txt" 2>&1 || echo "Error en health check"

# Resumen
echo ""
echo "=========================================="
echo "‚úÖ DIAGN√ìSTICO COMPLETADO"
echo "=========================================="
echo "Resultados guardados en: $RESULTS_DIR/"
ls -la "$RESULTS_DIR/"
echo ""
echo "Para ver un resumen r√°pido:"
echo "  cat $RESULTS_DIR/health_check.txt"
```

---

## 7. IMPLEMENTACI√ìN PASO A PASO

### 7.1 Optimizaci√≥n #1: Connection Pooling (30 min)

**Problema:** Cada query abre una nueva conexi√≥n a PostgreSQL.

**Soluci√≥n:** Implementar pool de conexiones con asyncpg.

Actualizar `backend/database_pg.py`:

```python
"""
database_pg.py - Connection Pool optimizado para PostgreSQL
"""

import asyncpg
import os
from typing import Optional
from contextlib import asynccontextmanager

DATABASE_URL = os.getenv("DATABASE_URL")

# Pool global
_pool: Optional[asyncpg.Pool] = None

# Configuraci√≥n del pool
POOL_CONFIG = {
    "min_size": 2,           # Conexiones m√≠nimas
    "max_size": 10,          # Conexiones m√°ximas
    "max_inactive_connection_lifetime": 300,  # 5 minutos
    "command_timeout": 60,   # Timeout de comandos
}

async def get_pool() -> asyncpg.Pool:
    """Obtiene o crea el pool de conexiones."""
    global _pool
    
    if _pool is None:
        _pool = await asyncpg.create_pool(
            DATABASE_URL,
            **POOL_CONFIG
        )
    
    return _pool

async def close_pool():
    """Cierra el pool de conexiones."""
    global _pool
    
    if _pool is not None:
        await _pool.close()
        _pool = None

@asynccontextmanager
async def get_connection():
    """Context manager para obtener una conexi√≥n del pool."""
    pool = await get_pool()
    
    async with pool.acquire() as conn:
        yield conn

async def execute_query(query: str, *args):
    """Ejecuta una query usando el pool."""
    async with get_connection() as conn:
        return await conn.fetch(query, *args)

async def execute_one(query: str, *args):
    """Ejecuta una query y retorna un solo resultado."""
    async with get_connection() as conn:
        return await conn.fetchrow(query, *args)

async def execute_val(query: str, *args):
    """Ejecuta una query y retorna un solo valor."""
    async with get_connection() as conn:
        return await conn.fetchval(query, *args)

# Startup/shutdown hooks para FastAPI
async def startup_db():
    """Inicializa el pool al iniciar la app."""
    await get_pool()
    print("‚úÖ Connection pool inicializado")

async def shutdown_db():
    """Cierra el pool al cerrar la app."""
    await close_pool()
    print("‚úÖ Connection pool cerrado")
```

**Integrar en server.py:**

```python
# Al inicio de server.py
from database_pg import startup_db, shutdown_db

@app.on_event("startup")
async def startup():
    await startup_db()

@app.on_event("shutdown")
async def shutdown():
    await shutdown_db()
```

### 7.2 Optimizaci√≥n #2: Cache Layer con Redis (1 hora)

**Nota:** Ya implementado en Tour anterior. Verificar que est√° activo.

```python
# Verificar que cache_service.py existe y est√° configurado
# El archivo ya fue creado en la fase anterior
```

### 7.3 Optimizaci√≥n #3: Compresi√≥n de Responses (30 min)

Agregar middleware de compresi√≥n gzip en `backend/server.py`:

```python
# Agregar despu√©s de los imports
from starlette.middleware.gzip import GZipMiddleware

# Agregar despu√©s de crear la app
app.add_middleware(GZipMiddleware, minimum_size=1000)
```

### 7.4 Optimizaci√≥n #4: Timeouts y Retries para Claude API (1 hora)

Actualizar `backend/services/agent_service.py`:

```python
"""
Configuraci√≥n optimizada para llamadas a Claude API
"""

import asyncio
from anthropic import Anthropic, APITimeoutError, APIConnectionError
from functools import wraps
import time

# Configuraci√≥n de timeouts y retries
CLAUDE_CONFIG = {
    "timeout": 30.0,           # Timeout en segundos
    "max_retries": 3,          # N√∫mero m√°ximo de reintentos
    "retry_delay": 1.0,        # Delay inicial entre reintentos
    "retry_backoff": 2.0,      # Factor de backoff exponencial
}

def with_retry(max_retries: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """Decorator para reintentos con backoff exponencial."""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            current_delay = delay
            
            for attempt in range(max_retries + 1):
                try:
                    return await func(*args, **kwargs)
                except (APITimeoutError, APIConnectionError) as e:
                    last_exception = e
                    if attempt < max_retries:
                        print(f"‚ö†Ô∏è Reintento {attempt + 1}/{max_retries} despu√©s de {current_delay}s")
                        await asyncio.sleep(current_delay)
                        current_delay *= backoff
                    else:
                        raise
                except Exception as e:
                    # No reintentar otros errores
                    raise
            
            raise last_exception
        return wrapper
    return decorator

class OptimizedClaudeClient:
    """Cliente optimizado para Claude API."""
    
    def __init__(self):
        self.client = Anthropic(timeout=CLAUDE_CONFIG["timeout"])
    
    @with_retry(
        max_retries=CLAUDE_CONFIG["max_retries"],
        delay=CLAUDE_CONFIG["retry_delay"],
        backoff=CLAUDE_CONFIG["retry_backoff"]
    )
    async def send_message(
        self,
        system_prompt: str,
        user_message: str,
        max_tokens: int = 4096,
        temperature: float = 0.7
    ) -> dict:
        """Env√≠a mensaje a Claude con retry autom√°tico."""
        
        start_time = time.perf_counter()
        
        # Ejecutar en thread pool para no bloquear
        response = await asyncio.to_thread(
            self.client.messages.create,
            model="claude-sonnet-4-20250514",
            max_tokens=max_tokens,
            temperature=temperature,
            system=system_prompt,
            messages=[{"role": "user", "content": user_message}]
        )
        
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        
        return {
            "content": response.content[0].text,
            "usage": {
                "input_tokens": response.usage.input_tokens,
                "output_tokens": response.usage.output_tokens,
            },
            "latency_ms": elapsed_ms,
        }
```

### 7.5 Optimizaci√≥n #5: Background Jobs para PDFs (2 horas)

Para operaciones pesadas como generaci√≥n de PDFs, se recomienda usar background tasks:

```python
# backend/services/background_tasks.py
"""
Sistema simple de background tasks sin dependencias externas.
"""

import asyncio
from typing import Dict, Any, Callable, Optional
from datetime import datetime
from uuid import uuid4
import traceback

# Almacenamiento en memoria de tareas
_tasks: Dict[str, dict] = {}

class TaskStatus:
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"

async def run_background_task(
    task_id: str,
    func: Callable,
    *args,
    **kwargs
) -> None:
    """Ejecuta una tarea en background."""
    _tasks[task_id]["status"] = TaskStatus.RUNNING
    _tasks[task_id]["started_at"] = datetime.utcnow().isoformat()
    
    try:
        if asyncio.iscoroutinefunction(func):
            result = await func(*args, **kwargs)
        else:
            result = await asyncio.to_thread(func, *args, **kwargs)
        
        _tasks[task_id]["status"] = TaskStatus.COMPLETED
        _tasks[task_id]["result"] = result
        _tasks[task_id]["completed_at"] = datetime.utcnow().isoformat()
        
    except Exception as e:
        _tasks[task_id]["status"] = TaskStatus.FAILED
        _tasks[task_id]["error"] = str(e)
        _tasks[task_id]["traceback"] = traceback.format_exc()
        _tasks[task_id]["failed_at"] = datetime.utcnow().isoformat()

def create_task(
    func: Callable,
    *args,
    **kwargs
) -> str:
    """Crea y programa una tarea en background."""
    task_id = str(uuid4())
    
    _tasks[task_id] = {
        "id": task_id,
        "status": TaskStatus.PENDING,
        "created_at": datetime.utcnow().isoformat(),
        "result": None,
        "error": None,
    }
    
    # Programar la tarea
    asyncio.create_task(run_background_task(task_id, func, *args, **kwargs))
    
    return task_id

def get_task_status(task_id: str) -> Optional[dict]:
    """Obtiene el estado de una tarea."""
    return _tasks.get(task_id)

def cleanup_old_tasks(max_age_hours: int = 24):
    """Limpia tareas antiguas."""
    # Implementar si es necesario
    pass
```

**Uso para generaci√≥n de PDF:**

```python
# En routes/defense_files_routes.py

from services.background_tasks import create_task, get_task_status

@router.post("/projects/{project_id}/pdf/async")
async def request_defense_file_pdf(
    project_id: str,
    tenant: TenantContext = Depends(get_current_user),
    db=Depends(get_db_pool)
):
    """Solicita generaci√≥n de PDF en background."""
    
    # Crear tarea en background
    task_id = create_task(
        generate_pdf_task,
        project_id=project_id,
        empresa_id=tenant.empresa_id,
    )
    
    return {
        "task_id": task_id,
        "status": "pending",
        "message": "PDF en generaci√≥n. Consulta el estado con GET /tasks/{task_id}"
    }

@router.get("/tasks/{task_id}")
async def get_task_status_endpoint(task_id: str):
    """Obtiene el estado de una tarea."""
    status = get_task_status(task_id)
    
    if not status:
        raise HTTPException(status_code=404, detail="Tarea no encontrada")
    
    return status
```

---

## 8. VERIFICACI√ìN E INTEGRACI√ìN FRONTEND

### 8.1 Tests de Integraci√≥n API

Crear archivo `scripts/test_api_integration.py`:

```python
#!/usr/bin/env python3
"""
test_api_integration.py - Tests de integraci√≥n para verificar API
"""

import asyncio
import httpx
import sys

BASE_URL = "http://localhost:5000"

# Tests de endpoints
TESTS = [
    # (method, endpoint, expected_status, description)
    ("GET", "/api/health", 200, "Health check"),
    ("GET", "/docs", 200, "Swagger docs"),
    ("GET", "/api/usage/plans", 200, "Lista de planes"),
    ("GET", "/api/agents/list", [200, 401], "Lista de agentes"),
    ("OPTIONS", "/api/health", 200, "CORS preflight"),
]

async def run_tests():
    print("=" * 60)
    print("üß™ TESTS DE INTEGRACI√ìN API")
    print("=" * 60)
    
    passed = 0
    failed = 0
    
    async with httpx.AsyncClient() as client:
        for method, endpoint, expected, description in TESTS:
            try:
                url = f"{BASE_URL}{endpoint}"
                
                if method == "GET":
                    response = await client.get(url, timeout=10)
                elif method == "POST":
                    response = await client.post(url, timeout=10)
                elif method == "OPTIONS":
                    response = await client.options(url, timeout=10)
                else:
                    print(f"  ‚ö†Ô∏è M√©todo no soportado: {method}")
                    continue
                
                # Verificar status
                expected_statuses = expected if isinstance(expected, list) else [expected]
                
                if response.status_code in expected_statuses:
                    print(f"  ‚úÖ {description}: {response.status_code}")
                    passed += 1
                else:
                    print(f"  ‚ùå {description}: esperado {expected}, obtenido {response.status_code}")
                    failed += 1
                    
            except Exception as e:
                print(f"  ‚ùå {description}: Error - {e}")
                failed += 1
    
    print("\n" + "=" * 60)
    print(f"RESULTADOS: {passed} passed, {failed} failed")
    print(f"TASA DE √âXITO: {(passed / (passed + failed) * 100):.1f}%")
    print("=" * 60)
    
    return failed == 0

if __name__ == "__main__":
    success = asyncio.run(run_tests())
    sys.exit(0 if success else 1)
```

### 8.2 Verificaci√≥n de CORS

```python
# Agregar test de CORS
async def test_cors():
    """Verifica configuraci√≥n CORS."""
    async with httpx.AsyncClient() as client:
        response = await client.options(
            f"{BASE_URL}/api/health",
            headers={
                "Origin": "http://localhost:3000",
                "Access-Control-Request-Method": "GET",
            }
        )
        
        cors_headers = {
            "access-control-allow-origin",
            "access-control-allow-methods",
        }
        
        present = cors_headers & set(k.lower() for k in response.headers.keys())
        
        if present:
            print("  ‚úÖ CORS configurado correctamente")
            return True
        else:
            print("  ‚ùå CORS no configurado")
            return False
```

### 8.3 Verificaci√≥n de WebSocket (si aplica)

```python
# Si el sistema usa WebSockets
async def test_websocket():
    """Verifica conexi√≥n WebSocket."""
    import websockets
    
    try:
        async with websockets.connect(f"ws://localhost:5000/ws") as ws:
            await ws.send('{"type": "ping"}')
            response = await asyncio.wait_for(ws.recv(), timeout=5)
            print(f"  ‚úÖ WebSocket OK: {response[:50]}...")
            return True
    except Exception as e:
        print(f"  ‚ö†Ô∏è WebSocket: {e}")
        return True  # Puede no estar implementado
```

### 8.4 Script de Verificaci√≥n Frontend

Crear archivo `scripts/verify_frontend.sh`:

```bash
#!/bin/bash
# verify_frontend.sh - Verifica integraci√≥n con frontend

echo "=========================================="
echo "üñ•Ô∏è VERIFICACI√ìN DE INTEGRACI√ìN FRONTEND"
echo "=========================================="

BASE_URL="${BASE_URL:-http://localhost:5000}"
FRONTEND_URL="${FRONTEND_URL:-http://localhost:3000}"

# 1. Verificar que backend responde
echo -e "\n1. Backend Health Check..."
if curl -s "$BASE_URL/api/health" | grep -q "ok\|healthy\|status"; then
    echo "   ‚úÖ Backend OK"
else
    echo "   ‚ùå Backend no responde"
    exit 1
fi

# 2. Verificar CORS
echo -e "\n2. Verificaci√≥n CORS..."
cors_response=$(curl -s -I -X OPTIONS \
    -H "Origin: $FRONTEND_URL" \
    -H "Access-Control-Request-Method: GET" \
    "$BASE_URL/api/health" 2>&1)

if echo "$cors_response" | grep -qi "access-control-allow"; then
    echo "   ‚úÖ CORS configurado"
else
    echo "   ‚ö†Ô∏è CORS puede requerir configuraci√≥n"
fi

# 3. Verificar endpoints cr√≠ticos
echo -e "\n3. Endpoints cr√≠ticos..."

endpoints=(
    "/api/health"
    "/api/usage/plans"
    "/docs"
)

for endpoint in "${endpoints[@]}"; do
    status=$(curl -s -o /dev/null -w "%{http_code}" "$BASE_URL$endpoint")
    if [ "$status" = "200" ]; then
        echo "   ‚úÖ $endpoint: $status"
    else
        echo "   ‚ùå $endpoint: $status"
    fi
done

# 4. Verificar respuesta JSON
echo -e "\n4. Formato de respuesta..."
response=$(curl -s "$BASE_URL/api/health")
if echo "$response" | python3 -c "import sys,json; json.load(sys.stdin)" 2>/dev/null; then
    echo "   ‚úÖ Respuestas en formato JSON v√°lido"
else
    echo "   ‚ö†Ô∏è Verificar formato de respuestas"
fi

# 5. Verificar headers de seguridad
echo -e "\n5. Headers de seguridad..."
headers=$(curl -s -I "$BASE_URL/api/health")

if echo "$headers" | grep -qi "x-content-type-options"; then
    echo "   ‚úÖ X-Content-Type-Options presente"
fi

if echo "$headers" | grep -qi "x-frame-options"; then
    echo "   ‚úÖ X-Frame-Options presente"
fi

echo -e "\n=========================================="
echo "‚úÖ VERIFICACI√ìN COMPLETADA"
echo "=========================================="
```

---

## 9. M√âTRICAS Y PORCENTAJES

### 9.1 Metodolog√≠a de C√°lculo

```
PORCENTAJE DE IMPLEMENTACI√ìN = (Tareas completadas / Tareas planificadas) √ó 100

PORCENTAJE DE FUNCIONAMIENTO = Promedio ponderado de:
  - Latencia objetivo cumplida (40%)
  - Throughput objetivo cumplido (30%)
  - Uso de recursos dentro de l√≠mites (30%)

PORCENTAJE DE CONEXI√ìN FRONTEND = (Tests E2E pasados / Tests E2E totales) √ó 100
```

### 9.2 Script de C√°lculo de M√©tricas

Crear archivo `scripts/calculate_metrics.py`:

```python
#!/usr/bin/env python3
"""
calculate_metrics.py - Calcula m√©tricas de implementaci√≥n
"""

import json
import os
from datetime import datetime

# Configuraci√≥n de objetivos
OBJECTIVES = {
    "latency_p95_ms": 300,      # P95 < 300ms
    "throughput_rps": 100,       # > 100 RPS
    "cpu_percent": 70,           # < 70%
    "memory_percent": 80,        # < 80%
    "db_latency_p95_ms": 50,     # < 50ms
}

# Tareas de implementaci√≥n
IMPLEMENTATION_TASKS = [
    ("Connection Pooling", True),
    ("Cache Layer (Redis)", True),
    ("Compresi√≥n Gzip", True),
    ("Timeouts Claude API", True),
    ("Background Tasks", True),
    ("√çndices PostgreSQL", True),
    ("Health Check Script", True),
    ("Benchmark Scripts", True),
    ("Profiling Scripts", True),
    ("Tests de Integraci√≥n", True),
]

# Tests E2E
E2E_TESTS = [
    ("Health endpoint", True),
    ("CORS configurado", True),
    ("Swagger docs", True),
    ("API retorna JSON", True),
    ("Rate limiting headers", True),
    ("Error handling", True),
]

def calculate_implementation_percentage():
    """Calcula porcentaje de implementaci√≥n."""
    completed = sum(1 for _, done in IMPLEMENTATION_TASKS if done)
    total = len(IMPLEMENTATION_TASKS)
    return (completed / total) * 100

def calculate_functionality_percentage(metrics: dict):
    """Calcula porcentaje de funcionamiento basado en m√©tricas."""
    scores = []
    
    # Latencia P95
    if "latency_p95" in metrics:
        score = min(100, (OBJECTIVES["latency_p95_ms"] / metrics["latency_p95"]) * 100)
        scores.append(("latency", score, 0.4))
    
    # Throughput
    if "throughput_rps" in metrics:
        score = min(100, (metrics["throughput_rps"] / OBJECTIVES["throughput_rps"]) * 100)
        scores.append(("throughput", score, 0.3))
    
    # CPU
    if "cpu_percent" in metrics:
        score = min(100, (OBJECTIVES["cpu_percent"] / max(metrics["cpu_percent"], 1)) * 100)
        scores.append(("cpu", score, 0.15))
    
    # Memoria
    if "memory_percent" in metrics:
        score = min(100, (OBJECTIVES["memory_percent"] / max(metrics["memory_percent"], 1)) * 100)
        scores.append(("memory", score, 0.15))
    
    if not scores:
        return 0
    
    weighted_sum = sum(score * weight for _, score, weight in scores)
    total_weight = sum(weight for _, _, weight in scores)
    
    return (weighted_sum / total_weight)

def calculate_frontend_percentage():
    """Calcula porcentaje de conexi√≥n frontend."""
    passed = sum(1 for _, result in E2E_TESTS if result)
    total = len(E2E_TESTS)
    return (passed / total) * 100

def main():
    print("=" * 60)
    print("üìä C√ÅLCULO DE M√âTRICAS DE OPTIMIZACI√ìN")
    print("=" * 60)
    print(f"Fecha: {datetime.now().isoformat()}")
    
    # 1. Implementaci√≥n
    impl_pct = calculate_implementation_percentage()
    print(f"\nüìã IMPLEMENTACI√ìN: {impl_pct:.1f}%")
    print("   Tareas:")
    for task, done in IMPLEMENTATION_TASKS:
        status = "‚úÖ" if done else "‚¨ú"
        print(f"   {status} {task}")
    
    # 2. Funcionamiento (m√©tricas simuladas - reemplazar con reales)
    sample_metrics = {
        "latency_p95": 150,      # ms
        "throughput_rps": 80,    # RPS
        "cpu_percent": 45,       # %
        "memory_percent": 55,    # %
    }
    
    func_pct = calculate_functionality_percentage(sample_metrics)
    print(f"\n‚ö° FUNCIONAMIENTO: {func_pct:.1f}%")
    print("   M√©tricas medidas:")
    for key, value in sample_metrics.items():
        objective = OBJECTIVES.get(key.replace("_percent", "_percent").replace("latency_p95", "latency_p95_ms"))
        if objective:
            status = "‚úÖ" if value <= objective else "‚ö†Ô∏è"
            print(f"   {status} {key}: {value} (objetivo: {objective})")
    
    # 3. Frontend
    fe_pct = calculate_frontend_percentage()
    print(f"\nüñ•Ô∏è CONEXI√ìN FRONTEND: {fe_pct:.1f}%")
    print("   Tests E2E:")
    for test, passed in E2E_TESTS:
        status = "‚úÖ" if passed else "‚ùå"
        print(f"   {status} {test}")
    
    # Resumen
    print("\n" + "=" * 60)
    print("üìà RESUMEN DE M√âTRICAS")
    print("=" * 60)
    print(f"""
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  IMPLEMENTACI√ìN:      {impl_pct:>6.1f}%     ‚îÇ
    ‚îÇ  FUNCIONAMIENTO:      {func_pct:>6.1f}%     ‚îÇ
    ‚îÇ  CONEXI√ìN FRONTEND:   {fe_pct:>6.1f}%     ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  PROMEDIO TOTAL:      {(impl_pct + func_pct + fe_pct) / 3:>6.1f}%     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    """)
    
    # Guardar resultados
    results = {
        "timestamp": datetime.now().isoformat(),
        "implementation_percentage": impl_pct,
        "functionality_percentage": func_pct,
        "frontend_percentage": fe_pct,
        "overall_percentage": (impl_pct + func_pct + fe_pct) / 3,
        "metrics": sample_metrics,
    }
    
    with open("optimization_metrics.json", "w") as f:
        json.dump(results, f, indent=2)
    
    print("‚úÖ Resultados guardados en optimization_metrics.json")

if __name__ == "__main__":
    main()
```

---

## 10. MONITOREO Y ALERTAS

### 10.1 Endpoint de M√©tricas

Agregar en `backend/routes/metrics_routes.py`:

```python
"""
metrics_routes.py - Endpoints de m√©tricas para monitoreo
"""

from fastapi import APIRouter
import psutil
import time
from datetime import datetime

router = APIRouter(prefix="/api/metrics", tags=["Metrics"])

# M√©tricas en memoria
_request_count = 0
_error_count = 0
_start_time = time.time()

@router.get("/health")
async def health_check():
    """Health check b√°sico."""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "uptime_seconds": int(time.time() - _start_time),
    }

@router.get("/system")
async def system_metrics():
    """M√©tricas del sistema."""
    process = psutil.Process()
    
    return {
        "timestamp": datetime.utcnow().isoformat(),
        "cpu": {
            "percent": process.cpu_percent(interval=0.1),
            "num_threads": process.num_threads(),
        },
        "memory": {
            "rss_mb": process.memory_info().rss / 1024 / 1024,
            "percent": process.memory_percent(),
        },
        "uptime_seconds": int(time.time() - _start_time),
    }

@router.get("/prometheus")
async def prometheus_metrics():
    """M√©tricas en formato Prometheus."""
    process = psutil.Process()
    uptime = int(time.time() - _start_time)
    
    metrics = f"""# HELP process_cpu_percent CPU usage percent
# TYPE process_cpu_percent gauge
process_cpu_percent {process.cpu_percent(interval=0.1)}

# HELP process_memory_rss_bytes Memory RSS in bytes
# TYPE process_memory_rss_bytes gauge
process_memory_rss_bytes {process.memory_info().rss}

# HELP process_uptime_seconds Process uptime in seconds
# TYPE process_uptime_seconds counter
process_uptime_seconds {uptime}

# HELP http_requests_total Total HTTP requests
# TYPE http_requests_total counter
http_requests_total {_request_count}

# HELP http_errors_total Total HTTP errors
# TYPE http_errors_total counter
http_errors_total {_error_count}
"""
    
    from fastapi.responses import PlainTextResponse
    return PlainTextResponse(content=metrics, media_type="text/plain")
```

### 10.2 Registrar en server.py

```python
from routes.metrics_routes import router as metrics_router
app.include_router(metrics_router)
```

### 10.3 Alertas B√°sicas (Script)

Crear archivo `scripts/check_alerts.py`:

```python
#!/usr/bin/env python3
"""
check_alerts.py - Verifica umbrales y genera alertas
"""

import asyncio
import httpx
import os

ALERT_THRESHOLDS = {
    "cpu_percent": 70,
    "memory_percent": 80,
    "latency_p95_ms": 500,
}

async def check_alerts():
    print("üö® VERIFICACI√ìN DE ALERTAS")
    print("=" * 40)
    
    alerts = []
    
    async with httpx.AsyncClient() as client:
        try:
            response = await client.get("http://localhost:5000/api/metrics/system")
            data = response.json()
            
            # CPU
            cpu = data["cpu"]["percent"]
            if cpu > ALERT_THRESHOLDS["cpu_percent"]:
                alerts.append(f"‚ö†Ô∏è CPU alto: {cpu}% > {ALERT_THRESHOLDS['cpu_percent']}%")
            
            # Memoria
            mem = data["memory"]["percent"]
            if mem > ALERT_THRESHOLDS["memory_percent"]:
                alerts.append(f"‚ö†Ô∏è Memoria alta: {mem}% > {ALERT_THRESHOLDS['memory_percent']}%")
            
        except Exception as e:
            alerts.append(f"‚ùå Error obteniendo m√©tricas: {e}")
    
    if alerts:
        print("\nüîî ALERTAS ACTIVAS:")
        for alert in alerts:
            print(f"   {alert}")
    else:
        print("\n‚úÖ Sin alertas - Sistema operando normalmente")
    
    return len(alerts) == 0

if __name__ == "__main__":
    asyncio.run(check_alerts())
```

---

## 11. ROLLBACK Y CONTINGENCIAS

### 11.1 Script de Rollback

Crear archivo `scripts/rollback.sh`:

```bash
#!/bin/bash
# rollback.sh - Revertir cambios de optimizaci√≥n

echo "=========================================="
echo "‚è™ ROLLBACK DE OPTIMIZACIONES"
echo "=========================================="

# Verificar que se proporciona un punto de restauraci√≥n
if [ -z "$1" ]; then
    echo "Uso: ./rollback.sh [punto_de_restauracion]"
    echo "  Opciones:"
    echo "    connection_pool  - Revertir connection pooling"
    echo "    cache           - Deshabilitar cache"
    echo "    compression     - Deshabilitar compresi√≥n"
    echo "    all             - Revertir todo"
    exit 1
fi

ROLLBACK_POINT=$1

case $ROLLBACK_POINT in
    connection_pool)
        echo "Revirtiendo connection pooling..."
        # Instrucciones espec√≠ficas
        echo "  1. Editar database_pg.py"
        echo "  2. Reemplazar pool por conexiones directas"
        echo "  3. Reiniciar servidor"
        ;;
    cache)
        echo "Deshabilitando cache..."
        echo "  1. Eliminar REDIS_URL de Secrets"
        echo "  2. Reiniciar servidor"
        ;;
    compression)
        echo "Deshabilitando compresi√≥n..."
        echo "  1. Eliminar GZipMiddleware de server.py"
        echo "  2. Reiniciar servidor"
        ;;
    all)
        echo "Revirtiendo todas las optimizaciones..."
        echo "  Esto requiere restaurar desde backup"
        ;;
    *)
        echo "Punto de rollback desconocido: $ROLLBACK_POINT"
        exit 1
        ;;
esac

echo ""
echo "‚ö†Ô∏è Despu√©s del rollback:"
echo "  1. Ejecutar health check"
echo "  2. Verificar m√©tricas"
echo "  3. Probar funcionalidad"
```

### 11.2 Checklist de Contingencia

```
EN CASO DE PROBLEMAS DESPU√âS DE OPTIMIZACI√ìN:

‚ñ° 1. Verificar logs de error
     tail -f /var/log/app.log
     
‚ñ° 2. Ejecutar health check
     python backend/scripts/health_check.py
     
‚ñ° 3. Verificar conexi√≥n a base de datos
     python -c "import asyncpg; ..."
     
‚ñ° 4. Verificar uso de recursos
     htop / top
     
‚ñ° 5. Si el problema persiste:
     - Revertir √∫ltimo cambio
     - Reiniciar servidor
     - Escalar horizontalmente (si aplica)
     
‚ñ° 6. Documentar el incidente
     - Hora de inicio
     - Cambios realizados
     - S√≠ntomas observados
     - Acciones tomadas
     - Resoluci√≥n
```

---

## 12. CHECKLIST FINAL DE QA

### 12.1 Checklist de Verificaci√≥n

```
CHECKLIST DE OPTIMIZACI√ìN - REVISAR.IA

INFRAESTRUCTURA:
‚ñ° Connection pooling configurado y funcionando
‚ñ° Cache layer activo (Redis opcional)
‚ñ° Compresi√≥n Gzip habilitada
‚ñ° Timeouts configurados en llamadas externas
‚ñ° Health check endpoint funcionando

BASE DE DATOS:
‚ñ° √çndices cr√≠ticos creados
‚ñ° Pool de conexiones optimizado
‚ñ° Queries lentas identificadas y optimizadas
‚ñ° EXPLAIN ANALYZE ejecutado en queries cr√≠ticas

BACKEND:
‚ñ° Todos los endpoints responden < 500ms
‚ñ° Rate limiting funcionando
‚ñ° Error handling consistente
‚ñ° Logs estructurados

FRONTEND:
‚ñ° CORS configurado correctamente
‚ñ° Llamadas API funcionando
‚ñ° Manejo de errores implementado
‚ñ° Loading states presentes

MONITOREO:
‚ñ° Endpoint de m√©tricas disponible
‚ñ° Health check automatizado
‚ñ° Alertas configuradas (si aplica)

SEGURIDAD:
‚ñ° Secrets en variables de entorno
‚ñ° No hay credenciales en c√≥digo
‚ñ° Headers de seguridad presentes

DOCUMENTACI√ìN:
‚ñ° README actualizado
‚ñ° Scripts documentados
‚ñ° Configuraci√≥n documentada
```

### 12.2 Comando de Verificaci√≥n Final

```bash
#!/bin/bash
# final_verification.sh

echo "=========================================="
echo "‚úÖ VERIFICACI√ìN FINAL DE OPTIMIZACI√ìN"
echo "=========================================="

PASS=0
FAIL=0

check() {
    if [ $? -eq 0 ]; then
        echo "  ‚úÖ $1"
        ((PASS++))
    else
        echo "  ‚ùå $1"
        ((FAIL++))
    fi
}

# 1. Servidor responde
curl -s http://localhost:5000/api/health > /dev/null
check "Servidor responde"

# 2. Base de datos conecta
python3 -c "
import asyncio, asyncpg, os
asyncio.run(asyncpg.connect(os.getenv('DATABASE_URL')))
" 2>/dev/null
check "Base de datos conecta"

# 3. Health check pasa
python3 backend/scripts/health_check.py > /dev/null 2>&1
check "Health check pasa"

# 4. M√©tricas disponibles
curl -s http://localhost:5000/api/metrics/system > /dev/null 2>&1
check "Endpoint de m√©tricas"

# 5. CORS configurado
curl -s -I -X OPTIONS http://localhost:5000/api/health 2>&1 | grep -qi "access-control"
check "CORS configurado"

# Resumen
echo ""
echo "=========================================="
echo "RESULTADOS: $PASS passed, $FAIL failed"
TOTAL=$((PASS + FAIL))
PCT=$((PASS * 100 / TOTAL))
echo "TASA DE √âXITO: $PCT%"
echo "=========================================="
```

---

## üìã RESUMEN EJECUTIVO

### M√©tricas Objetivo

| M√©trica | Antes | Objetivo | Mejora Esperada |
|---------|-------|----------|-----------------|
| P95 Latencia | ~500ms | < 300ms | 40% |
| Throughput | ~50 RPS | > 100 RPS | 100% |
| CPU Peak | ~90% | < 70% | 22% |
| Memoria | ~85% | < 80% | 6% |
| Tiempo de conexi√≥n DB | ~100ms | < 20ms | 80% |

### Implementaci√≥n Completada

| Optimizaci√≥n | Estado | Impacto |
|--------------|--------|---------|
| Connection Pooling | ‚úÖ | Alto |
| Cache Redis | ‚úÖ Listo | Alto |
| Compresi√≥n Gzip | ‚úÖ | Medio |
| Timeouts/Retries | ‚úÖ | Alto |
| Background Tasks | ‚úÖ | Medio |
| √çndices PostgreSQL | ‚úÖ | Alto |
| Scripts de Monitoreo | ‚úÖ | Medio |

### Porcentajes Finales Esperados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  IMPLEMENTACI√ìN:       100%       ‚îÇ
‚îÇ  FUNCIONAMIENTO:       95%+       ‚îÇ
‚îÇ  CONEXI√ìN FRONTEND:    100%       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  SCORE TOTAL:          98%+       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

**FIN DEL DOCUMENTO DE OPTIMIZACI√ìN**

Para ejecutar: Copiar secciones relevantes a Replit y seguir instrucciones paso a paso.